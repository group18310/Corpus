Incidents versus Hosts ­ the Evolution We know that the number of Internet hosts is increasing, and we know that the number of reported incidents also is increasing. But which of them are increasing the most? It would be interesting to show trends for the hacking activity. Table 2 shows collected numbers from ISC Internet Domain Survey and CERT/CC. The first column shows the year, the second column shows the number of hosts (http://www.isc.org/index.pl?/ops/ds/) and the third column shows the number of incidents (http://www.cert.org/stats/cert_stats.html). The next two columns show results from the equation incidents / hosts * factor = X
· Table 2: Evolution of hosts and incidents Year 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 Hosts 4 852 000 9 472 000 16 146 000 29 670 000 43 230 000 72 398 092 109 574 429 147 344 723 171 638 297 233 101 481 Incidents 2 340 2 412 2 573 2 134 3 734 9 859 21 756 52 658 82 094 137 529 Incidents/Hosts 0,000482275 0,000254645 0,000159358 7,19E-05 8,64E-05 0,000136178 0,00019855 0,00035738 0,000478297 0,000589996 Factor=100000 X= 48,2275 25,4645 15,9358 7,1925 8,6375 13,6178 19,855 35,738 47,8297 58,9996

2

Searches using "Google" (www.google.com)

17



Hosts - Incidents
250000000

hosts incidents 160000 140000

200000000 120000 100000 80000 100000000 60000 40000 50000000 20000 0 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 0 Incidents

150000000 Hosts

· Figure 5: Hosts versus incidents 1994 ­ 2003.

From Figure 5, we see that both hosts and incidents have been increasing dramatically during the recent years. We also see that the growth in hosts started earlier than for incidents. This has of course natural reasons, because incidents cannot happen without hosts to attack, and with the growth of hosts, potential attackers and hacking activity will also increase. However, the interesting part would be to see how many incidents there are per host over several years. This way we can estimate if the "hacking activity" grows or sinks those years. Figure 6 shows the relationship between incidents and hosts. You can clearly see that from 1994 until 1997 there was a decrease in activity per host. However, since 1997 the trend turned, and the activity per host has continuously been growing until 2003. It is most likely still growing today, because of the development of sophisticated attacking tools. The tools are made to harm a greater number of hosts, and to be used with less knowledge of hacking. We tell more about this in the chapter "Attacking methods".

18



incidents/hosts * 100000 70,0 60,0 50,0 40,0 factor 100000 30,0 20,0 10,0 0,0 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003

· Figure 6: Relation between incidents and hosts.

Vulnerabilities
Protecting software in the face of attacks is a difficult task. Vulnerabilities (weaknesses that can be exploited to compromise the operation of the system) can creep into the system in a variety of areas. Some of these vulnerabilities are difficult to correct because they are the result of architecture and design decisions that were made early in the product's development cycle. In these cases, the vulnerabilities can only be removed by changing the basic architecture of the product. These types of fundamental changes often have consequences that affect other aspects of the product's operation. These types of vulnerabilities are typically long-lived, and product users must find some other way to protect themselves from attacks that attempt to exploit the vulnerabilities (e.g. invest in anti-virus software in order to detect and remove viruses before they operate on the vulnerable system). Other vulnerabilities are easier to correct since they are the result of low-level design decisions or implementation errors (bugs in the programs). Often the vendor can quickly correct these types of vulnerabilities, once discovered, and the corrections (oftentimes called "patches") can be made available to the customers. However, even though the corrections may be available quickly, it is not always the case that they can be deployed quickly. System operators need to insure that the corrections do not have unintended side effects on their systems, and typically test the corrections before deployment. In addition, in the case of a widely used product, system operators must often
19



update the software used in thousands of computers to deploy the correction. This is a labor intensive and time-consuming task in itself. Therefore, systems are attacked several months after vendors produce corrections to the vulnerabilities, in many cases. Deciding which vulnerabilities really matter, and effectively dealing with them, are key steps in an organization's risk management process. More about patching in the part "Problems with Patching" (pages 35-36).

Basic types of vulnerabilities Here is a list of the general vulnerability types: Default software installations - Performing a default software installation on computers with sensitive data is not good practice, especially when the chosen software is likely to be used by many people, such as on a public access computer or Web server. This often leads to backdoors for hackers that know the default services. Ineffective use of authentication - Most organizations rely on authentication via passwords. Passwords can be a secure form of authentication when they are created properly. However, most people create poor passwords. Patches not applied - Patches for known security problems are not applied. Too many open ports and services running - Services listens for packets that arrive from other computers with matching port numbers. Too many ports open can give away a lot of information about the machine. Not analyzing incoming traffic - Analyzing incoming packets allows you to weed out packets that do not match the security policy. Backups not maintained and verified - If backups are not taken regularly, you will not be able to quickly recover from data loss. The backups should be verified. Lack of protection against malicious code - viruses, worms and Trojan horses (more on malicious code in "Attack methods").

Attack Methods
There are many types of attacks. A general smart network attack usually happens like this: First, the intruder has to locate the system to attack. Then he gains user access or privileged access to that system, covers his tracks, and installs backdoors. Now he can attack other systems, take or alter information, or engage in unauthorized activity. Most compromised systems are not patched, or they are configured wrong. Intruders use toolkits to try numerous exploits looking to capitalize on an exploit that has not been patched by system administrators. Technology has changed, and so has the challenges of security professionals. It is important for them to keep informed because the attack methods used by hackers are

20



many. Figure 7 below shows that the technical knowledge of the intruders has decreased. One reason for this is that the attack tools are published and made available through the Internet. While the attackers gets "dumber", the attack sophistication increases. The attackers started by guessing passwords, and they are now using more advanced tools like XSS (cross site scripting) and distributed attack tools. The tools are much more userfriendly than they used to be, and the attackers' average level of learning declines over time.

· Figure 7: Attack Sophistication vs. Intruder Technical Knowledge (Lipson 2000)

The Basic Attacks Tools Probes and Scans A probe is an attempt to gain access to a system or to discover information about the system. Probing can be compared to testing doorknobs to find an unlocked door for easy entry. Probes are sometimes followed by a more serious security event, but they are often the result of curiosity or confusion. A scan is a way of performing multiple probes using an automated tool. The most common kind of scan is a "port scan."

21



Account Compromise Account compromise is the discovery of user accounts and their passwords on a system. It allows an unauthorized user to gain access to all resources for which that user account is authorized. Packet Sniffer A packet sniffer is a program that captures data from information packets as they travel over the network. That data may include user names, passwords, and proprietary information that travels over the network. If the data captured by a packet sniffer is encrypted, it is unlikely that someone will be able to reveal any sensitive information. However, if the data is not encrypted, just about any information sent is vulnerable for being compromised. Denial of Service The goal of denial of service attacks is not to gain unauthorized access to machines or data, but to prevent legitimate users of a service from using it. A denial of service attack can come in many forms, but the underlying purpose to a denial of service attack is to bog down a system by giving it too much information to process quickly enough. Malicious Code Malicious code is a general term for programs that, when executed, can cause undesired results on a system. Users of the system are usually not aware of the program until they discover the damage. Malicious code includes Trojan horses, viruses, and worms. Trojan horses and viruses are usually hidden in legitimate programs or files that attackers have altered to do more than what is expected. Worms are self-replicating programs that spread with no human intervention after they are started. Viruses are also self-replicating programs, but they usually require some action on the part of the user to spread to other programs or systems. Spoofing Spoofing is when attackers can forge their identity, appearing to be using a trusted computer, and therefore are able to gain unauthorized access to other computers.

Methods of Attacking Hackers use several ways of attacking, and we wish to describe some of them:

Social engineering Social engineering are techniques for persuading another person to do what you want. An example, which is a common hacker trick, is to telephone unsuspecting employees and pretend to be a network system administrator or security manager. To do these kind of scams, the hacker needs to gain knowledge about the company's network to sound convincing, and thereby get passwords, account names, and other sensitive information
22



from the employee. To gain this kind of knowledge, one can read newspapers, magazines, and annual reports. The method is very effective, because it bypasses cryptography, computer security, network security, and everything else technological. It proves that the weakest link in any security system is the human. The well-known hacker, Kevin Mitnick used this method. He testified before Congress in 2000, and said the following about social engineering: "Companies can spend millions of dollars toward technological protections and that's wasted if somebody can basically call someone on the telephone and either convince them to do something on the computer that lowers the computer's defenses or reveals the information they were seeking" (Schneier 2000). Other types of social engineering can be showing up at a computer room, or stealing credit card numbers.

Insider attacks The insiders are malicious because they are already inside the system they want to attack. It is often a person that has a high level of access, and he/she can be considered to be trusted by the system he/she is attacking. Firewalls, intrusion detection systems, and most other computer security measures, try to deal with the external attacker, but are powerless against insiders. Most security problems occur from within, and it's mostly hacking at the application level. Estimation is that former employees do 85% of all hacking against companies. (Appendix D)

Dumpster diving Hackers frequently search dumpsters located outside of buildings for information sources such as operator logs, technical manuals, policies, standards, company phone books, credit card numbers, and dial-in telephone numbers. This is categorized as "dumpster diving". The information might help the hacker to gain access to the organization.

Hardware and Software tools Phreaks use hardware devices to gain free phone access. They generate tones that allow them to navigate the various telephone switches. A lot of software tools are available on the Internet or on bulletin board systems. This can be network sniffer software (to capture IDs and passwords), password cracker tools, or war dialers.

23



Reverse intent CERT/CC advisories CIAC information bulletins are intended to notify people of security problems. Hackers and phreaks use this to their advantage, and the information is used to perform the opposite action of what it was intended to. When hackers find out about these announcements, they are quick to notify each other of it, and exploit the weaknesses.

Phishing Phishing is when someone (phishers) are using spam to deceive consumers into disclosing credit card numbers, bank account details, Social Security numbers, passwords, and other sensitive information. Phishers "fish" for personal information that can be used in identity theft, and thereby the name. They pass themselves off as Earthlink, eBay, or some other legitimate business, and tell the Internet user, via e-mail, that there is a problem with their ISP (Internet Service Provider) account, and provide them with directions to a Web site for clarification. By clicking on the link to this Web site, users get directed to a hoax Web site that probably is a perfect copy of for example Earthlink. At this page, users are fooled into providing personal information. The phony e-mails and Web pages may claim that you have won a price, or they may encourage you to sign up for testing of a new product or service. Some of the Web pages may download computer viruses or Trojan horse programs to your computer automatically, and cause damage of your computer files, or the scammer might get your password. The scammer can be signing on to your ISP account, read your e-mail, send email from you, etc., and all this because he/she got the hold of your screen name and password. It is easy to get a phony Web site as well, because there are scripts for stealing Web sites. Reamweaver (http://reamweaver.com) is one of them. It works by downloading and extracting the file, uploading it to a Web site directory, and making sure that all the files have full permissions. Users can do some precautions to protect themselves against phishing. They can do this by checking that their ISP is genuine, inspecting the accuracy of the Web address, and by being on lookout for a PKI (public key infrastructure) on a Web site. The PKI verifies the identity of the certified company (Selfridge 2004).

Identification of Hackers
Security practitioners need to understand hackers in order to protect their systems against unauthorized intrusion of their computer and communications systems. They need to know who they are, what motivates them to break into systems, and how they operate. What are the motives and modes of operation? How do hackers gather and share information? How do they break into systems? The New Hacker's Dictionary has the following definition of a hacker: "A person who enjoys learning the details of computer systems and how to stretch their capabilities ­ as
24



opposed to most users of computers who prefer to learn only the minimum amount necessary" (Norris 1995).

Who are the Hackers? "Hackers built the Internet. Hackers made the Unix operating system what it is today. Hackers run Usenet. Hackers make the World Wide Web work. If you are part of this culture, if you have contributed to it and other people in it know who you are and call you a hacker, you're a hacker." (Raymond 2001) The typical hacker profile in the early 1980's, was a highly intelligent, introverted teenager or young adult male who viewed hacking as a game. He was also from middle or upper class family. Hacking used to involve a elite group of individuals. The newer hacker stereotype is a socially awkward teenager (boy) with oversized glasses who never gets out. In reality, hackers can be very smart or of average intelligence, social or non-social, male or female, of all ages, and rich or poor. Although most people consider hackers to be "bad people", many of them are not. Hackers can be divided into two groups: white-hat hackers and black-hat hackers. A cracker or hacker who breaks into a computer system or network with malicious intent, is a black-hat hacker. He/she takes advantage of the break-in, perhaps by stealing data or destroying files. In contrast, the white-hat hackers work with clients in order to help them secure their systems. These are "ethical" hackers. A samurai can be categorized as a white-hat, because this is a computer hacker who is hired legally to infiltrate corporate computer systems for legitimate reasons. The hacker types mentioned above can again be divided into the following groups: "script kiddies", phreakers, competent programmers who modify existing tools and stars who build new tools.

Script kiddies and phreakers The script kiddies are normally not technically sophisticated. They randomly seek out a specific weakness over the Internet in order to gain root access to a system, and do not really understand what he/she is exploiting. Someone else originally discovered the weakness. The script kiddies do not target specific information or a specific company, but use knowledge of a vulnerability to scan the Internet for a victim with that vulnerability. Most hackers are script kiddies. They are estimated to be 90% of the total amount of hackers. This type of hackers is looking for an easy kill, and is looking for common exploits. The skills of these people are various. Some of them have no idea of what they are doing and what consequences it can lead to, while others are advance users who develop their own tools and leave behind sophisticated backdoors. Their methodologies are simple; they scan the Internet for a specific weakness, and when they find it, they exploit it. Most of the tools are automated, and they require little interaction. Phreakers are people who crack the telephone network.

25



Competent programmers and stars It is estimated that less than 10% of the hackers are competent programmers who modify existing tools, while the stars are real masters who build completely new tools. Less than 1% of the hackers fits into the star-category. These real hackers look down upon the group of people who get a kick out of breaking into computers and phreaking the phone system, and call them crackers. They say that the crackers are usually the script kiddies, and the real hackers want nothing to do with them. They are considered lazy and not very bright. The hackers are the ones who build things, while crackers break them. To become a hacker, a person needs intelligence, practice, dedication, and hard work. The hackers have superior technical skills, are very persistent, and they often publish their exploits.

The Hacker Environment The hacker culture does not have any leaders. It has culture heroes that have been around for a while and become well known. The community of expert programmers and networking wizards traces its history back to the first time-sharing minicomputers and the earliest ARPAnet experiments decades ago. Members of this shared culture were the ones who originated the term "hacker". Hackers share information through hacker clubs, publications, conventions, bulletin boards and newsgroups, Web sites, meetings, and through chatrooms. How large the environment is, is difficult to estimate, and different sources tell different things. Only one out of 10,000 or more people engage in hacking activity (Slawsky 2003). Another source (Graham 2001) says that about 100,000 hackers are skilled enough to bring down a major Internet portal for a few hours. Most members of hacker clubs never physically meet, but they give a sense of companionship, and give the members help to work as a team toward common goals. By working as teams, they can achieve goals that can be out of reach for an individual hacker. Examples of hacker clubs are Legion of Doom (LOD), Chaos Computer Club, NuKE, and The Posse. Some hacker clubs produce their own publications. Legion of Doom produces the hacker publication Phrack, and Chaos Computer Club produces Chaos Digest. The publications provide hackers with technical information, and they have a social function. Some publications are sent through postal mail, while others are received through electronic mail. Many of the hacker conventions serve as venues for hackers to brag, swap stories, and exchange information. They tend not to be highly organized. Some hacker groups sponsor these conventions, like "the Chaos Congress" (sponsored by Chaos Computer Club) and "Hacking at the End of The Universe" (sponsored by Hack-Tic). DefCon is the largest underground hacking event in the world, held every summer in Las Vegas, USA. In 2001, more than 5,000 hackers were participants in the convention, and "Starla Pureheart" (a.k.a. Anna Marie Moore) was the first female hacker to win the ethical hacking contest that year. She is a good example of a hacker with sophistication, real skills, and ethics (Verton 2002) (Appendix E).

26



Internet newsgroups and bulletin board systems (BBS) are very similar, because they allow people a vast forum for communication. Hackers and hacker clubs primarily communicate through bulletin board systems, and the information found here is usually hot news. The difficult part can be to get access to a bulletin board, and as new members become more trusted, level of access to sensitive information increases. Most of the hacking Web sites contain available hacking tools and free downloads of hacker programs. With these tools, instructions on how to perform attacks also follow. In addition, the number of hacking Web sites is increasing. Chatrooms like IRC and ICQ are very popular for hackers to exchange information, and it is very common that the black-hats like to brag about their skills. An example of this, is the hacker "Mafiaboy". He is known for taking down Web sites like Yahoo, eBay, CNN, etc., in February 2000, and bragged over what he did on IRC. The chat log in the IRC hacker room #!tnt details a conversation between "Mafiaboy" (who has changed his nickname to anon (for anonymous))and other hackers (Appendix E) (Verton 2002): T3: Mafiaboy, so who's next after dell Anon: Microsoft will be gone for a few weeks T3: oh man, that's evil T3: I need to get away from you before I get busted for being an accomplice or some sh** Anon: I know what I'm doing Anon: yahoo.com T3: So Mafiaboy, it was really you that hit all those ones in the news? buy.com, etrade, eBay, all that sh**? Anon: you just pin em so hard they can't even redirect T3: they say you're costing them millions Anon: surprised I didn't get raided yet, T3, they are fools

The communication on IRC is often very loose, and also the way that IRCers use and spell their language is very similar to their language used in an actual everyday conversation. Uncommon structure of sentences is also very common (Thorkildsen 2003). It is not very common that hackers physically meet, but there are hacker clubs that have meetings for people that want to show up. 2600 (www.2600.org) have arranged meetings all over the world, and they all take place on the first Friday of the month. They meet in public areas like bars, at food courts at shopping centers, Internet cafés, or by a specific payphone. The meetings are free, and the target group is everyone interested in computers, telecommunications, security, and communications. Table 3 illustrates some estimates of the hacker environment. The numbers vary greatly from one source to another, and is described closer with examples in Appendix D. Numbers of hackers vary from about one hundred serious hackers to hundreds of thousands. It is hard to estimate, because the sources may have different interpretations of what a hacker is, and the hackers use aliases to keep anonymous. Thereby, they can change their identity very quickly just by changing aliases. The table shows that there is an exponentially increase in number of Web sites, and also that the table is not complete because of the difficulty of finding data (numbers from 1999 and 2000 are lacking completely, and there are "holes" in the number of Web sites in 2001, and also in bulletin boards in 2002 and 2003. We did not find any numbers of publications, except from "dozens" in 1997).

27



· Table 3 Hacker Environment Information

Hacker Information Web sites April, 1997 November, 1997 February, 1998 July, 2001 February, 2002 February, 2003 4 100 6 000 1 900 2 000 2 500 Publications Dozens Bulletin Boards 440 500 500 1 000

John Maxfield, a computer security consultant called a "hacker tracker", estimated in 2001 that there were 50,000 hackers, and close to 1,000 bulletin boards. About 200 of the bulletin boards are "nasty". This means they are posting credit card numbers, regional phone companies, banks, and have even authored tutorials on how to make bombs and explosives. Additionally, Maxfields estimates say that there were just 400 to 500 hackers in 1982, and every two years the numbers increase by a factor of 10 (Skidmore 2001). Norris's article from 1995 says that it was estimated to be about 1,300 underground bulletin boards only in the US. When this number is compared with table X, it shows that estimates are contrary to each other, and it is difficult to know which are most accurate. It is a good example in showing the problems with data collection, and we choose to believe in the numbers that seem reasonable compared to each other, and thereby disregard extreme numbers that do not seem to be correct. Still, we do not disregard the fact that we could have been wrong in some of our selection of sources, but we believe that the trends are realistic. In the conclusion of Appendix D, we have discussed this problem in connection with the number of hacker Web sites. Hackers need three things to succeed; motive, opportunity, and means. The motive may be increased knowledge (intellectual challenge), a joy ride, or profit. Other motivations can be gang mentality, recognition, and theft of information, vandalism, blackmail, sabotage, or terrorism. Appendix E gives examples of this, as it contains information about different teenage hackers, and mentions some of their motives for hacking. The opportunity for people to hack systems has increased very much over the years, because computer systems can be found everywhere. The imagination and determination of a hacker is what limits the means of attack. "Delete nothing, move nothing, change nothing, learn everything" is a summary of the basic law of hacking (Norris 1995). The motive of the hackers may affect which types of attacks they perform. Script kiddies might be hacking to gain knowledge and respect, while black-hats hack to find personal information and misappropriate information.

28



Likely Sources of Attack
Percentage of R espondents 100 90 80 70 60 50 40 30 20 10 0 Foreign Gov. Independent H ackers U .S. C ompetitors D isgruntled Employees Foreign C orp.

1999 2000 2001 2002 2003

· Figure 8: Likely Sources of Attack. (CSI/FBI 2003 Computer Crime and Security Survey)

Figure 8 shows different likely sources of attacks. From 1999 to 2003, foreign governments and independent hackers have increased with 7 and 8 percentage points, respectively. These two groups can be considered growing threats. Foreign corporations, US competitors and disgruntled employees are more fluctuating, but they have all decreased from 1999 to 2003. Still, independent hackers and disgruntled employees are clearly the two most likely sources of attack.

Hacker Wars Chris Belthoff, a senior analyst, said: "These virus writers are fighting a war amongst themselves for attention and one-ups-manship, and we're all getting caught in the crossfire. The war definitely increases the chances that the variants will continue to come. But hopefully, it will help us pick up on clues as to who the virus writers are." (Gaudin 2004) More and more variants of worms are coming; the Bagle, Netsky, and MyDoom, and the viruses are devastating. The three viruses mentioned above, have infected more than 215 countries, and caused billions of dollars worth of damages. Cyber wars are very efficient for the attacker from a risk/cost perspective, and the attacks can be just as damaging as physical attacks. It is also believed that the rivalry of the hackers leads to more attacks. Why do hacker gangs fight each other? And how? We will try to answer these questions in the rest of this chapter.
29



IRC Wars and Bots Hackers often use IRC channels (Internet Relay Chat). They use them to brag about their achievements and to chat with other hackers, but it is also used in cyber warfare in order to gain control of IRC chatrooms, and then keep control against attacks from rival gangs. Several IRC servers offer hacker channels. The first person to start up a channel on an IRC server is automatically operator (OP). He has the power to kick off people, or invite people in, and he may also pass on the operator status to someone else. "A hacker can get control of a chatroom by kicking off all the rival moderators. This is a way for hacker gangs to gain control of IRC chatrooms, and then keep control against attacks from rival gangs. Hackers are using a method called "the flood", which is a technique where a hacker sends a huge number of pings against the victim. There will be so much meaningless traffic that nothing else can get through." (Appendix G). In the turf wars between hacker clubs, hackers run "bots" (automated programs). These bots are left behind in machines that the gangs hack into, where one kind of bot tries to stay logged onto the IRC chatroom, becomes moderator, and pass moderation privileges to other bots. Another kind of bot tries to use DoS on existing moderators from the defending gang in order to kick them off. As the defenders lose control, they become the attackers. The attackers can be using more DoS-bots, while the defenders are using more IRC-bots in order to maintain control. IRC wars are still a small segment of the overall hacker community.

Hacktivism Hacktivism is political hacking on the Internet. Patriotic hackers and religion extremist groups are common hacktivists, while peace activists who are against war is a new development of hackers. Hundreds of Web sites have been hacked by peace activists. This kind of hacking has been called the "new era of cyberwar". "Pr0metheus" is an example of a religious hacker (Verton 2002). He hates organized religion, especially Christianity, and replaced Christian Web sites with his own liturgy on the principle of Satanism. See also Appendix E. Hacktivism began with a series of so-called network-direct actions against Web sites of the Mexican government in 1998. This became popular with the Israelis and Palestinians in the Middle-East crisis. Tactics like Web site defacement, worm and virus infections, DoS attacks, Web site sit-ins, and e-mail bombings have become popular in times of political crisis. Mig2 expected the damage on computer systems worldwide due to hacktivism to be $20 million in 2003. The hacker turf wars seem to be battles for control of cyberspace, and the war is for power and seniority among authors of viruses or worms. Version J of the Bagle worm, had the following provocative statement in it: "wanna start a war(?)" (Koprowski 2004). Cyber terrorists will probably use DoS and DDoS tools more and more, because they can be very destroying, and it is a "new" way to have a war between countries, as well as other
30



groups. The point of cyber attacks is to terrorize, and it can impact an economy or jobs. But al-Qaida or some other Islamic extremist group are not solely to blame for these kinds of terrorist attacks, because some cyber crime comes from unethical businesses that seek to spy on, or sabotage, competitors.

31



Modeling the Threat to Information Security
In this chapter we will look at the paper "Modeling the Lifecycle of Software-based Vulnerabilities" by Johannes Wiik, Jose J. Gonzalez, Howard F. Lipson and Timothy J. Shimeall, and discuss the system dynamics model "software vulnerability lifecycle" within the paper.

System Dynamics
"System dynamics is a powerful method to gain useful insight into situations of dynamic complexity and policy resistance" (Sterman 2000). The method can be used in different contexts and different modeling processes ­ from large, data intensive models to very small models. System dynamics can be used to help solve high-stakes problems in realtime. It was developed by Jay Forrester to show how a model of the structure of a human activity system and the policies used to control it, could be used to deepen our understanding of the operation and behavior of that system. An important tool for representing the feedback structure of systems, are causal loop diagrams (CLDs). The diagrams consist of variables connected by causal links shown by arrows denoting the causal influences among the variables. The links are either positive (+) or negative (-), and this shows how the dependent variable changes when the independent variable changes. When the link is positive, it means that if the cause increases, the effect increases above what it would otherwise have been. If the cause decreases, the effect decreases in below that it would otherwise have been. If the cause increases, and the effect decreases below what it would otherwise have been, and if the cause decreases, and the effect increases above what it would otherwise have been, the link is negative. A loop identifier highlights the important loops, and indicates whether the loop is a positive (reinforcing) or negative (balancing) feedback. The identifier circulates in the same direction as the loop to which it corresponds. For the modeling and simulation model below, the tool PowerSim® Studio Academic 2003 was used. There are specific diagramming notation for stocks and flows in system dynamics, where stocks are represented by rectangles, and inflows and outflows are represented by pipes (arrows) pointing into and out of the stock, respectively. Valves control the flows, while clouds represent the sources and sinks for the flows.

32



The Single Vulnerability Problem: "Modeling the Lifecycle of Software-based Vulnerabilities"
Introduction to the Model "Many of the contributing factors to computer security problems are non-technical in nature ­ that is, they are dependent upon human and organizational actions and interactions in the political, social, legal, and economic realms. However, much of the research in computer security has had a predominantly technical focus. This paper represents a first attempt at using the concepts of system dynamics to model some of the human and organizational actions and interactions that impact the software vulnerability lifecycle. It represents the relationship over time between the discovery of security vulnerabilities (i.e., flaws) in software, and the occurrence of computer security incidents based on the exploitation of those vulnerabilities by attackers. Although our initial model relies on several simplifying assumptions, it points the way towards richer and more comprehensive models that can increase our capabilities and understanding in ways not possible through traditional computer security research approaches" (Wiik, Gonzalez et al. 2004). Before we show the model, we would like to give a short description of the "host life cycle" and the "single vulnerability lifecycle" described by (Arbaugh, Fithen et al. 2000; Wiik, Gonzalez et al. 2004). Computer systems oscillate between three different states, considering vulnerabilities. This is what is called the "host lifecycle". The three different states are hardened, vulnerable, and compromised. A host is hardened when all security relations are installed, typically installed with patches. The host enters a vulnerable state when at least one security related correction has not been installed. If the host is successfully exploited, it eventually enters the compromised state. The only state that is safe is the hardened state, and this is where system administrators want to keep their systems.

· Figure 9: Host life cycle. (Arbaugh, Fithen et al. 2000)

The "vulnerability life cycle" has several states. We refer to Figure 1. The states are: Birth ­ the flaws creation (programmers make mistakes or have malicious intensions).
33



Discovery - someone discovers that the product has a flaw. Disclosure - discoverer reveals details of the problem to a wider audience. Correction - release of correction to the flaw, from vendor or developer. Publicity - vulnerability known on a large scale, once the disclosure gets out of control. Scripting - simplification of intrusion techniques, which exploit the vulnerability. Death ­ when the number of systems the vulnerability can exploit shrinks to insignificance.

With this and the chapter "The Threat to Information Security" in mind, we present the SD model in the next section.

The Model The model is divided into two parts, one attacking part, and one defending part. The attack sector Advanced hackers are the only ones that have knowledge to attack in the beginning, so the first attacks, on a single vulnerability, typically come from advanced hackers. Such great skills are very rare. After gaining more knowledge of the vulnerability, scripts are developed by these advanced hackers, and through the hacker community, the scripts spread to hackers with less knowledge. Therefore, the scripts result in more potential hackers, and an increase in attack frequency for each hacker. See figure 10.

· Figure 10: The attack sector.

34



The defense sector Figure 11 considers patching as the main defense mechanism. For a large number of hosts there is often a long delay to become patched, and for some hosts patching is never considered. However, the delay time decreases if the perceived threat is high. Publicity and awareness of increasing numbers of intrusions have the effect that administrators patch their systems quicker. This leads to more hardened hosts, which again affects the hackers that find fewer targets.

· Figure 11: The defense sector

Problems with patching Patch management is tough because there are too many patches and not enough time. Exploits to announced vulnerabilities are also materializing faster. Both clients and servers are attack targets, and the vulnerabilities are with Microsoft, Unix, and Linux. The biggest mistake that companies make is leaving out the processes. People are looking for a tool that will save all their problems, but it is not just about the tool. To get less vulnerable, one needs diligent monitoring for new patches coupled with detailed evaluation, testing, deployment and validation that a team or individual manages. Before a patch management process can be installed, the following pieces must be in place: network inventory, change management, configuration management, asset management, formalized record keeping, and an understanding of costs, prioritization guidelines, and maintenance and communications plans. Companies have different procedures in patch management, and some are better than others. The time before patching varies a lot. We believe that Pitney Bowes is a good example of patch management: the client desktops are given a risk profile from 1 to 5, where 5 are the clients that must be the most secure. The desktops that are rated a 5 must therefore be patched in less than 24 hours. The worst security incidents have taken
35



from 1,000 to 1,500 person-hours to correct, but the time is now down to 75 hours (Fontana 2003). Agder University College is doing their patching about every two weeks on their Windows servers. Nevertheless, they keep an eye on what is happening, and if a new important patch is coming in, it will be installed as soon as the security experts are sure that it will not make any problems.

Model discussion Critical and substantial variables and constants Let us look at the constant "Delay to patch" in the model. This constant affects the variable "Actual patching delay" together with "Perceived threat". The definition of "Actual patching delay" is as follows: 'Delay to patch'*(1-'Perceived threat') Initially "Delay to patch" is set to 12 months. This is probably a good estimate: "The most compelling conclusion from this research, however, is the surprisingly poor state in which administrators maintain systems. Many systems remain vulnerable to security flaws months or even years after corrections become available." (Arbaugh, Fithen et al. 2000) The release of the patch can vary in relation to the vulnerability's publicity, and vendor's effort. However; "- Nachi, Klez. Lovsan, SoBig, BugBear, Swen, Blaster and Yaha ­ represent only a sampling of the most prevalent worms and viruses that slithered into corporate networks this fall. But they all have one thing in common: Patches were readily available before most damage had been done." (Fontana 2003)

36



Rate of attacks versus intrusions
host/m o 2,500 2,000 1,500 1,000 500 0 01 Ja n 01 Jul 2004 01 Jan 01 Jul 2005 01 Ja n Attack s Intrusion ra te

Non-commercial use only!

Number of hardened hosts
host 800,000 600,000 400,000 200,000 0 01 Ja n 01 Jul 2004 01 Ja n 01 Jul 2005 01 Jan

Non-commercial use only!

· Figure 12: "Delay to patch" is 12 months

We look at the graphs in Figure 12 "Rate of attacks versus intrusions" and "Number of hardened hosts" with "Delay to patch" set to 12 months. The model shows that most attacks happen before the majority of hosts are hardened, and approximately 4 months after disclosure. If we decrease the time "Delay to patch" to 2 months, as shown in Figure 13, we will see an enormous effect on the graphs. The result is that the majority of hosts are hardened before the attack wave comes, and the intrusion rate is therefore very small.

37



Rate of attacks versus intrusions
host/m o 150 100 50 0 01 Ja n

Attack s Intrusion ra te

01 Jul 2004

01 Jan

01 Jul 2005

01 Ja n

Non-commercial use only!

Number of hardened hosts
host 1,000,000 800,000 600,000 400,000 200,000 0 01 Jan 01 Jul 2004 01 Ja n 01 Jul 2005 01 Jan

Non-commercial use only!

· Figure 13: "Delay to patch" is 2 months

Clearly, the patching process matters. The question is how organizations should manage their patching process (Fontana 2003). If we look at the graph "Hacker community with script" in Figures 14 and 15, it also differs in result of hackers, considering the two states of "Delay to patch". In both situations, there is an s-shaped curve, typical for the "word of mouth" effect. At the end of "simulation time", the two graphs are flattening off at respectively 1,000 hackers and 400 hackers.

38



Hacker community with script
hack e r 1,000 500 0 01 Ja n

01 Jul 2004

01 Ja n

01 Jul 2005

01 Jan

Non-commercial use only!

· Figure 14: "Delay to patch" is 12 months

Hacker community with script
hack e r 400 300 200 100 0 01 Ja n 01 Jul 2004 01 Ja n 01 Jul 2005 01 Jan

Non-commercial use only!

· Figure 15: "Delay to patch" is 2 months

This means that fewer hackers will have the "script" when the "Delay to patch" is two months. Because the patch came earlier, the "Perceived availability of targets" decreases, and not that many hackers will therefore bother to gain the script. That does not mean that the availability of the script is poor. What our searches show, is that the hacker community is growing (Appendix C and D). There are more bulletin boards, publications and web sites than ever. Most of these media have direct links to attacking tools or "hacking information". We believe that a publication of an attacking tool, would give a "jump in attacks" on that vulnerability, because of the "script kiddies".

39



To show the devastating effect of the attack tool, we will examine the constants "attack frequency with tools", and "attack frequency with no tools". Initially, the constant "attack frequency with tools" is set to 1 host/(wk/hacker), and "attack frequency with no tools" is set to 1 host/(mo/hacker). See Figure 15.

The "attack frequency with tools" is of course largest (four times the "attack frequency with
no tools"), but rather moderate compared with what attack tools can accomplish. "In the past, intruders found vulnerable computers by scanning each computer individually, in effect limiting the number of computers that could be compromised in a short period of time. Now intruders use worm technology to achieve exponential growth in the number of computers scanned and compromised. They can now reach tens of thousands of computers in minutes where it once took weeks or months." (Pethia 2001). Because of this, it would not be "wrong" to experiment larger numbers of frequency. In Figure 17, we set "attack frequency with tools" to 100 host/(mo/hacker), which still is moderate.

Rate of attacks versus intrusions
host/m o 2,500 2,000 1,500 1,000 500 0 01 Ja n 01 Jul 2004 01 Jan 01 Jul 2005 01 Ja n Attack s Intrusion ra te

Non-commercial use only!

· Figure 16: "attack frequency with tools" is set to 1 host/(wk/hacker)

Rate of attacks versus intrusions
host/m o 30,000 20,000 10,000 0 01 Ja n Attack s Intrusion ra te

01 Jul 2004

01 Jan

01 Jul 2005

01 Ja n

Non-commercial use only!

· Figure 17: "attack frequency with tools" is set to 100 host/(mo/hacker)

40



After 4 months, we see that attacks grow above 30,000 host/mo, compared to 2,500 when the "attack frequency with tools" was 1 host/(wk/hacker) (Figure 16), and that intrusion rate grow above 10,000 host/mo, compared to 1,500 host/mo. This tells us that the effectiveness of an attacking tool can be tremendous.

Proposals to extend the model The model assumes that after a while, a sophisticated hacker produces a script for this special vulnerability and that a larger scale of hackers starts to use the script. The definition of "script" is diffuse. If we use the term as defined in (Arbaugh, Fithen et al. 2000), it "applies to any simplification of intrusion techniques that exploit the vulnerability, such as cracker "cookbooks" or detailed descriptions on how to exploit the vulnerability". This means that the script is not necessarily a sophisticated attack tool. This would lead to less activity on the vulnerability, because people would not have the skill enough, or they would not care to use the cookbooks, or descriptions to exploit the vulnerability. The authors define the script as an attack tool: "We did not include the process of further improved attack tools in this model but have kept it on an aggregated level with one type of automated tool that we call script". In reality, there are not developed attack tools for all vulnerabilities. We believe that only for "popular" vulnerabilities, it would be created sophisticated attack tools, leading to more interest from hackers with less knowledge, and therefore more attacks. In addition, if there are not created sophisticated attack tools, there will not be as many attacks, according to the model. Since this model always assumes that there will be created a script for the vulnerability, perhaps it is suited for "popular" vulnerabilities. Therefore, a more precise definition of "script", or split in definition, could extend the model. E.g., one could distinguish between vulnerability that has sophisticated tool(s) to exploit, and vulnerabilities that have not.

The Multiple Vulnerability Problem
Hacker tools often combine exploits of different vulnerabilities. The automation of an exploit creates a tremendous growth in exploits. Consequently, a single script can actually influence the life cycle of several vulnerabilities simultaneously. Often, exploiting one vulnerability intensify the exploit of another vulnerability. This could be one reason for why the exploitation cycles of various vulnerabilities overlap, as shown in Figure 18.

41



· Figure 18: Multiple Vulnerabilities (© 1998-2003 by Carnegie Mellon University)

Another reason would be that within the hacker community there is competition of whom is the "cleverest". Therefore, various vulnerabilities are used in the competitions between the hackers. Defenders will experience this as waves of attacks. More and more worms are using multiple methods of propagation. They are attempting to exploit multiple vulnerabilities in widely used Internet services, which means that they can spread at a faster rate (Magee 2003). A model describing multiple vulnerabilities would include many of the same variables as the single vulnerability model. However, it should also have some extra factors as well. This can e.g. be to have different vulnerabilities in different variables, and possibly with a patch for each of them since one can have many vulnerabilities and only some of them may get patched (but if a person gets aware of his/her vulnerabilities, he/she would probably patch everything, and not just install one or two patches). The different vulnerabilities should also have different start-up periods in a model, since all of the vulnerabilities will not start at the same time. The model could also include recruitment to the hacker community, how the hackers pick various vulnerability types, and the research and development pipeline in the hacker community.

42



Denial of Service (DoS) Attacks and Distributed Denial of Service (DDoS) Attacks
Denial of Service
The first publicized example of a denial of service attack against an Internet host, happened in September 1996, and the computers of Public Access Networks Corporation (Panix), a New York ISP. The method used was SYN flooding; a type of packet flooding attack described closer below. Denial of service (DoS) is a type of attack that is designed to hang or crash a program, or bring down the entire system, by flooding it with useless traffic. The goal of exploits that shut down services is typically to knock out a server, router, or other system so that users can no longer access the process or service it supports. Attacks that exhaust system resources have the situation where the service may stay up, but users cannot reach it because the system's resources are overwhelmed, typically by bogus requests. This can be resources such as bandwidth, CPU cycles, and memory. However, the basic idea is the same for all DoS attacks: to flood the target with so much stuff that it shuts down. Packet flooding and logic attacks are two common methods for initiating a DoS attack: Packet flooding attacks; are aimed at overwhelming the target with spurious traffic and overloading it. The receiver gets exploded with multiple connection requests, but he fails to send the necessary acknowledgements in return. The result is half-open connections that tie up resources and prevent legitimate connections from being made. Consequently, any legitimate traffic, which becomes a fraction of the total traffic, is denied service. SYN flood attacks, Internet Control Message Protocol (ICMP) flood attacks, Smurf attacks, Trinoo, Tribe Flood Network (TFN), Shaft, Stacheldraht, Trinity, Targa3, and FloodNet are examples of attacks that involve packet flood exploits. Logic attack; the use of malformed packets are typically geared toward crashing a service. It exploits known software bugs on the target system in an effort to take it offline. The attacks exploit errors in TCP/IP stack by sending typically formatted packets. Buffer overflow is a common result of a logic attack. It occurs when too much data is written to a buffer, which can result in overwriting of data in adjacent buffers, alteration of data, file damage, and system crashes. Examples of malformed packet attacks are Ping of Death, TearDrop, NewTear, Bonk, Syndrop, Chargen, WinNuke, Land, and Joltz.

-

· Table 4: Denial of service attacks detected (by percent)

Year 1998 1999 2000 2001 2002

DoS attacks 31 27 36 40 42
43



The number of DoS attacks is increasing, from 31% in 1998 to 42% in 2002 (Table 4), and DoS attacks are a big part of Web site incidents, as seen in Figure 19.

· Figure 19: Web site incidents (CSI/FBI 2003 Computer Crime and Security Survey)

In 2002, denial of service attacks led to big financial losses. Theft of proprietary information was the attack type with the worst losses ($70,195,900), while DoS attacks came on a second place, with a loss of $65,643,300.

Distributed Denial of Service
A DDoS attack has the same impact on a target as a DoS attack. The difference between them, is that a DDoS attack originates from multiple machines on the Internet, while it originates from a single machine in a DoS attack. Distributed denial of service attacks are based on many of the same mechanisms as DoS attacks, but they are more complex and have the potential to do damage that is more widespread. Bruce Schneier compares DDoS attacks with a pizza delivery attack: Alice does not like Bob, so she calls a hundred pizza delivery parlors, and has a pizza delivered to Bob's house at 11 p.m. from each one of them. The pizza parlors are all demanding their money at 11. They are the victims, and the attacker is nowhere to be seen (Schneier 2000). The first widely publicized DDoS attack occurred in 2000, when the hacker "Mafiaboy" launched an assault using easily accessible tools from the Internet. Yahoo, CNN, Amazon, eBay and eTrade were among the victims of the fallout. The FBI estimated that it took about 50 machines to take down Yahoo. This does not mean that the tools used are sophisticated, or that the hacker is skilled.
44



To do DDoS attacks, the attacker first chooses the exploit and the attack type. He/she can download the software from the Internet, and compile the program. The attacker then enlists zombie systems to form an army of unwitting participants. To find these, the attacker scans the Internet for vulnerable IP addresses with a scanning tool (an RPC scanner program). Most machines will be immune to the scripts because of firewalls, but that still leaves hundreds of machines that is successfully hacked. After doing this, the attacker downloads a daemon (a program that executes command strings from the master system, onto the zombies). This gives the hacker complete control, and he/she should put a master control program on every 20th machine. When the command sequence is sent from the master system, the zombies will attempt to execute the attack, by for example bombarding the target with packets. See Figure 20.

· Figure 20: The DDoS Deluge (Clark 2003)

DDoS attacks will become more difficult to detect as they evolve, and they will be able to compromise more and more systems within shorter windows of time. There is also an increasing availability of more sophisticated automated tools for scanning and deployment, which means that the DDoS attack tools are becoming easier for less skilled attackers to launch. Worms are not typically intended to be mechanisms for DoS or DDoS attacks, but they can result in serious denial of service conditions. When a worm is launched, it can spread to systems that were not deliberately selected as targets. There are many types of DDoS attacks that can be launched, and the German hacker "Mixter" has written a couple of them: TFN (Tribe Flood Network), and its sequel, TFN2K. See more about DDoS tools in Table 5 (page 59-60). Attacks rates of DoS/DDoS attacks are alarming: 500 packets per second can over-whelm a commercial server. And it takes 14,000 packet per second to disable a server with
45



specialized firewall designs. In 2001, it was suggested that 4,000 DDoS attacks happen across the Internet each week, and the number is probably far higher now. A study estimated that 2.4 percent of all attacks could break through highly tuned/optimized firewalls (Sigmond and Kaura 2001). There are three aspects to tackling DDoS: detection, identification of the source, and solution. The biggest challenge of reliable detection is separating normal traffic from spurious traffic, and several algorithms are used for detection. The identification of the source involves backward tracing the path of attack and identifying the key devices that are responsible for the spurious traffic, like routers and switches. The solution may involve filtering the traffic and/or the complete/partial shut down of a certain network path.

A DoS Case
The two German hackers, "Mixter" (a.k.a. Kemal A.) and "Randomizer", had a turf war going on between their hacker clubs. They were both pioneers in the making of DoS tools. As mentioned in the previous part about DDoS, "Mixter" is the writer of the attack tool TFN and its sequel TFN2K. And "Randomizer" is the writer of Stacheldracht. These are all DDoS tools. TFN was the tool that "Mafiaboy" used to take down the major Web sites in February 2000. "Mixter" and "Randomizer" were leaders of these two separate hacker clubs in Germany, and a war started up between their clubs around 1998 about the possession of IRC chatrooms (the part about "IRC Wars and Bots" describes how hackers work to gain control of IRC chatrooms (page 30)). They competed for bragging rights. "Mixter" got sentenced for computer sabotage, spying for data, and other attacks on businesses in 1998, and moved to Israel to live there for a few years. In 2000, "Mixter" got sentenced to a 6-month youth prison sentence for computer sabotage, spying for data, and other attacks on businesses in 1998. The sentence got suspended to a two-year parole period. This particular case, along with some general information about the hacking and Internet environment, is modeled in a causal loop model in the following chapter.

Causal Loop Model
To describe the causal loop model in Figure 21, we divide the model into two parts, and describe the parts separately. As one can see from Figure 21, the top-part of the model is the general part about hackers, stealing of Web sites, the effect of word of mouth, and protection of systems, shown in Figure 23. The bottom part is more specific, Figure 22. It describes the case of "Mixter" and "Randomizer"3; their turf war, which side gets the upper hand, bragging, etc., More about system dynamics and causal loop diagrams in "System Dynamics" (page 32).

3

Actually, it is the hacker groups led by "Mixter" and "Randomizer".

46



· Figure 21: DoS War

"Mixter" and "Randomizer" Figure 22 can be divided into two equal parts, one side with the case of "Mixter", and one side with "Randomizer". When we describe this part of the CLD, the "Mixter"-side is exactly the same as "Randomizer"'s side, only with their names switched. One side can be looked upon as the reflection of the other (except from the names).

47



· Figure 22: The case of "Mixter" and "Randomizer"

Figure 22 has two flows; "Mixter"'s and "Randomizer"'s research and development (R&D). These flows are involved in all three causal loops in the model. The inner causal loop, "B: One side gets the upper hand", includes the hackers' research and development, their toolkits, the effectiveness of their DoS tools, one side's possession of chatroom, and their effort in R&D. The loop is balancing because of the possession of chatrooms, which can change from side to side. The "R: Turf war" ­ loop includes the hackers' R&D, their toolkits, DoS, and effort in R&D. The tools get better and better as one side sees that the other side improves, and the loop is therefore reinforcing. The sides are competing to be better than the other, so an improvement in "Mixter"s DoS tool leads to an improvement in "Randomizer"s DoS tool, and vice versa.

48



Distribution of a toolkit, and the perception of the other's toolkit, make the "R: Bragging" ­ loop together with effort in R&D, R&D, and the toolkits. Hacker's bragging on IRC is described further in "The Hacker Environment" (page 27). The threshold affects the distribution, and the distribution affects the tools distributed on the Internet. This variable, "tools distributed on Internet", affects the other part of the model, Figure 23, which is to be described next.

Hackers and the Internet World

· Figure 23: Hackers and the Internet World

When tools distributed on the Internet increases (from Figure 22), the rate of stealing Web sites will also increase. This rate affects the number of stolen Web sites, which make a balancing loop called "Defend stolen Web sites" together with the rate of taking back Web sites. Potential hackers and w.o.m. affects the rate of spreading information about tool on stolen Web sites, and these three factors make a balancing loop because of the community saturation. The rate of spreading information is also involved in the reinforcing loop "R: Word of Mouth of script", together with the w.o.m. and hackers using tool. Effectiveness of DoS tools, Internet hacker R&D, and the tool kit level make a reinforcing causal loop over R&D war defense and attack.

49



The last two causal loops to be discussed here, are both balancing. "B: Implement defenses" includes the variables: DoS outside Mxt & Rnd, rate of protecting systems, systems protected, fraction of systems protected, and effectiveness of DoS tools. "B: Build defenses" includes the variables develop defenses and defense level as well as the variables used in the implementing of defences. The loops are both balancing because the effectiveness of DoS tools decreases as the fraction of systems protected increases. Three factors, disregarding "Tools distributed on internet", lead to an increase in the rate of stealing Web sites as they increase. These factors are fraction of systems protected, effectiveness of DoS tools, and hackers using tool.

Discussion
Discussion of CLD Most of the variables in the CLD are more or less discussed in our report, directly or indirectly, and the model shows how they affect each other. A lot of the variables in Figure 20 in comparison to a hacker turf war, is supported in our sources. There are turf wars, usually for the possession over IRC chatrooms, and thereby for bragging rights on the IRC channels (about bragging and IRC on page 27). Because the bragging is related to IRC, we feel that the name of the "Bragging"-loop does not fit in the relation where it is now. The loop involves the distribution of toolkits, and one hackers perception of the other hackers tool, which has little to do with bragging. In our opinion, the loop should have another name, and bragging should be put somewhere in relation with the possession of chatrooms. If the model was to be extended, two new variables could be included in the balancing loop "One side gets the upper hand" are "bots" ­ DoS-bots and IRC-bots. These factors can be used in relation with who gets the control of IRC chatrooms (page 30). Other factors can affect the variables in Figure 22, that are not just related with "Mixter" and "Randomizer". These factors can be other DoS tools, that other hackers than them have developed. For example, "Randomizer"'s effort in research and development will probably increase when other DoS tools than "Mixter"'s improves and gets distributed. This factor does not affect the turf war between them though, but it can improve R&D and the tools developed. The other part of the model, Figure 23, is more general and not specific related with the "Mixter" and "Randomizer" case (as mentioned earlier). We feel that this part of the model is missing at least one thing: no factors in the model are affecting the variable "Nonprotected system". It is natural that "Systems protected" would affect the number of nonprotected systems, because as the number of systems that get protected goes up, the number of non-protected systems will go down (if you ignore the introduction of new systems ­ which can be both protected and non-protected). A variable named "Systems in total" could be included in a possible extended model, because this variable would be the total of protected and non-protected systems. One can also question who are "Potential hackers using tool"? Is it people using the Internet all over the world, people with some computer skills, or people that are already

50



hackers? This is a diffuse variable, and can be interpreted different by different people. It can therefore be difficult to know what number would be put in here. The stealing of Web sites is often described in relation with phishing (referring to the part about phishing page 24), and does not necessarily have anything to do with a denial of service war. Because of this, the part about stealing Web sites can after our opinion be considered misplaced and do not need to be included in this model at all. Tools distributed on the Internet could therefore e.g. as well be affecting the word of mouth of tools directly, and/or the Internet hacker research and development.

DoS Attacks and DDoS Attacks As we were finding information about DoS and DDoS, we believed that some of the sources used DoS as a collective term of DoS and DDoS (only DoS was mentioned in statistics and not DDoS). When we look at Table 4, we see that the number of DoS attacks increased from 31% in 1998 to 42% in 2002. A reason for this can be the introduction of DDoS attacks. The table shows that the numbers went down to 27% in 1999, compared to 1998, but went up again to 36% in 2000. 2000 was the year of the big attacks on Web sites, and it was also the year when DoS attacks increased with 33% (from 27 to 36 percent). This makes a lot of sense, because it was at the same time as the introduction of DDoS tools. After DDoS got known, hackers knew the impact that these attacks could make, and the DDoS tools were further developed and used. The future use of DDoS tools will probably depend on the research and development of DDoS tools and other attack tools. It was also estimated that 2.4 percent of all attacks could break through optimized firewalls. This number is from 2001, and a lot of things have changed since then. People are more aware of the problems of worms and other kinds of attacks than they used to, they are installing firewalls, anti-virus software, and are getting better at patching. But at the same time, the attack tools are getting more sophisticated. These two things are factors which affects a possible "new factor"; successful attacks. This could make a starting point in a new system dynamics model, or in an extension of the model already made (Figures 10 and 11). A problem in our research was to find information about the "Mixter" and "Randomizer" case. We heard a story from professor Jose J. Gonzalez, that Timothy Shimeall from CERT/CC had told him (on the group modeling workshop February 16-20, 2004 at SEI/CERT, Pittsburgh), about a turf war between these two German hackers. This story seemed impossible for us to find on the Internet or in books, except from small bits and pieces. At "Mixter"'s homepage, he describes himself as a white-hat hacker with no harmful intentions, which contradicts with what other people has said about him (Timothy Shimeall, among others). This can be a natural thing, because he wants to present himself in the best possible way. We found no information about the turf war between the two clubs that they were members of, or that they were leaders of the clubs. Because of this, we question some of the things that Tim Shimeall has said, and wonder if some of the story is guessed upon on the basis of vague facts. For example, in his story he told that "Mixter" and "Randomizer" were leaders of each of their hacker clubs, while the first sentence of "The Hacker
51



Environment" (page 26) says the opposite: "The hacker culture does not have any leaders". But because they are admired because of their skills and achievements in making of DoS tools, they are probably looked upon as heroes by other hackers. Shimeall also said that "Mixter" had to flee to Israel, while we found a source (Wegner 2000) where "Mixter" said in an interview that he was going to Israel to work, so he was not fleeing from the FBI. Still, there is no doubt that the causal loop model over the case presents a very realistic situation. There are often turf wars between hacker clubs, and the wars often happen in order to possess IRC chatrooms. Our problem is that we can not verify the story about the hacker war.

52



Conclusion
Some of the results we have found were pretty much as expected. The number of hosts on the Internet is constantly increasing, and the number of attacks and vulnerabilities reported to CERT/CC has increased each year. The number of incidents reported was 6 in 1988, while it was 137,529 in 2003. Reported vulnerabilities has gone up from 171 in 1995 to 3,784 in 2003. The only deviation from this trend, is that reported vulnerabilities was higher in 2002 (4,129 vulnerabilities) than it was in 2003. This result came as a surprise to us. We have also mapped some common vulnerabilities and attacks methods. There are often vulnerabilities because of default software installations, ineffective use of authentication, patches that are not applied, traffic that is not analyzed, backups that are not maintained and verified, and the lack of protection against malicious code. Malicious code, spoofing, denial of service, probes and scans, account compromise, and packet sniffing are some of the most common attack tools, while social engineering, insider attacks, dumpster diving, the use of hardware and software tools, reverse intent, and phishing are some of the most used methods of attacking. An interesting trend is that while the attack tools are becoming more and more advanced, the technical knowledge of the hackers does not need to be as high as it used to. Earlier, the hackers were highly intelligent people who wrote the tools themselves, but nowadays the hackers are mostly script kiddies who use tools that they find on the Internet. Attack tools are easy to find, and they are easy to use. 90% of the hackers are probably script kiddies, less than 10% are competent programmers who modify existing tools, and less than 1% are stars who write new tools. Still, not all hackers are bad. They can be divided into two groups; white-hat (ethical) hackers and black-hat hackers (who take advantage of the break-in). IRC wars between hacker groups are common to gain control of IRC chatrooms, and then keep control against attacks from rival gangs. Hackers share and get information through hacker clubs, publications, conventions, bulletin boards and newsgroups, Web sites, meetings, and through chatrooms. And the numbers of hacker Web sites and bulletin boards are increasing. An estimate is that about 1 out of 10,000 people engage in hacking activity, while another source says that there are about 100,000 hackers. There are different motives for why people are hacking: increased knowledge, recognition, theft of information, vandalism, blackmail, sabotage and terrorism are some examples. The single vulnerability model has led to the following findings: if we compare the variable delay to patch, when it is set to 12 and 2 months, the variance is vast. Both the attack rate and the intrusion rate go considerably down, and most of the hosts get hardened before the attack wave comes. Delay to patch also affects the hacker community, because fewer hackers will have script when the delay to patch is set to 2 months. In our simulation, when delay to patch is set to 12 and 2 months, the graphs are flattening out at 1,000 and 400 hackers with script, respectively. This proves how much patch management matters. Another finding in the model was that the effect of the attacks and intrusion rate could be extremely effective as the attack frequency rose from 1 host/(mo/hacker) to 100

53



host/(mo/hacker). Attacks grew from 2,500 host/mo to above 30,000 host/mo, and the intrusion rate grew from 1,500 host/mo to 10,000 host/mo. There was hardly any information to find about multiple vulnerabilities, so we found out that a lot of research remains to be done here. Denial of service attacks and distributed denial of service attacks are becoming more and more dangerous, and some of these attacks have proved that they can do enormous damage to major Web sites. In 2002, the financial losses because of DoS attacks, were $65,643,300, and the number of attacks have increased from 31% in 1998 to 42% in 2002. It is also more difficult to protect oneself against the attacks than ever before. Our conclusion when it comes to the case about "Mixter" and "Randomizer" is that we can not validate the story given from Timothy Shimeall, and our opinion is that if those two hacker clubs had a big turf war, it would probably have been publicized somewhere. Nevertheless, hacker wars (in general) are contributing factors for the development of hacker tools, because of the need to prove their skills, which is shown in Figure 21.

54



Recommendations
In this chapter, we wish to give some suggestions of further work. Model the problem with multiple vulnerabilities. The model could include recruitment to the hacker community, how the hackers pick various vulnerability types, the research and development pipeline in the hacker community, etc. Multiple vulnerabilities is a hard subject to find information about, and a lot of research work remains to be done. Discuss the problem of patching and the protection of systems as new attack tools are emerging. Find out what would happen if a billionaire fundamentalist were to fund an organized activity involving hundreds of brilliant computer scientists for the purpose of identifying dormant system vulnerabilities, develop advanced exploit tools, and roll out a series of devastating attacks toward some neuralgic point of the global information network (without advanced notice). A system dynamics model could illustrate this case. Research more about why people/organizations do not report their vulnerabilities, and if the trend is about to change since the numbers of reported vulnerabilities decreased from 2002 to 2003. Are organizations only afraid of bad publicity, or are there other reasons? Hacker wars is an interesting theme, but since our story was based on a story we could not find any evidence on, it could be an alternative to find and discuss a hacker war that is easy to find information about and to go into. This could be a hacker war between clubs or between countries, and one suggestion is to discuss both of these cases, and compare them.

58



DDoS Tools and Attacks
· Table 5: Known DDoS Tools (http://www.riverheadnetworks.com/re/known_ddos_tools.html)

Name of Tool Trinoo

Flooding Capabilities UDP

Short Description Only initiates UDP attacks to random ports. Communication between master and slave is via unencrypted TCP and UDP. No IP spoofing. Uses UDP ports 27444 and 31335. Uses IP spoofing. Uses ICMP Echo reply packets to communicate between zombie and master. Uses encryption for communications (but not for ICMP heartbeat packets that zombie sends to master) and has an auto-update feature (via rcp). Has ability to test (via ICMP Echo) if it can use spoofed IP addresses. Uses encryption for communications (but not for ICMP heartbeat packets that zombie sends to master) and has an auto-update feature (via rcp). Has ability to test (via ICMP Echo) if it can use spoofed IP addresses. Same as TFN - but the slave is silent so difficult to spot. No return info from slave. Zombie to master communication is encrypted. Can spoof IP addresses Uses the backdoor hole of snmpXdmid and uses UDP port 530. NT specific zombie. No spoofing capabilities. Sends ICMP 1500 octet packets marked as fragments. Uses UDP ports 18753 and 20433. Has optional IP spoofing capabilities (needs root). Can set ICMP/UDP packet size. Usually uses TCP port 12754 but can use any port. Master connects via telnet to zombie. Communication between zombie and controller is not encrypted. The target gets hit by ACK packets and sends TCP RST to non-existent IP addresses. Routers will return ICMP unreachable causing more bandwidth starvation. Can spoof IPs and do IP flooding Ramen is a worm that propagates by using a newly compromised system to scan Class B (/16) wide address spaces, searching for port 21 (FTP)
59

TFN Stacheldracht v4

UDP, ICMP Echo, TCP SYN, Smurf UDP, ICMP, TCP SYN, Smurf

Stacheldracht v2.666

UDP, ICMP, TCP SYN, Smurf, TCP ACK, TCP NUL

TFN 2K (Tribal Flood Network) FAPI

UDP, ICMP Echo, TCP SYN, Smurf UDP, TCP SYN, TCP ACK, ICMP

Carko (Stacheldraht UDP, ICMP, TCP SYN, v1.666 + antigl + Smurf, TCP ACK, TCP yps) NUL Freak88 ICMP

Shaft

UDP, ICMP, TCP SYN

Mstream

TCP ACK

Blitznet Ramen

TCP SYN Multicast



and looking for new vulnerable hosts. SYN scanning performed by Ramen can disrupt network traffic when scanning the multicast network range. Targa ANY Works by sending malformed IP packets known to slow down or hang up many TCP/IP network stacks. Will only work on a multicast enabled network. Similar to Mstream. Stick uses the straightforward technique of firing numerous attacks at random, from random source IP addresses to purposely trigger IDS events. Stick is a DoS tool against IDS systems.

Spank Stick

Multicast Any

Trank Omega NAPHTA TCP ACK, UDP, ICMP, IGMP TCP Can spoof IPs and has a chat option between attackers Naptha attacks exploit weaknesses in the way some TCP stacks and applications handle large numbers of connections in states other than "SYN RECVD," including "ESTABLISHED" and "FIN WAIT-1." Listens to TCP port 33270. When idle it connects to Undernet IRC server on port 6667.

Trinity (also called MyServer and Plague) IRC bots

UDP, TCP Fragment, TCP SYN, TCP RST, TCP RandomFlag,TCP ACK, Establish, NULL ICMP, UDP

Zombie systems controlled via a central IRC channel. Sub7 Trojan used to maintain control over the zombie. Using public IIS servers as unsuspecting zombies, it sends a string of data to multiple web servers and they reflect the data to the target. Using a known IIS bug to infect Web servers, this Trojan DDoS will only attack whitehouse.org but it will utilize 225,000 infected IIS systems. It exploits a vulnerability in the Indexing Service on systems running Microsoft IIS. Utilizing an IIS hole in regards to Unicode support, this worm uses IRC as a back channel to control an army of zombies. Use a Cisco router as a zombie for an ICMP based ping attack. Worm utilzing yet another MS IIS hole. SQL with no password (default). The hacker takes over the system and uses it as part of IRC botnet to DDOS victims.

HTTPSmurf

TCP HTTP

Code Red

TCP HTTP

Power worm

TCP HTTP

Cisco Nimda SQL -- Voyager Alpha

ICMP TCP HTTP TCP HTTP

60



Explanation of terms
Activity

A group of events that occur on the Internet and relate to one another in any of several ways. A tool that searches a hard disk for viruses and removes any that are found. The process of identifying an individual or data. To copy files to a second medium (a disk or tape) as a precaution in case the first medium fails. A black-hat hacker is a hacker or cracker who breaks into a computer system or network with malicious intent. He/she takes advantage of the break-in, perhaps destroying files or stealing data for some future purpose. A buffer overflow occurs when a program or process tries to store more data in a buffer (temporary data storage area) than it was intended to hold. The extra information - which has to go somewhere - can overflow into adjacent buffers, corrupting or overwriting the valid data held in them. It may occur through a programming error (bug), and it is an increasingly common type of security attack on data integrity. Some sort of programming mistake. Online chatting provides real-time anonymous communication. IRC and ICQ are popular in the hacking community. CIAC has been providing the US Department of Energy with incident response, reporting, and tracking, along with other computer security support since 1989. A tool for representing the feedback structure of systems. Small bits of data that a web site can place on your system, and requests your browser to send them back to the web site the next time you visit. This is a malicious hacker who decrypts passwords or breaks software copy protection schemes. The art of protecting information by transforming it (encrypting it) into an unreadable format, called cipher text. Only those who possess a secret key can decipher (or decrypt) the message into plain text. Encrypted messages can sometimes be broken by cryptanalysis, also called codebreaking, although modern cryptography techniques are virtually unbreakable. Cryptography is needed to protect banking transactions, personal information, and to protect our infrastructure from infowar attacks.

Antivirus program

Authentication Backup

Black-hat hacker

Buffer overflow

Bug Chat

CIAC (Computer Incident Advisory Capability)

CLD (Causal Loop Diagram) Cookies

Cracker

Cryptography (crypto)

61



Daemon

A daemon usually provides some kind of service (e.g., e-mail, printing, telnet, FTP, and web access). It is a program running in the background (in UNIX). An attack that pits many machines against a single victim. The worlds largest underground hacking event. A technology product feature that can be used to produce undesirable behavior. An exploit whose purpose is to deny somebody the use of the service to crash or hang a program or the entire system. Fundamental unit of information that describes the aspects of network or host behavior. A device that isolates a network from the Internet. Firewalls are installed between internal (private) networks and the (public) Internet. All the traffic to and from the internal network goes through the firewall, which acts as a "gate" with virtual guards that examine the traffic. A class of hacker attack where the victim is flooded with traffic. Someone who is able to manipulate the inner workings of computers, information, and technology. Hacktivism means "hacker activism", or breaking into Web sites as part of a cause. An instant messenger service. An activity with security or survivability implications. Describing the act of compromising a system. The most popular chat program in the hacker community. The Domain Survey attempts to discover every host on the Internet by doing a complete search of the Domain Name System. Provides access to the Internet. The ISPs get together and form agreements among themselves as to how the Internet should operate. A freely-distributable open source operating system that runs on a number of hardware platforms. Malware is short for malicious software. It is software designed to damage or disrupt a system (such as a virus or Trojan horse). The Microsoft Corporation is one of the largest and most influential companies in the personal computer industry. It was founded in 1975 by

DDoS (Distributed Denial of Service) DefCon Defect (flaw)

DoS (Denial of Service)

Event

Firewall

Flood Hacker

Hacktivism

ICQ ("I Seek You") Incident Intrusion IRC (Internet Relay Chat) ISC (Internet Domain Survey)

ISP (Internet Service Provider)

Linux

Malware

Microsoft

62



Paul Allen and Bill Gates. Panix (Public Access Networks Corporation) Patch Phreaker PKI (Public key infrastructure) A New York ISP. A fix to a program bug. A person who is using a computer or other device to trick a phone system. A system of digital certificates, Certificate Authorities, and other registration authorities that verify and authenticate the validity of each party involved in an Internet transaction. An attack that only gathers information from the target system. A type of protocol that allows a program on one computer to execute a program on a server computer. A system developer does not need to develop specific procedures for the server while using RPC. The client program sends a message to the server with appropriate arguments and the server returns a message containing the results of the program executed. A computer hacker who is hired legally to infiltrate corporate computer systems for legitimate reasons. A way of performing multiple probes using an automated tools. A list of commands that can be executed without user interaction. A type of hacker with technical knowledge often less than the average computer user. He/she knows to do a little more than run pre-packaged scripts against computers hoping to break into them. A wiretap that eavesdrops on computer networks. A form of hacking that targets peoples minds rather than their computers. An example is to pretend to be from a company's computer department and call up a user asking for their password (or call up the computer support department and tell them you've lost your password). The word generally means the act of forging your identity. More specifically, it means forging the sender's IP address (IP-spoofing). This is a type of DoS attack. A SYN (synchronize) packet notifies a server of a new connection. By spoofing large numbers of SYN requests, an attacker can fill up memory on the server, which will wait for more data (that will never arrive). A method to gain useful insight into situations of dynamic complexity and policy resistance. A class of malware. Trojans are one of the leading causes of breaking into machines. They do not replicate themselves, but they can be just as destructive as a virus. One type of Trojan horse claims to get your 63

Probe RPC (Remote procedure call)

Samurai

Scan Script Script kiddie

Sniffer Social engineering

Spoof

SYN flood

System dynamics

Trojan



computer rid of viruses, but instead introduces viruses on your computer. Unix A popular multi-user, multitasking operating system developed at Bell Labs in the early 1970s. A virus is a program (or a fragment of code) that replicates by attaching a copy of itself to other programs. For a virus to be activated, the software it infects must first be run. In this context, the word "vulnerability" describes a problem that allows a system to be attacked or broken into. The problem can be a bug or common misconfiguration. Warez means pirated software (illegally copied software). These are "ethical" hackers who work with clients in order to help them secure their systems. A classical wiretap is when law enforcement eavesdrops on your phone line. This is a program that propagates itself by attacking other machines and copying itself to them. XSS occurs when a web application gathers malicious data from a user. Computers that are "owned" by hackers for the purpose of directing them against other victims. In a DDoS attack, the zombies are used to flood the victim.

Virus

Vulnerability

Warez White-hat hackers

Wiretap

Worm

XSS (Cross site scripting) Zombie

64



Abbreviations
Anon ACK AOL ATM BBS BIND Bot CCC CERT/CC CIAC CLD CPU CSI DDoS DNS DoS EIM FAA FBI ICMP ICQ ID IGMP IP IRC IRT ISC ISP LOD OP Panix Perl PKI R&D RPC RST SD SEI SYN TCP TCP NUL TFN UDP VPN WAP w.o.m. XSS Anonymous Acknowledgement America Online Asynchronous Transfer Mode Bulletin Board Systems The Berkeley Internet Domain Robot Chaos Computer Club Computer Emergency Response Team Coordination Center Computer Incident Advisory Capability Causal loop diagram Central processing unit Computer Security Institute Distributed Denial of Service Domain Name System Denial of Service Employee Internet Management Federal Aviation Administration Federal Bureau of Investigation Internet Control Message Protocol "I Seek You" Identification Internet Group Management Protocol Internet Protocol Internet Relay Chat Incident Response Team Internet Domain Survey Internet Service Provider Legion of Doom Operator Public Access Networks Corporation Practical Extraction and Report Language Public key infrastructure Research and development Remote Procedure Call Reset System Dynamics Software Engineering Institute Synchronize Transmission Control Protocol No flags Tribe Flood Network User Datagram Protocol Virtual Private Network Wireless Application Protocol Word of mouth Cross site scripting

65



Appendix
The appendixes are arranged in order of the date they are written. They are memos to our teaching supervisor, and meant as background information to the modeling discussion. The appendixes are listed as following: Appendix A (KEB&SS)Searching for vulnerabilities040116.doc Appendix B (KEB&SS)Hacker Information040122.doc Appendix C (KEB&SS)Hacker Information040127.doc Appendix D (KEB&SS)Hacker Information040204.doc Appendix E (KEB&SS)TeenageHackers040225.doc Appendix F (KEB&SS)Blaster and blackout040225.doc Appendix G (KEB&SS)MixterAndRandomizer040308.doc Appendix H (KEB&SS)DoSAndDDoS040315.doc Appendix I (KEB&SS)DoSandDDoS040323.doc

66



Appendix A (KEB&SS)Searching for vulnerabilities040116.doc
Kjetil Eiklid Braathen, Silje Salte Agder University College Faculty of Technology and Science Institute of ICT Groosveien 36 N-4876 Grimstad Norway

HiA

Searching for vulnerabilities
To: From: CC: Date: Re:

Jose J Gonzalez

Kjetil E Braathen, Silje Salte Johannes Wiik January 16, 2004
Vulnerability types

Organization of this memo:
ORGANIZATION OF THIS MEMO: INTRODUCTION DISCUSSING PAPERS, FINDING VULNERABILITY TYPES OVERVIEW OF ATTACK TRENDS, CERT® COORDINATION CENTER (UNKNOWN 2002) Abstract Methodology Results Personal conclusions SECRETS & LIES ­ CHAPTER 18: VULNERABILITIES AND THE VULNERABILITY LANDSCAPE (SCHNEIER 2000) Abstract Methodology Results Personal conclusions THE TEN MOST CRITICAL WEB APPLICATION SECURITY (OWASP 2003) Abstract Methodology Results Personal conclusions NETWORK IN-SECURITY (TANNER 2003) Abstract Methodology Results Personal conclusions
67



CONCLUSION SUMMARY SIGNATURE REFERENCES SOURCES SEARCHED KEYWORDS THIS MEMO

Introduction
The purpose is to understand and map the types of typical vulnerability threats. We will use this in further study. We have studied the links recommended in the e-mail you sent us, and we found relevant information to our topic. We have also searched the Internet, and we have looked through articles, reports and papers by CERT/CC staff.

Discussing papers, finding vulnerability types
Through this memo, we have divided the sections into the papers or texts we have found interesting. Overview of Attack Trends, CERT® Coordination Center (Unknown 2002) Abstract The CERT Coordination Center has been observing intruder activity since 1988. Much has changed since then, from our technology to the makeup of the Internet user community, to attack techniques. In this paper, we give a brief overview of recent trends that affect the ability of organizations (and individuals) to use the Internet safely. Methodology In this paper the author lists up six trends in exploiting vulnerabilities. For each trend, the author gives an explanation. The six trends are automation, increasing sophistication of attack tools, faster discovery of vulnerabilities, increasing permeability of firewalls, increasingly asymmetric threat and increasing threat from infrastructure attacks. After this, the author concludes that the trends seen by CERT/CC indicate that organizations relying on the Internet face significant challenges to ensure that their networks operate safely and that their systems continue to provide critical services, even in the face of attack. In the appendix of the paper there is a list of sources for more information about the problems. Results We now know more about infrastructure attacks like "distributed denial of service" (DDoS), worms, attacks on the Internet Domain Name System (DNS) and The Berkeley Internet Domain (BIND), and attacks against or using routers.

68



Personal conclusions This paper raises readers' awareness of current trends in attack techniques and tools. Our goal was to find types of vulnerabilities, and especially attack methods, which this paper gives us examples of. The links in the appendix will be interesting in the further study. Secrets & Lies ­ chapter 18: Vulnerabilities and the Vulnerability Landscape (Schneier 2000) Abstract To successfully make use of the vulnerabilities that an attacker has found, he has to find a target, plan the attack, do the attack, and get away. It's not enough for a potential criminal to find a flaw in the encryption algorithm for the ATM network. He/she has to get access to the communications line, know enough about the protocols to create a bogus message letting him/her steal money, steal the money, and get away with it. Methodology First, Schneier looks at attack methodology which tells us five steps to a successful attack. Then he describes countermeasures, which are methods to reduce vulnerabilities. Next, he tells about the vulnerability landscape and breaks it down into four broad categories that are all described closer. Finally, Schneier explains how to rationally apply countermeasures. Results There are three parts to an effective set of countermeasures: protection (cryptography, firewalls and passwords), detection (intrusion detection systems) and reaction (a login system that lock users out after three failed login attempts). One of the five steps to a successful attack: is to identify vulnerabilities. Schneier breaks down the vulnerability landscape into four broad categories: the physical world (locks, guards), the virtual world (firewalls, authentication, end-to-end data encryption), the trust model (who to trust within an organization), and the system's life cycle (when and where to conduct the attack). Personal conclusions We like the organization of the vulnerability landscape into categories, but would wish that there would be more concrete examples of vulnerabilities, and not just examples of the countermeasures. For example, the virtual security section is described very briefly, it tells that countermeasures that are needed are firewalls, strong authentication and end-to-end encryption, but it doesn't say anything about any concrete vulnerabilities. The Ten Most Critical Web Application Security (OWASP 2003) Abstract The top 10 list was created to focus government and industry on the most serious of web application vulnerabilities. Organizations should understand and improve the
69



security of their web applications and web services, and the consequence of an attack can be devastating. Methodology There is first a list over the top ten vulnerabilities. Then, the author goes thoroughly into each one of these with a description, environments that are affected, examples and references, how to determine if you are valuable, and how to protect yourself. Results The top vulnerabilities in web applications are: invalidated parameters, broken access control, broken account and session management, cross-site scripting (XSS) flaws, buffer overflows, command injection flaws, error handling problems, insecure use of cryptography, remote administration flaws, and web and application server misconfiguration. Other vulnerabilities that were considered for the list include unnecessary and malicious code, broken thread safety and concurrent programming, denial of service, unauthorized information gathering, accountability problems and weak logging, data corruption and broken caching, pooling and reuse. Personal conclusions It gives a good insight into some of the web application vulnerabilities because they are not only mentioned, but also described in depth. The conclusion also mentions other areas that were considered for the list, which we think is a good thing. Network in-security (Tanner 2003) Abstract People are more aware of the importance of security than before. This is among others because of the many worms and vulnerabilities that have been announced in Microsoft products. The industry has a tendency to introduce new technology without delivering appropriate security for it. Many companies tend to cut costs regarding to security, and there are network managers that don't install patches on their servers when software vulnerability is found. It's often an issue that it's not until people get hacked that they wished they had invested in it. Methodology The article first tells about hard security requirements. Then, we get to know about attitude changes toward security over time, and people are aware of the problem. Still, they shouldn't blindly trust the security that they buy. The next section is about reactionary security, and among others says that the security industry is part of the problem. Cutting of costs of security is the next theme, and different types of threats are mentioned in this relation. The article continues by explaining that threats aren't always external, and therefore tells about different types of internal threats. At the end, we are told that the human is the weakest link when it comes to security. People don't understand it yet. Results The vulnerabilities mentioned in this article are both external and internal threats. There is theft, like hacking into bank accounts or copying sensitive data, identity theft
70



(becoming a person), intellectual property (patents, DVDs, etc.), and brand theft (pretending to be a web site). There are also DoS, surveillance and viruses that are designed to infect a system and cause damage. Still, most security problems occur from within, and it is mostly hacking at the application level. The internal threats can be disgruntled company employees selling company secrets and opportunists running fraud operations to consumer-level users on a commercial private network. One can prevent internal attacks with audit trails, comprehensive internal security procedures and adequate user-level authentication and access to critical resources. Vulnerabilities include operating systems as well as network elements such as firewalls, Ethernet switches, WAP gateways and dial-up modem banks. VPNs and voice mail are also risks. At the application level there are examples like Web browsers and Microsoft Outlook. Other problems are IRC and instant messaging, and Java and cookies. Server software is also at risk of attack, especially where remote control applications are used. Personal conclusions This is an article that describes security issues in a good way. It describes both external and internal threats to the security, even though these threats are not further deepened, they are just mentioned briefly. Conclusion We have found some types of vulnerabilities, but we are sure we will find more, when we continue our studies, and make searches for new keywords. In the follow-up we could do new searches, and/or gather more information on the links already discovered. Summary We have studied four different texts. We now know more about infrastructure attacks like "distributed denial of service" (DDoS), worms, attacks on the Internet Domain Name System (DNS) and The Berkeley Internet Domain (BIND), and attacks against or using routers. There are three parts to an effective set of countermeasures: protection (cryptography, firewalls and passwords), detection (intrusion detection systems) and reaction (a login system that lock users out after three failed login attempts). The top vulnerabilities in web applications are: invalidated parameters, broken access control, broken account and session management, cross-site scripting (XSS) flaws, buffer overflows, command injection flaws, error handling problems, insecure use of cryptography, remote administration flaws, and web and application server misconfiguration. Vulnerabilities include operating systems as well as network elements such as firewalls, Ethernet switches, WAP gateways and dial-up modem banks. VPNs and voice mail are also risks. At the application level there are examples like Web browsers and Microsoft Outlook. Other problems are IRC and instant messaging, and Java and cookies. Server software is also at risk of attack, especially where remote control applications are used.

71



Signature
Kjetil E Braathen, Silje Salte


72



Appendix B (KEB&SS)Hacker Information040122.doc
Kjetil Eiklid Braathen, Silje Salte Agder University College Faculty of Technology and Science Institute of ICT Groosveien 36 N-4876 Grimstad Norway

HiA

Hacker information
To: From: CC: Date: Re:

Jose J Gonzalez

Kjetil E Braathen, Silje Salte Johannes Wiik January 22, 2004
Hacker information

Organization of this memo:
ORGANIZATION OF THIS MEMO: INTRODUCTION DISCUSSING PAPERS, FINDING HACKER INFORMATION PROTECTING AGAINST HACKER ATTACKS (NORRIS 1995) Abstract Methodology Results Personal conclusions SURVIVABILITY: PROTECTING YOUR CRITICAL SYSTEMS (ELLISON ET AL. 1999) Abstract Methodology Results Personal conclusions CODE-DRIVEN ATTACKS: THE EVOLVING INTERNET THREAT (GHOSH 2000) Abstract Methodology Results Personal conclusions CERT/CC STATISTICS 1988-2003 (UNKNOWN 2003) Number of incidents reported Vulnerabilities reported Personal conclusions
73



CONCLUSIONS SUMMARY SIGNATURE REFERENCES SOURCES SEARCHED KEYWORDS THIS MEMO

Introduction
The purpose of this memo is to answer the following questions: How does hacker information spread? How does hacker script spread? How does script develop? How large is the hacker environment, and how large are the segments? How big is the hacker activity? How do incidents affect hacking? How do incidents affect patching? Reference modes (time-series)? And how many vulnerabilities are reported per year?

Discussing papers, finding hacker information
Through this memo, we have divided the sections into the papers or texts we have found interesting. Protecting Against Hacker Attacks (Norris 1995) Abstract This article presents a profile of hackers and hacker clubs, their methods of communication, and specific methods of information gathering and attack. Recommended procedures and controls for countering such hacker activities are provided. Methodology The article starts by telling what a hacker is; the profile of a hacker, hacker clubs, publications, conventions and bulletin boards and newsgroups. This is the section we choose to focus on. Then, it tells about different methods of attack; social engineering, dumpster diving, hardware and software tools, and reverse intent. At the end, it explains security monitoring and recommended course of action. Results Computer systems are to be found everywhere now, and the opportunity to hack these systems has increased. Hackers use used equipment which is inexpensive and adequate to the tasks. There is no exact number mentioned of how many people are involved in hacking, so estimated numbers vary greatly from hundred serious hackers to hundreds of thousands. The hacker activity is hard to monitor because of the use of aliases. Hacker information spreads through hacker clubs, hacker publications, hacker conventions, and bulletin boards and newsgroups. Example of hacker clubs are Legion
74



of Doom (LOD), Chaos Computer Club, NuKE, The Posse, and Outlaw Telecommandos. The clubs help members work as a team to achieve goals which might be out of reach for an individual hacker, even though most members never physically meet. The publications, such as Phrack, 40Hex and Chaos Digest, provide technical information, and provide a social function. They can be received over e-mail or regular mail. Conventions are held in Europe and the US so that people can brag, tell stories and exchange information. Examples of conventions are the Chaos Congress, Hacking at the End of The Universe and HoHoCon. Bulletin board systems are the primary way for hackers and hacker clubs to communicate, even though they can be difficult to get access to. It is estimated to be about 1,300 underground bulletin boards in the US. Information found here is mostly current and state-of-the-art. Personal conclusions It says a great deal about the spreading of hacker information, about the hacker environment and hacker activity. How large the environment is, and how many people are involved, seems impossible to find out. We would also wish to mention that this article is old, and lots of things have happened since then. Survivability: Protecting Your Critical Systems (Ellison, Fisher et al. 1999) Abstract Society is growing increasingly dependent upon large-scale, highly distributed systems that operate in unbounded network environments. Unbounded networks, such as the Internet, have no central administrative control and no unified security policy. Furthermore, the number and nature of the nodes connected to such networks cannot be fully known. Despite the best efforts of security practitioners, no amount of hardening can assure that a system that is connected to an unbounded network will be invulnerable to attack. The discipline of survivability can help ensure that such systems can deliver essential services and maintain essential properties such as integrity, confidentiality, and performance, despite the presence of intrusions. Unlike traditional security measures, which require central control and administration, survivability is intended to address unbounded network environments. This paper describes the survivability approach to helping assure that a system that must operate in an unbounded network is robust in the presence of attack and will survive attacks that result in successful intrusions. Included are discussions of survivability as an integrated engineering framework, the current state of survivability practice, the specification of survivability requirements, and strategies for achieving survivability. Methodology The authors start this paper by introducing the new network paradigm, organizational integration. This new paradigm represents a shift from bounded networks with central control to unbounded networks. Next, they define survivability (as the capability of a system to fulfill its mission, in a timely manner, in the presence of attacks, failures, or accidents). In addition, they explain the environments of unbounded networks, and characterize a survivable system. At last, they discuss strategies for achieving survivability.

75



Results To maintain their capabilities to deliver essential services, survivable systems must exhibit the four key properties: resistance to attacks, recognition of attacks and the extent of damage, recovery of full and essential service after attack, adaptation and evolution to reduce effectiveness of future attacks. The traditional view of information systems security must be expanded to encompass the specification and design of survivability behavior that helps systems survive in spite of attacks. Only then can systems be created that are robust in the presence of attack and are able to survive attacks that cannot be completely repelled. Personal conclusions This is a rather old paper (1999), but still is relevant to system survivability thinking today. Questioning how much a system can tolerate from massive coordinated attacks, clearly the "four key properties" are applicable. Code-Driven Attacks: The Evolving Internet Threat (Ghosh 2000) Abstract Over the last two years (2000) the intrusion threat to computer systems has changed radically. Instead of dealing with hackers, we are now faced with defending our systems against code-driven attacks. One of the key characteristics of this new threat is that malicious code can spread on an Internet scale in Internet time, rendering current intrusion detection approaches impotent. Methodology First, the paper describes the code-driven attack threat; the problem of code driven attacks and next generation code-driven attacks. Then it describes active-scripting-based attacks, which is an approach to addressing a specific class of the code-driven attack threat. Results The nature of the threat against computer systems is changing radically. The most significant emerging intrusion threat is code-driven attacks, and the most costly intrusions are being perpetrated per code, rather than individual hack-in attempts. For example, the Love Letter is estimated to have cost businesses $8 billion in lost productivity. Code that spreads itself over Internet connections, can quickly bring down very large segments of the Internet. The code-driven threat is aimed against the Win32 platform because this platform is used both in homes and in offices. Scripting-based attacks are developed in popular scripting languages such as VB-Script, Jscript, VBA macros, Perl and Python, and go through applications like Web browsers, mailers, MS Office applications and the Windows scripting host.

76



Personal conclusions The article discusses the development of hacker tools, and describes types of scripts and applications that it spreads through. It also mentions methods that can be used to prevent this. CERT/CC Statistics 1988-2003 (Unknown 2003) Below are statistics from CERT/CC web page. Number of incidents reported 1988-1989

1988 1989 Year 6 132 Incidents
1990-1999

1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 Year Incidents 252 406 773 1,334 2,340 2,412 2,573 2,134 3,734 9,859
2000-2003

2000 2001 2002 2003 Year Incidents 21,756 52,658 82,094 137,529
Total incidents reported (1988-2003): 319,992

Below we have visualized the statistics.

77



Number of incidents reported 160000 140000 120000 100000 Incidents 80000 60000 52658 40000 20000 9859 0 21756 3734 6 132 252 406 773 1334 2340 2412 2573 2134 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 Year 82094 137529

Vulnerabilities reported

1995-1999

1995 1996 1997 1998 1999 Year Vulnerabilities 171 345 311 262 417
2000-2003

2000 2001 2002 2003 Year Vulnerabilities 1,090 2,437 4,129 3,784
Total vulnerabilities reported (1995-3Q 2003): 12,144

Below we have visualized the statistics:

78



Vulnerabilities reported 4500 4000 3500 3000 Vulnerabilities 2500 2000 1500 1000 500 171 0 1995 1996 1997 1998 1999 Year 2000 2001 2002 2003 417 1090 2437 4129 3784

345

311

262

Personal conclusions For now, we just observe these numbers. It is clear that the number of incidents are increasing drastically, and that reported vulnerabilities are also increasing each year except 2003. Conclusions We managed to find answers to some of the questions, but not all. We found questions like how incidents affect hacking and patching, to be hard to find answers to. Hacker information spreads through clubs, publications, conventions, bulletin boards and newsgroups, and we would therefore think that script is spread the same way. The hacker environment and the hacker activity is hard to estimate, and also depends upon how you define a hacker. There are no clear numbers. But it is clear that the number of incidents and the number of vulnerabilities is increasing each year. Summary Hacker information spreads through hacker clubs, hacker publications, hacker conventions, and bulletin boards and newsgroups (as mentioned in the conclusion). These help members work as a team to achieve goals which might be out of reach for an individual hacker, even though most members never physically meet. Bulletin board systems are the primary way for hackers and hacker clubs to communicate. The traditional view of information systems security must be expanded to encompass the specification and design of survivability behavior that helps systems survive in spite of
79



attacks. Questioning how much a system can tolerate from massive coordinated attacks, clearly the "four key properties" are applicable. Code that spreads itself over Internet connections, can quickly bring down very large segments of the Internet. The code-driven threat is aimed against the Win32 platform because this platform is used both in homes and in offices.

Appendix C (KEB&SS)Hacker Information040127.doc
Kjetil Eiklid Braathen, Silje Salte Agder University College Faculty of Technology and Science Institute of ICT Groosveien 36 N-4876 Grimstad Norway

HiA

Hacker information continued
To: From: CC: Date: Re:

Jose J Gonzalez

Kjetil E Braathen, Silje Salte Johannes Wiik January 27, 2004
Hacker information continued

Organization of this memo:
ORGANIZATION OF THIS MEMO: INTRODUCTION DISCUSSING PAPERS, FINDING HACKER INFORMATION KNOW YOUR ENEMY (SLAWSKY 2003) Abstract Methodology Results Personal conclusions PATCHING: PROCESS MATTERS (FONTANA 2003) Abstract Methodology Results Personal conclusions SURVIVABILITY ­ A NEW SECURITY PARADIGM FOR PROTECTING HIGHLY DISTRIBUTED MISSION-CRITICAL SYSTEMS (LIPSON 2000) MASTERCARD SITE DATA PROTECTION PROGRAM (VERDESCHI 2003) Abstract Methodology Results Personal conclusions INFORMATION TECHNOLOGY--ESSENTIAL BUT VULNERABLE: INTERNET SECURITY TRENDS (PETHIA 2002) Abstract Methodology Results
81



Personal conclusions CONCLUSIONS SUMMARY SIGNATURE REFERENCES SOURCES SEARCHED KEYWORDS THIS MEMO

Introduction
The purpose of the memo is to continue with finding hacker information with the use of more and better words, and to search for newer articles by looking at references and authors. We will also try to find answers to the following: Experiences and strategies of patching? How long time does it take before patching? How long time does it take a hacker to develop scripts? What do scripts do? Do scripts change, and are there different types of versions? How do the attacks happen? How many hackers are there, and how many hacker communities are there?

Discussing papers, finding hacker information
Through this memo, we have divided the sections into the papers or texts we have found interesting. Know Your Enemy (Slawsky 2003) Abstract Companies learn to think like hackers to protect their computer systems. This means that they should keep up with the latest in hacker techniques by reading trade journals and participating in organizations such as the Information Systems Security Association. It can also be necessary to adopt an assumed identity and looking at web sites that are devoted to hacking and hacker activity. Methodology It is a very short and continuous article that is not divided into chapters or sections. Results There has been a development in what hackers do. They used to be a elite group of people who were interested in how computers works. Now, there are people that write hacking tools and release them so that anyone with a computer can get online, download the tools, and start to use them. These are known as "script kiddies". Any system can be broken in to by a determined hacker. But only one out of 10,000 or more people engage in hacking activity. A big concern is the increasing popularity of wireless networks.

82



Personal conclusions The article is very new and up to date. We would still wish that it wasn't so brief, and described things more in depth. Patching: Process matters (Fontana 2003) Abstract Patch management is tough. It's tough because there are too many patches and not enough time, and because exploits to announced vulnerabilities are materializing faster. Clients are becoming the attack targets as much as servers. "This typically isn't a task for one person. It has to involve the security group, the operations group and the developers, so what also makes patching tough is a lack of resources. (Felicia Nicastro)" Methodology The article is divided into a chapter about how to patch, an example of patching in action, and at last a chapter is about Pitney Bowes named "open season on clients". There are also a list over what to do, and what not to do when it comes to patching, and a list over the most popular patching tools. Results A big mistake for companies, is to leave out the processes such as monitoring for new patches coupled with detailed evaluation, testing, deployment and validation that a team or individual manages. The following pieces must be involved before a patch management process can be installed: network inventory, change management, configuration management, asset management, formalized record keeping, and an understanding of costs, prioritization guidelines, and maintenance and communications plans. At Centura Bank, they notify a lead engineer after a new patch is identified. If the patch is for a critical flaw, notification is sent straight to the vice president of engineering who decides if the patch is needed and structures the process toward deployment, if necessary. The patch is then tested. Pitney Bowes categorizes its network assets and their relevance to the company. Client desktops are given a risk profile from 1-5, so that desktops rated a 5 (clients that must be most secure) must be patched in less than 24 hours. Personal conclusions The article shows examples of how two different companies perform patching. It also has a short list over what to do, and what not to do, when it comes to patching. Survivability ­ A New Security Paradigm for Protecting Highly Distributed Mission-Critical Systems (Lipson 2000) We chose to use the following figure, Attack Sophistication vs. Intruder Technical Knowledge, because it shows that the intruders technical knowledge has been sinking dramatically while the sophistication of attacks are constantly increasing. In the 1980's,

83



the attacks started out being password guessing, and developed to become more advanced, like using back doors, sniffing, packet spoofing, denial of service and cross site scripting.

The next figure shows the vulnerability exploit cycle from when an intruder discovers new vulnerability, to the use of different types of exploit tools.

84



MasterCard Site Data Protection Program (Verdeschi 2003) Abstract The protection program from MasterCard give insight into how the hackers work, and how to prevent this. Methodology It is a PowerPoint presentation that begins with some slides about the hacker; the profile, motivations, tools, and 7 phases for an attack. This is the part we concentrate on. It also shows some slides that show a couple of hacker web sites. At the end, there is mostly information about MasterCard SDP Security Standard and how to protect themselves. Results The typical hacker is characterized as bored and antisocial individuals or groups, where 90% are "script kids" that have little knowledge, but access to hacker tools. Less than 10% are competent programmers who modify existing tools, and only less than 1% build new tools. Some of the motivations that the hackers have are: intellectual challenge, joy riding, gang mentality, recognition, theft of information, vandalism, blackmail, sabotage and terrorism. Some hacking tools were mentioned in numbers. There are 30 hacker publications, 440 hacker bulletin boards, and 400,000 web sites dedicated to "hacking tips". Hackers.com, 2600.com and insecure.org are examples of hacker web sites. We couldn't find statistics over the mentioned numbers, so the following table is found in different articles [1][2][3][4] Hacker information Web sites April, 1997 November, 1997 February, 1998 July, 1999 (Unknown date) 2003 1 900 2 000 2 500 30 000 400 000 30 Publications Dozens Bulletin Boards 440 500 500

440

We can see from this, that the development of hacker web sites has increased dramatically, while the number of publications and bulletin boards hasn't changed much. Before a hacker attacks, he must do following things: get information about the target's network, find weaknesses / deploy tools, exploit weakness and gain entry, gain privileged access, hide tracks, utilize sniffers to monitor / steal information, and expand control from one to many hosts.
85



Personal conclusions The presentation gave us some numbers that can give some insight of the hacker community. It also showed an estimate in percent of the different types of hackers. We don't know if the numbers are exact . Information Technology--Essential But Vulnerable: Internet Security Trends (Pethia 2002) Abstract Mr. Chairman and Members of the Subcommittee: My name is Rich Pethia. I am the director of the CERT® Centers. Thank you for the opportunity to testify on computer security issues that affect the government. Today I will discuss the vulnerability of information technology on the Internet, including information about recent security trends, and steps I believe we must take to better protect our critical systems from future attacks. My perspective comes from the work we do at the CERT Centers, which are part of the Survivable Systems Initiative of the Software Engineering Institute, a federally funded research and development center operated by Carnegie Mellon University. We have 14 years of experience with computer and network security. The CERT Coordination Center (CERT/CC) was established in 1988, after an Internet "worm" became the first Internet security incident to make headline news, acting as a wake-up call for network security. In response, the CERT/CC was established at the SEI. The center was activated in just two weeks, and we have worked hard to maintain our ability to react quickly. The CERT/CC staff has handled well over 173,000 incidents and cataloged more than 8,000 computer vulnerabilities. The CERT Analysis Center, established just two years ago, addresses the threat posed by rapidly evolving, technologically advanced forms of cyber attacks. Working with sponsors and associates, the CERT Analysis Center collects and analyzes information assurance data to develop detection and mitigation strategies that provide high-leverage solutions to information assurance problems, including countermeasures for new vulnerabilities and emerging threats. The ultimate goal of this work is to predict technologically sophisticated cyber attacks and develop defensive measures to protect against them before they are launched. The CERT Analysis Center builds upon the work of the CERT Coordination Center. The CERT Centers are now recognized by both government and industry as a neutral, authoritative source of data and expertise on information assurance. In addition to handling reports of computer security breaches and vulnerabilities in network-related technology, we identify preventive security practices, conduct research, and provide training to system administrators, managers, and incident response teams. More details about our work are attached to the end of this testimony (see Survivable Systems Initiative). Methodology This congressional testimony explains which threat the society faces. There are several brief chapters, using "reported numbers" as instrument that easily clarify our challenges.

86



The author gives an overall description, and uses headings such as: The growing risk, the growing threat, Cyber space and physical space are one. Results Internet numbers: The Internet Domain Survey ( http://www.isc.org/ds/ ) reports that the Internet grew from 109 million computers in January 2001 to more than 147 million in January 2002. The following figure [5] shows how many hosts that have been connected to the Internet from the beginning of 1991, and until January 2003.

We can also see the numbers shown in a table (http://www.isc.org/index.pl?/ops/ds/ (Host Count History)), from August 1981.

ISC Domain Survey: Number of Internet Hosts Adjusted Counts N/A N/A N/A N/A

Date

Hosts

Source host table

88



07/1999 56,218,000 01/2000 72,398,092 07/2000 93,047,785 01/2001 109,574,429 07/2001 125,888,197 01/2002 147,344,723 07/2002 162,128,493 01/2003 171,638,297

N/A N/A N/A N/A N/A N/A N/A N/A

We can make significant progress to survivability by making changes in software design and development practices, increasing the number of trained system managers and administrators, improving the knowledge level of users, and increasing research into secure and survivable systems. A particular relevant comment to our task is perhaps this: "A recent article in the Washington Post 1 reports that our growing dependence on computer-controlled and network-connected infrastructures--and the damage that could result from cyber attacks against those infrastructures--has not gone unnoticed by terrorist organizations. As the article reports: "...U.S. investigators have found evidence in the logs that mark a browser's path through the Internet that al Queda operators spent time on sites that offer software and programming instructions for the digital switches that run power, water, transport, and communications grids." And "...al Queda prisoners have described intentions, in general terms, to use those tools."". Personal conclusions This is a good article providing overall knowledge. It gives us some relevant numbers, and confirms that concentrated attack from terrorists is probable. Conclusions It was hard to find articles that had more than one or two answers to the questions we were to find out. And it was also hard to find out newer information from some of the former authors. The CERT/CC annual report 2003 will probably come in February, which perhaps will give us new information. Summary Any system can be broken in to by a determined hacker. But only one out of 10,000 or more people engage in hacking activity. A big concern is the increasing popularity of wireless networks. A big mistake for companies, is to leave out the processes such as monitoring for new patches coupled with detailed evaluation, testing, deployment and validation that a team or individual manages

89



The typical hacker is characterized as bored and antisocial individuals or groups, where 90% are "script kids" that has little knowledge, but access to hacker tools. Less than 10% are competent programmers who modify existing tools, and only less than 1% builds new tools. There are 30 hacker publications, 440 hacker bulletin boards, and 400,000 web sites dedicated to "hacking tips". Hackers.com, 2600.com and insecure.org are examples of hacker web sites.

Keywords Here are the keywords used in EBSCO: Number of hackers John Shors Tim Jordan Paul Taylor Hacker attacks Patching Script version



Appendix D (KEB&SS)Hacker Information040204.doc
Kjetil Eiklid Braathen, Silje Salte Agder University College Faculty of Technology and Science Institute of ICT Groosveien 36 N-4876 Grimstad Norway

HiA

Hacker information continued 2
To: From: CC: Date: Re:

Jose J Gonzalez

Kjetil E Braathen, Silje Salte Johannes Wiik February 4, 2004
Hacker information continued 2

Organization of this memo:
ORGANIZATION OF THIS MEMO: INTRODUCTION DISCUSSING PAPERS, FINDING HACKER INFORMATION NUMBER OF HACKING WEB SITES GROW 45% (UNKNOWN 2003) Abstract Methodology Results Personal conclusions CONCLUSIONS SIGNATURE REFERENCES SOURCES SEARCHED KEYWORDS THIS MEMO

92



Introduction
This memo is written as a continuation on (KEB&SS)Hacker Information040127, because of doubt of the numbers in the table on page 5 in the article "MasterCard Site Data Protection Program" by Verdeschi. It seems to us that 400,000 hacker web sites is too much. Based on this, there was another article found from the same year, which this memo tells about.

Discussing papers, finding hacker information

Number of Hacking Web Sites Grow 45% (Unknown 2003) Abstract Hacking tools used by employees within organizations may be the biggest security threat to emerge this year (2003), leading to increased vulnerabilities, lost data, and wasted time and resources. Methodology It is a short article that reports from a leader of employee Internet management (EIM), Websense Inc., San Diego, California. At the end of the article, there is a section about Websense. Results The number of hacking web sites has increased with 45% the last 12 months. Total number of web sites is now approximately 6000 sites, with more than one million pages of content. The increase in hacking web sites may have much to do with political and economic issues, and the most hacked country in the world is the United States. 85% of all hacking against companies is committed by former employees. It is so, because the former employees have knowledge of the company's computer system. Most of the hacking web sites contain archives of available hacking tools. These hacking tools can be denial of service attack software, sniffer and anti-sniffer software and password crackers. The sites also offer free downloads of hacker programs that enable employees to be self-taught, and step-by-step instructions for beginners on everything from how to gain unauthorized access to computer systems to instruction on how to perform attacks on routing protocols. Personal conclusions The article has some good facts about hacker web sites, and it is only a year old. Conclusions We have, as mentioned in the introduction, doubt about two of the references used in KEB&SS)Hacker Information040127. The sources here are found searching on www.google.com, while all the others are found on Agder University College's library

93



database, EBSCO. In addition, is sounds more likely to us that the number of hacker web sites was 6,000 in 2003, than 400,000. The article, Number of Hacking Web Sites Grow 45%, says that the number of web sites has increased with 45%, which means that the number in the beginning of 2002 must have been around 4,100 hacker web sites. We use this number, and create a new table compared to the one in last memo. We have also removed the two sources that seems doubtful to us. The new table is as following:

Hacker information Bulletin Boards 440 500 500

Web sites April, 1997 November, 1997 February, 1998 February, 2002 February, 2003 1 900 2 000 2 500 4 100 6 00
Keywords .... This memo ....

94



Appendix E (KEB&SS)TeenageHackers040225.doc
Kjetil Eiklid Braathen, Silje Salte Agder University College Faculty of Technology and Science Institute of ICT Groosveien 36 N-4876 Grimstad Norway

HiA

T eenage Hackers
To: From: CC: Date: Re:

Jose J Gonzalez

Kjetil E Braathen, Silje Salte Johannes Wiik February 25, 2004
Teenage Hackers

Organization of this memo:
ORGANIZATION OF THIS MEMO: INTRODUCTION DISCUSSING THE BOOK, FINDING INFORMATION ABOUT TEENAGE HACKERS THE HACKER DIARIES: CONFESSIONS OF TEENAGE HACKERS (VERTON 2002) Abstract Methodology Results Personal conclusions SIGNATURE REFERENCES SOURCES SEARCHED KEYWORDS THIS MEMO

95



Introduction
The purpose of this memo is to provide information about teenage hackers, who they are and why they do what they do. The Hacker Diaries tells the life stories of today's teenage computer hackers and profiles some of the most notorious hackers and hacking groups of recent years.

Discussing the book, finding information about teenage hackers
The Hacker Diaries: Confessions of Teenage Hackers (Verton 2002) Abstract Computer hacking and Web site defacement has become a national past time for America's teenagers, and according to the stories you'll read about in The Hacker Diaries ­ it is only the beginning. · · Who exactly are these kids and what motivates a hacker to strike? Why do average teenagers get involved in hacking in the first place?

This compelling and revealing book sets out to answer these questions ­ and some of the answers will surprise you. Through fascinating interviews with FBI agents, criminal psychologists, law--enforcement officials ­ as well as current and former hackers ­ you'll get a glimpse inside the mind of today's teenage hacker. Learn how they think, find out what it was like for them growing up, and understand the internal and external pressures that pushed them deeper and deeper into the hacker underground. Methodology The book is divided into chapters, where each chapter tells a story about a teenage hacker (sometimes two). We wish to tell about some of these hackers to illustrate how a hacker can be like, why he/she was hacking, what he/she has done, etc. Results Genocide Genocide grew up in Fairbanks, Alaska. Most of his high school hacking career was spent causing chaos on the school's computer network. His cousin Tony had learned him lessons in social engineering (the art of collecting information from unsuspecting individuals by asking what seems to be harmless questions or by pretending to be somebody you're not). His first hack consisted of logging in with his chemistry teacher's name and password, and changed a grade so that he would get to graduate on time. His mother started taking college courses, and Genocide began accompanying her to the college. He spent a lot of time surfing bulletin board systems (BBS), and also by reading and learning about various commands, operating systems and hardware design. When he became bored of that, he cracked a password file. He barely got away with it. Hacking was all about the taste of adrenaline, the challenge, and to push the limits.

96



Genocide began to make hacker friends after a while, and they kept their distance in the beginning. The members of the group shared similar view about hacking, and they were pissed off at the ignorance of the media and the general population when it came to understanding what a hacker was. The group became the Genocide2600 group (www.genocide2600.com (this is the new page, and not the original page)) and started to share their information with anyone willing to listen. A hacker could even visit the Genocide2600 site and learn how to defeat the FBI's lock-in trace capabilities, accept a free long-distance call by lowering the voltage on the phone, make a low-budget twoparty phone line, etc. The group started to attack pedophiles online. A program called AOHell was the tool that they used to hack into private AOL chat rooms in search of child pornographers and zap them with e-mail bombs that would crash their systems. Their Internet connection would be broken, he would reconnect, and the hackers hit him again. Genocide2600 now claims to have more than 100 members from coast to coast. Mafiaboy Bill Swallow moved from a management position to the undercover team of agents who posed as teenage hackers online. He, and other undercover agents had to do hacks, or else they would have lost credibility. Hackers who knew they were jammed up, quickly became the FBI's trainers and consultants. They showed Swallow how to act in various IRC chat rooms and how to respond to questions and challenges from other hackers. The best source of intelligence about a hacker is another hacker. The first of the big attacks by Mafiaboy (14 years old at the time) started on February 7, 2000. Yahoo! got hit. Yahoo! was dealing with a hacker who knew what he was doing and who took the time to learn about his target and plan the attack. It was a DDoS attack (DDoS = Distributed Denial of Service). The same night, Mafiaboy was on an IRC (Internet Relay Chat) channel bragging about his skilz (skills). The next day, Buy.com, eBay and Amazon.com got hit, and Mafiaboy was again on IRC that night and claimed responsible of the attacks once again. Somebody on the channel suggested CNN for a good next target, and within minutes CNN got hit. Dozens of computers had been hijacked and used in the attacks. The intruder had planted malicious software on these systems that had turned them into autonomous launching pads for denial-of-service attacks. IRC is one of the most popular and most interactive services on the Internet. You need a Web browser and an IRC client to connect to an IRC server. The next step then is to get into one of the channels (an IRC server can have dozens, hundreds or thousands of chat channels open), and get yourself a nickname. Participants in the chat can exchange ideas on common interests, and even many businesses now hold scheduled chat sessions. The chat log in the IRC hacker room #!tnt details a conversation between Mafiaboy (who has changed his nickname to anon (for anonymous) and other hackers: T3: mafiaboy, so who's next after dell Anon: Microsoft will be gone for a few weeks T3: oh man, that's evil

97



T3: I need to get away from you before I get busted for being an accomplice or some sh** Anon: I know what I'm doing Anon: yahoo.dom T3: So Mafiaboy, it was really you that hit all those ones in the news? buy.com, etrade, eBay, all that sh**? Anon: you just pin em so hard they can't even redirect T3: they say you're costing them millions Anon: surprised I didn't get raided yet, T3, they are fools This is part of the chat log captured by several security experts in the private sector and other hackers, and sent it to the FBI. Mafiaboy got caught by the FBI. When investigators picked apart his computers, they found no technical evidence linking him to the attacks. Without wiretap and data interception operation, they wouldn't a case. On September 12, 2000, Mafiaboy got a eight-month sentence in a juvenile detention center. He pleaded guilty to dozens of charges related to the February attacks. The last time the FBI had dedicated nationwide resources and manpower to hunt down a single hacker was with Kevin Mitnick (America's most wanted hacker) in the late 1980's and early 1990's. The Mafiaboy investigation involved more than a hundred agents in two countries. Neither Mafiaboy nor Mitnick were very good hackers. Mitnick was far better at social engineering than he was at hacking. His success was a direct function of the phone numbers, account numbers, and passwords ha was able to fool unsuspecting people into giving him. For Mafiaboy, successful hacking was a matter of downloading software tools from the Internet, following directions, and hitting the Enter key on his keyboard. Pr0metheus Pr0metheus became a hacker when he was 14, and he is one of Satan's hackers. His organized hacking career started with a well-known group called PoizonBox. The group was responsible for more than 900 Web site defacements. Pr0metheus got bored of PoizonBox, and became the leader of a new defacement group called Hacking For Satan. All he wants is to spread the word of Satanism. It's not about raising people's awareness of Internet security issues, or about the love of technology or the thrill of the hack. He hates organized religion, and especially Christianity. One of the hacks that he did, included the search for hosts that contained the words church and holycross in their name, and seconds later the online system spits back a list of more than 2,000 servers. To narrow down the list, he wrote or modified several automated scripts using the Perl (Practical Extraction and Report Language) programming language. The next script he used, was to check for the servers ran on the Windows operating system. The last script that was run, checked for FrontPage systems that had open ports and access controls that enabled "everyone" to modify the site's content. One of his first targets was the Southgate Baptist Church in Springfield, Ohio,
98



where Pr0metheus used the script to replace their Web site with his own liturgy on the principles of Satanism. Starla Pureheart Anna Marie Moore (with nickname Starla Pureheart) grew up in a computer-oriented family. She was exceptionally bright, and had successfully hacked her own Windows system. This was no big achievement for her, so by the time she was 13, she was well on her way to mastering the Linux operating system. The characterization of hackers as socially awkward teenagers with oversized glasses and pocket protectors doesn't apply to Anna. She contradicts the image of the teenage hacker as dark, brooding, and antisocial misfit. In her case, hacking is the ruthless quest for knowledge and the study of technology. When Anna was 15, she won the CyberEthical Survifor contest at the annual DefCon hacker conference in Las Vegas. DefCon (www.defcon.org) is the worlds largest underground hacking event in the world, and gathered more than 5,000 hackers. Hacking still remains a passion to Anna. She was supported by her parents all along with her hacking and they have helped her to develop moral and ethical compass. General results The book illustrates that there is no stereotype hacker. They are of all ages, from all walks of life and from everywhere. What is very often common with hackers, is that they often spend their time in front of the computer until late at night (or early in the morning). At this time, some of them talk to other hackers through IRC-channels, searching through Bulletin Board Systems, etc. Hackers are motivated by intellectual curiosity. There is a new trend within the hacker culture. Teenage hackers used to be interested in exploring and sharing information, but a growing number of them are interested in destroying and blocking information flow. Most of the hackers are script kiddies. A core belief in the hacker community, is that when hackers discover new vulnerabilities, they force companies to take action to plug the security holes in their software that might otherwise go unfixed. Technology is more fragile than people like to believe. Personal conclusions This is a very entertaining book, and it comes up with a lot of facts about the hacker culture. The book describes, as mentioned before, each of the hackers, why they did it, some of the things they have done, etc. When you read this book, you get another more "friendly" impression of hackers. Several of the hackers in the book try to explain the real meaning of being a "hacker". They mean that a "real hacker" is what we know as a "white hat" hacker, a person with good intentions. They mean that there is pride being a hacker, and that most of the hackers do not have malicious intentions. But, anyway, when it comes to criminality, they are balancing on a thin line, and most of the hackers do cross it.

99






Appendix F (KEB&SS)Blaster and blackout040225.doc
Kjetil Eiklid Braathen, Silje Salte Agder University College Faculty of Technology and Science Institute of ICT Groosveien 36 N-4876 Grimstad Norway

HiA

Blaster and blackout
To: From: CC: Date: Re:

Jose J Gonzalez

Kjetil E Braathen, Silje Salte Johannes Wiik February 25, 2004
Blaster and blackout

Organization of this memo:
ORGANIZATION OF THIS MEMO: INTRODUCTION DISCUSSING PAPERS, FINDING HACKER INFORMATION HACKER DANGER FOR POWER SUPPLY? (KRANE 2003) Abstract Methodology Results Personal conclusions CONCLUSIONS SUMMARY SIGNATURE REFERENCES SOURCES SEARCHED KEYWORDS THIS MEMO

101



Introduction
The issue here will be to find out whether or not the MS Blaster worm was linked to the major blackout in parts of US and Canada on August 14, 2003.

Discussing papers, finding hacker information
Through this memo, we have divided the sections into the papers or texts we have found interesting. Hacker Danger For Power Supply? (Krane 2003) Abstract Since the blackout August 14, 2003, utilities have accelerated plans to automate the electric grid, replacing aging monitoring systems with digital switches and other high-tech gear. But those very improvements are making the electricity supply vulnerable to a different kind of peril: computer viruses and hackers who could black out substations, cities or entire states. Methodology The article focuses on danger of hacking for power supply, and the Blaster worm and the Slammer worm are mentioned in this connection. It also tells about the renewal of the electric grid requires a vulnerable connection to a computer network. There are system weaknesses, and there are bad practices for patching. Results The grid has a growing number of vulnerabilities, and security experts have warned about it, especially after U.S. National Security Agency hackers proved that they could break into the grid control networks in 1998. Computer viruses are a new worry. The MS Blaster worm flummoxed an estimated half-million computers around the world in August 2003 might have made worse utilities' problems during the blackout. It might have brought down ­ or perhaps blocked communications ­ on computers used to monitor the grid. The worm didn't cause what happened, but it could have exacerbated what happened. Personal conclusions The article says very clearly that the Blaster worm didn't cause the blackout. It may have worsened the situation, though. Blaster worm linked to severity of blackout (Verton 2003) Abstract WASHINGTON -- The W32.Blaster worm may have contributed to the cascading effect of the Aug. 14 blackout, government and industry experts revealed this week. On the day of the blackout, Blaster degraded the performance of several communications lines

102



linking key data centers used by utility companies to manage the power grid, the sources confirmed. Methodology In this article, the author (Dan Verton) accumulates comments from different persons, having different backgrounds, on the W32.Blaster worm issue. He doesn't take side, but simply quote several opinions. Results There are both people thinking that the worm did have influence on industry systems, and not. Personal conclusions We get the feeling that the worm did affect several industry systems and the blackout, but there is not enough information on this to make conclusions. We probably don't get the "whole story", simply because this is "classified information". Conclusions Before there is more evidence, there is difficult to conclude that the MS Blaster worm was linked to the major blackout in parts of US and Canada on August 14, 2003. The two articles in this memo fulfill this.

Signature
Kjetil E Braathen, Silje Salte


103



Appendix G (KEB&SS)MixterAndRandomizer040308.doc
Kjetil Eiklid Braathen, Silje Salte Agder University College Faculty of Technology and Science Institute of ICT Groosveien 36 N-4876 Grimstad Norway

HiA

Mixter and Randomizer
To: From: CC: Date: Re:

Jose J Gonzalez

Kjetil E Braathen, Silje Salte Johannes Wiik March 8, 2004
Mixter and Randomizer

Organization of this memo:
ORGANIZATION OF THIS MEMO: INTRODUCTION DISCUSSING PAPERS, FINDING HACKER INFORMATION OPINION: ON MAGIC, IRC WARS, AND DDOS (GRAHAM) Abstract Methodology Results Personal conclusions HACKER DISCLOSES NEW INTERNET ATTACK SOFTWARE (SHANKLAND 2000) Abstract Methodology Results Personal conclusions WEBSITE OF MIXTER: .MIXTER SECURITY (HTTP://MIXTER.VOID.RU/INDEX.HTML) Abstract Structure of the website Results Personal conclusions CONCLUSIONS SUMMARY SIGNATURE REFERENCES

104



SOURCES SEARCHED KEYWORDS THIS MEMO

Introduction
The purpose of this memo is to find information about the two German hackers Mixter and Randomizer. They were both pioneers in denial of service attacks, and members of two different hacker clubs that competed with each other. It all started in 1995, and we will try to find the whole story.

Discussing papers, finding hacker information
Through this memo, we have divided the sections into the papers or texts we have found interesting. Opinion: On Magic, IRC wars, and DDoS (Graham) Abstract The thing about hacking is that it is a lot like the magic tricks you see in Las Vegas. The key to magic is not coming up with difficult tricks, but obfuscation them with distractions. On the other hand, hacker attacks are only frightening and attention-grabbing because people don't know the boring details. Users scare easily, and most users are afraid of their machines because they can't seem to master all the complexities. In reality, there are only a few ways hackers break into PCs, and only a few steps users need to be aware of to defend themselves. Methodology The article is divided into an introduction, a part about mundane Internet principles, a section about wars between hacker clubs, a section about DDoS, one part that says that effect doesn't equal sophistication, and a summary. At last, resources and news articles used are mentioned. Results The system that the Internet is based upon, is based on trusting its users, and is therefore defenseless against "internal" attacks. There are about 20 hackers in the world that are skilled enough to bring down the Internet in a similar manner that Robert T. Morris took down the net with a "worm" 10 years ago. But on the other hand, there are about 100,000 hackers that are skilled enough to bring down a major Internet portal for a few hours. The method of how the attacks on Yahoo and the other big Web sites happened: the hacker breaks into about 50 machines that are attached to a high-speed Internet connection, and runs a program on each of these machines. The program causes the machines to send network traffic as fast as they can against the victim.

105



Hacker gangs are breaking into machines and are using them for attacks against Internet Relay Chat (IRC) chatrooms. A hacker can get control of a chatroom by kicking off all the rival moderators. This is a way for hacker gangs to gain control of IRC chatrooms, and then keep control against attacks from rival gangs. Hackers are using a method called "the flood", which is a technique where a hacker sends a huge number of pings against the victim. There will be so much meaningless traffic that nothing else can get through. The FBI estimated that it took about 50 machines to take down Yahoo. It does not mean that a sophisticated tool and a skilled hacker is used just because the attacks are impressive. To do this kind of an attack, DDoS, all you need to do is to download the software from the Internet, use a scanner program against millions of IP addresses, and the machines that are not secured against scripts will get hacked. The scripts will give you full control of the machines through a remote command window. When you log into one of these machines, you start installing bots like Trin00 (Trinoo), TFN (Tribe Flood Network), or Stacheldraht. "Bot" is short for "robot", and it is an automated program. For example, one kind of bot tries to stay logged onto the IRC chatroom, become moderator, and pass moderation privileges to other bots. Personal conclusions The article is very general, and the discussion about how hacker gangs compete gives an insight into how they fight. This does not mean that this is the way that the hacker gangs of Mixter and Randomizer competed against each other. Hacker discloses new Internet attack software (Shankland 2000) Abstract A programmer familiar with attack software has disclosed three new attack programs of the type believed to have taken down major Internet sites last week, complicating the jobs of security experts trying to fight the malicious programs. Methodology It is a short, continuous article that is not divided into sections. There is also a link to a page that describes how a denial of service attack works, and a link to a page that contains different other links to articles about Mixter, Mafiaboy, the big attacks against Yahoo, eBay, etc., about denial of service attacks, etc,. Results Packet Storm is a site that publishes malicious software so security professionals can scrutinize it. Mixter, at Packet Storm, is the author of the attack tool TFN (Tribe Flood Network) and its sequel, TFN2K. These are both distributed denial of service tools (DDoS). Other examples of DDoS tools are: Blitznet written by "phreeon", Trinoo written by "phifli" and Stacheldracht written by "Randomizer". There are online detection tools that are used to find computers infected with DDoS attack software, f.e., MyCIO. Of more than 10,000 who have used it to scan their systems, the MyCIO software has found five cases of Stracheldraht, one of TFN and one of Trinoo.

106



Personal conclusions It is explained who has written what DDoS tool, and a little about what they do and how to detect them. But the article is very short, and we would wish that it told us much more about Mixter and Randomizer and the story behind. Website of Mixter: .mixter security (http://Mixter.void.ru/index.html) Abstract Here's a short summary of the less boring technical things I've done so far. I consider this my personal home page and feel like writing my boring history on this page. If you fall asleep, you've been warned. :P Far from all of this is professional security work, some of it was done for fun and education. I started out in C with maintaining and contributing a bit to the development of eggdrop, the all-purpose IRC bot. My old Tcl script for eggdrop is entity, which is still available, now for 1.6 eggdrop bots. :) It's designed specially for large distributed eggdrop networks and has very efficient channel- and basic intrusion protection. Some people use and like it for its ease of use. This was my first experiences with programming distributed networks, sort of. Structure of the website This website is divided into three main pages, .home, .about and .mail. From the .home location, you can download scripts and tools made by Mixter and other hackers, or view papers written by Mixter. You can also read other articles and DDOS related material from here. There is also a page with security links. In the .about section, which we find interesting, Mixter has written his project history, a personal profile, and facts about the DDOS incident. The .mail link links you to your e-mail client. Results Randomizer is just mentioned on this website (as the writer of "Stacheldracht", and a TESO member). This is Mixter's own personal profile, written in 2002: Nickname: Mixter Real Name: Isn't exactly a secret, but I prefer to keep my privacy. Ask me. Current age: 23 Contact: mixter@hacktivismo.com Citizenship: German Residence: Germany, at the moment Politics: Libertarian Areas of Interest: Maintaining friendships around the world. Hacktivismo, and technical projects using the Internet in new ways. Distributed applications and decentralized peer-to-peer. Philosophy. Mostly, recognizing and challenging established authority. Amateur biochemistry and bioinformatics. I'm also into Life Extension. Practical security, vulnerabilities. I don't have time for it right now. Forcing myself to learn things like openssl or all of ANSI C++. Music: Classical, Psytrance. I also composed some ambient tracks. Employment: Recently started as a senior developer at a Germany-based security/crypto company. Current Projects: Hacktivismo and Six/Four. Right now, I don't feel like getting involved in any new projects.
107



Maintained Projects: Mostly, nsat and libmix. I have some private projects. Personal conclusions Good website with good links, well written. Would it be an idea to e-mail Mixter and ask him about the hacking clubs and Randomizer? Conclusions It seemed impossible to us to find the whole story that started in 1995. Randomizer is barely mentioned in some of the articles, and we have not found any information about the two hacker clubs that competed. A lot of time has been used to search for information this time, and little exact information has come out of it (compared to what we wished). The results that we found were mainly written right after the attacks in February 2000. An idea would perhaps be to write an e-mail to Mixter, and ask him about the hacking clubs. Summary Randomizer is just mentioned as the writer of "Stacheldracht", and a TESO member, and a boy who "shrouds his identity in secrecy". Mixter participates in larger projects, and seems to shear knowledge in a wider way.


Jose J Gonzalez

Kjetil E Braathen, Silje Salte Johannes Wiik March 15, 2004
DoS and DDoS

Organization of this memo:
ORGANIZATION OF THIS MEMO: INTRODUCTION DISCUSSING PAPERS, FINDING HACKER INFORMATION LESSON 182: DISTRIBUTED DENIAL OF SERVICE ATTACKS (CLARK 2003) Abstract Methodology Results Personal conclusions GERMAN CREATOR OF SITE CRASHING PROGRAM GETS HEAVIER SENTENCE (UNKNOWN 2000) Results CONCLUSIONS SIGNATURE REFERENCES SOURCES SEARCHED KEYWORDS THIS MEMO

110



Introduction
In this memo, we will try to find more information about denial of service attacks, and distributed denial of service attacks. We will also try once again to find more information about the story behind the hacking war between the clubs of Mixter and Randomizer, which we found hard to do in (KEB&SS)MixterAndRandomizer040308.

Discussing papers, finding hacker information
Through this memo, we have divided the sections into the papers or texts we have found interesting. Lesson 182: Distributed Denial of Service Attacks (Clark 2003) Abstract Focuses on distributed denial of service (DoS) attacks, a computer virus. Goal of the virus; Common methods for initiating a DoS attack; Initiation process of the distributed DoS attack. While Denial of Service (DoS) attacks have been around for many years, they are becoming increasingly menacing as the Internet extends further into the global communications fabric. Over the past several years, such exploits have been overshadowed by Distributed DoS (DDoS) attacks in which multiple systems can be used to launch an attack, significantly increasing the potential for widespread damage. Methodology The article describes the DoS method at first, and divides it into the two common methods for initiating a DoS attack; packet flooding and the use of malformed packets. After this is described, the article tells about DDoS in detail. At the end, there is a section about some incidents that happened in 2003 (until September, when the article was written), and which tools were used. Results Denial of service attacks are divided into two primary groups: Packet flooding attacks, which are aimed at overwhelming the system resources. The receiver gets exploded with multiple connection requests, but he fails to send the necessary acknowledgements in return. The result is half-open connections that tie up resources and prevent legitimate connections from being made. Two types of packet flooding attacks are Internet Control Message Protocol (ICMP) flood attacks, and Smurf attacks. Trinoo, Tribe Flood Network (TFN), Shaft, Stacheldraht, Trinity, Targa3, and FloodNet are other examples of attacks that involve packet flood exploits. The use of malformed packets are typically geared toward crashing a service. The attacks exploit errors in TCP/IP stack by sending atypically formatted packets. Buffer overflow is a common result of a malformed packet attack. It occurs when too much data is written to a buffer, which can result in overwriting of data in adjacent buffers, alteration of data, file
111

-



damage, and system crashes. Examples of malformed packet attacks are Ping of Death, TearDrop, NewTear, Bonk, Syndrop, Chargen, WinNuke, Land, and Joltz. Distributed denial of service attacks are based on many of the same mechanisms as DoS attacks, but they are more complex and have the potential to do more widespread damage. In an attack like this, the attacker first chooses the exploit and the attack type, and then enlists zombie systems to form an army of unwitting participants. To find these, the attacker scans the Internet for vulnerable IP addresses with a scanning tool. After he/she has done this, he/she downloads a daemon (a program that executes command strings form the master system, onto the zombies). When the command sequence is sent from the master system, the zombies will attempt to execute the attack, by for example bombarding the target with packets.

Figure 1: The DDoS Deluge DDoS attacks will become more difficult to detect as they evolve, and they will be able to compromise more and more systems within shorter windows of time. There is also an increasing availability of more sophisticated automated tools for scanning and deployment, which means that the DDoS attack tools are becoming easier for less skilled attackers to launch. Worms are not typically intended to be mechanisms for DoS or DDoS attacks, but they can result in serious denial of service conditions. When a worm is launched, it can spread to systems that were not deliberately selected as targets. Personal conclusions Both DoS and DDoS attacks are described in an understandable way, and the article is pretty easy to read. It explains how the types of attacks work, and also gives examples of them.

112



German Creator of Site Crashing Program Gets Heavier Sentence (Unknown 2000) Results The 21-year-old hacker, "Mixter", got sentenced to a 6-month youth prison sentence for among other things "computer sabotage", "spying for data", and also other attacks on businesses in 1998. The sentence got suspended to a two-year parole period. Conclusions We found a good article about DoS and DDoS attacks, and just a small site that mentioned a few things about Mixter. We still did not manage to get the whole story, which seems impossible to find on the Internet.

Signature
Kjetil E Braathen, Silje Salte


Appendix I (KEB&SS)DoSandDDoS040323.doc
Kjetil Eiklid Braathen, Silje Salte Agder University College Faculty of Technology and Science Institute of ICT Groosveien 36 N-4876 Grimstad Norway

HiA

DoS and DDoS
To: From: CC: Date: Re:

Jose J Gonzalez

Kjetil E Braathen, Silje Salte Johannes Wiik March 23, 2004
DoS and DDoS

Organization of this memo:
ORGANIZATION OF THIS MEMO: INTRODUCTION DISCUSSING PAPERS, FINDING HACKER INFORMATION DDOS ATTACKS: PRECURSOR TO DIGITAL TERRORISM (SIGMOND AND KAURA 2001) Abstract Methodology Results Personal conclusions UNDERSTANDING AND PREVENTING DDOS ATTACKS (VAUGHAN-NICHOLS 2004) Abstract Methodology Results Personal conclusions HACKER WAR KEEPS THE WORMS COMING (GAUDIN 2004) Abstract Methodology Results Personal conclusions RESULTS OF THE DISTRIBUTED-SYSTEMS INTRUDER TOOLS WORKSHOP (UNKNOWN 1999) Abstract Methodology Results Personal conclusions 2003 CSI/FBI COMPUTER CRIME AND SECURITY SURVEY (UNKNOWN 2003)
114



SUMMARY CONCLUSIONS SIGNATURE REFERENCES SOURCES SEARCHED KEYWORDS THIS MEMO

Introduction
This memo is written to find more information about DoS and DDoS attacks, and also to examine the two links http://www.cert.org/reports/dsit_workshop.pdf and http://www.robertgraham.com/op-ed/magic-ddos.html. The original purpose of the links, given to us by Tim Shimeall, was to find more information about the Mixter and Randomizer case.

Discussing papers, finding hacker information
Through this memo, we have divided the sections into the papers or texts we have found interesting. DDoS Attacks: Precursor to Digital Terrorism (Sigmond and Kaura 2001) Abstract It's well established that hackers can cause havoc, knocking down important Web sites, like Amazon.com, and causing major financial loss. But, in this networked world, just how large could the threat be? A new breed of cyber threats is emerging. As the Internet becomes an integral part of the economic fabric, concerns about its safety and reliability continue to mount. Ironically, some of the most powerful features of the Internet, namely interconnectivity, distributed computing, and the ability to transmit information instantaneously, are the very factors that could bring down this digital lifeline and everything that it feeds. Perhaps the most potent and difficult to tackle hacker attacks are distributed denial of service (DDoS) attacks. Methodology The article starts with a little introduction, then explains the development from DoS to DDoS. After this, the authors take a look at how big the impact is, a small part about FAA (Federal Aviation Administration), about how DDoS belongs to the next generation, how to tackle DDoS, and that it is an emerging business opportunity. At the end, there are numbers of estimated costs of different DDoS attacks. Results There have been warnings from security experts that say that future attacks will not come from "script kiddies" and casual hackers, but they will come from highly-trained cyber-terrorists and the cyber-armies of enemy states.

115



The purpose of a DoS attack is to render the target system completely useless. There are two strategies to do this: flood attack; flooding the target with spurious traffic and overloading it. Examples are ICMP attack, SYN attack, AmurF attack and Fraggle attack. logic attack; exploits known software bugs on the target system in an effort to take it offline. Examples are Ping of Death, Teardrop, Land and Chargen.

A DDoS attack differs from a DoS attack, in that the spurious traffic originates from multiple machines in the Internet, while it originates from a single machine in DoS attacks. DDoS attacks have therefore much bigger impact, and are more difficult to fight. In 1999, 27 percent of the respondents to CSI/FBI annual surveys indicated experiencing DDoS/DoS attacks. The numbers went up to 36 percent in 2000. It is suggested that 4,000 DDoS attacks happen across the Internet each week (2001). It is also estimated that 2.4 percent of all attacks could break through highly tuned/optimized firewalls. Cyber wars are very efficient for the attacker from a risk/cost perspective, and the attacks can be just as damaging as physical attacks. Hackers are busy creating smarter versions of the hacker tools. This can be new types of DoS attacks, which cause degradation of service, and do not result in denial of service. Degradation of service is when the victim's servers are not completely overwhelmed, but are stunned with a barrage of significant network activity. The use of "pulsating zombies" is another version of the attack. This is when the pulsating zombies are never active for sufficiently long durations, while normal zombies are always on. Another way to explain this, is to say that short bursts of attack traffic are directed at an intended target. Zombies are computers that are controlled remotely by crackers. Another type of attack involves "reflectors" (all Web servers, DNS servers, and routers are reflectors). Here, the zombies (a couple of hundred) send packages to reflectors (hundreds of thousands) after spoofing the victim's source address. The reflectors interpret the packets as coming from the victim and end up sending reply packages to the victim. Detection, identification of the source, and solution are three aspects to tackling DDoS. These kind of attacks can result in billions of dollars in lost business within hours. Personal conclusions DoS and DDoS are very briefly described, with examples, and thereby not explained thoroughly. We question the contention that future attacks will come from highly trained cyber-terrorists, because the tools that hackers use are becoming more and more userfriendly. But cyber-terrorists will probably use these kinds of tools more and more as well, because they can be very destroying, and it is a "new" way to have a war between countries. Understanding and Preventing DDoS Attacks (Vaughan-Nichols 2004) Abstract It was in early 2000 that most people became aware of the dangers of distributed denial of service (DDoS) attacks when a series of them knocked such popular Web sites as
116



Yahoo, CNN, and Amazon off the air. More recently, a pair of DDoS attacks nailed The SCO Group's Web site, which many people thought had to be a hoax, since surely any company today could stop a simple DDoS SYN attack. Wrong. Methodology The author starts saying in this article that DoS and DDoS attacks are continuously launched against the Internet. Then the author describes some attacks and attack types. At the end, he suggests how to deflect them. Results There are many types of DDoS attacks. Often, when we are talking about DDoS attacks, we mean attacks on the TCP/IP protocol. There are three types of such attacks: the ones that target holes in a particular TCP/IP stack; those that target native TCP/IP weaknesses; and the boring, but effective, brute force attacks. For added trouble, brute force also works well with the first two methods. What you should do to deflect attacks: all the usual security basics can help you (antivirus client, firewall, patching). This will not stop all DDoS attacks, but it will stop some of them. Keep yourself current on the latest DDoS developments. A good site for this is the University of Washington hosted Distributed Denial of Service (DDoS) Attacks/tools site (http://staff.washington.edu/dittrich/misc/ddos/). This site has a good archive of articles and other DDoS material. Personal conclusions This article is informational on the DDoS subject. We will examine the links. Hacker War Keeps the Worms Coming (Gaudin 2004) Abstract The onslaught of worm variants has slowed slightly in the past few days, but at least one security analyst says the attack of three vicious viruses seems far from over. Methodology This is a short article with some facts and quotations, which lead to the main message: the rivalry of the hackers that instigate more attacks. Results "What appears to be fueling the virus writers' fire is that they are actually sniping at each other". ''These virus writers are fighting a war amongst themselves for attention and one-upsmanship, and we're all getting caught in the crossfire.'' The above quotations confirm the hacker war. When the virus is written just to kill another virus from another "hacking club", it confirms the rivalry.
117



Personal conclusions This is a rather short article, which shows us the hacker fronts clearly, and maybe it shows us some of the hackers mind: that the goal is not always the intrusion or virus itself, but to state an example of power. Results of the Distributed-Systems Intruder Tools Workshop (Unknown 1999) Abstract In a denial of service attack using distributed technology, the attacked system observes simultaneous attacks from all the nodes at once ­ flooding the network normally used to communicate and trace the attacks and preventing any legitimate traffic from traversing the network. Methodology The paper is the outcome of the work done at a Distributed-Systems Intruder Tools Workshop in Pittsburgh, Pennsylvania (November 2-4, 1999). It starts with a summary, followed by an introduction, recent activity involving distributed attack systems, some audience-specific information (specific information for groups in the Internet community: managers, system administrators, Internet service providers (ISPs), and incident response team (IRTs)). We choose not to discuss the last part in this memo, but focus on the relevant things for our use. Results The intruder community is loosely organized when it comes to development of attack tools. There are parallels to draw with open system development, because there are many developers and a large, reusable code base. Tools that are used, are becoming increasingly sophisticated, and they are also becoming more user friendly and widely available. This results in unsophisticated users using the available tools to identify and take advantage of a large number of vulnerable machines. To develop new and more powerful distributed attack tools, intruders are using currently available technology. There has been an increase in the development and use of distributed sniffers, scanners, and denial of service tools. Intruders are actively seeking systems with good network connectivity for compromise and installation of daemon programs. Personal conclusions The paper is from December 1999, and has therefore no recent information about Distributed-Systems Intruder Tools. There was good information about DDoS (we chose not to write all of it here so that we would not repeat ourselves). 2003 CSI/FBI Computer Crime and Security Survey (Unknown 2003) In this part, we look at statistics over denial of service attacks.

The figures shows that the number of DoS attacks are increasing (except from 1999 when it decreased), and that these kind of attacks are a big part of Web site incidents. But the portion of DoS attacks detected went down in year 2000. Summary A DDoS attack differs from a DoS attack, in that the spurious traffic originates from multiple machines in the Internet, while it originates from a single machine in DoS attacks. DDoS attacks have therefore much bigger impact, and are more difficult to fight. Cyber wars are very efficient for the attacker from a risk/cost perspective, and the attacks can be just as damaging as physical attacks. Cyber-terrorists will probably use these kinds of tools more and more, because they can be very destroying, and it is a "new" way to have a war between countries, as well as other groups. There are many types of DDoS attacks that can be launched. Often, when we are talking about DDoS attacks, we mean attacks on the TCP/IP protocol. The rivalry of the hackers leads to more attacks. The intruder community is loosely organized when it comes to development of attack tools. There are parallels to draw with open system development, because there are many developers and a large, reusable code base. Conclusions The two links mentioned in the introduction were misleading in the way that the Distributed intruder tools report (http://www.cert.org/reports/dsit_workshop.pdf) had no information at all about Mixter and Randomizer. The paper was written before the February 2000 attacks against the big Web sites (Yahoo etc.,). The other article (http://www.robertgraham.com/op-ed/magic-ddos.html) was one of the sources used for the memo (KEB&SS)MixterAndRandomizer040308. We read this one more time, and our conclusion is like last time; no direct information about the Mixter and Randomizer case. A good site for information on DDoS, is the University of Washington hosted Distributed Denial of Service (DDoS) Attacks/tools site (http://staff.washington.edu/dittrich/misc/ddos/). This site has a good archive of articles and other DDoS material. We believe that this site could lead to more useful information, but we have not yet examined the site.



Unknown (1999). Results of the Distributed-Systems Intruder Tools Workshop. Distributed-Systems Intruder Tools Workshop, Pittsburgh, Pennsylvania (November 2-4, 1999), CERT Coordination Center. Unknown (2003). 2003 CSI/FBI Computer Crime and Security Survey, Computer Security Institute. Vaughan-Nichols, S. J. (2004). Understanding and Preventing DDoS Attacks. Datamation.

Sources searched
Cert Coordination Center (www.cert.org) The Library, Agder University College (www.hia.no/hiabib) (EBSCO: "academic search elite", "business source premier", "regional business news", and "business source elite") www.google.com www.yahoo.com This memo

http://staff.washington.edu/dittrich/misc/ddos/ http://www.robertgraham.com/op-ed/magic-ddos.html http://www.wired.com/news/technology/0,1282,43697,00.html

121

This report is submitted to the University of Strathclyde in partial fulfilment of the regulations for the degree of MSc in Computer and Internet Technologies.

Mobile BackPack Client in J2ME
Murvin Bhantooa 200675927 Supervised by: Dr Mark Dunlop Department of Computer and Information Sciences September 2007

Except where otherwise expressly indicated the work reported in this document is my own. It has been performed during this course, and has not been submitted for assessment in connection with any other award whatsoever. Signed _________________________________________ Date ________________

ABSTRACT There has been much research going on collaborative editing of documents. Many new tools can be now downloaded that allow multiple people to actively work on a centrally located document. While much emphasis is put on desktop applications there is now a general trend for companies to provide open API's such as Google, BackPack and Flickr. Those functionalities which were reserved for desktop applications can now be ported to other systems including mobile handsets. This report covers the implementation of the open BackPack API to produce a mobile version that mimics the desktop one. The focus is however more on the collaborative note editing functionality.

ACKNOWLEDGEMENTS I would like to thank my supervisor Dr Mark Dunlop for his guidance and support while carrying out this project. I would also like to thank my parents for their support and encouragements.
Chapter 1
Introduction

1.1 INTRODUCTION This chapter describes the specification and plan for the "Mobile Client in J2ME" project. It starts with the original specification as set by the project coordinator. Then the intended aims of the project are listed followed by an outline of how those aims were achieved.

1.2 ORIGINAL SPECIFICATION

"BackPack is a web based system for writing and sharing notes as well as other items. BackPack comes with an XML based API so that new clients can be written that can read/write/edit items written on BackPack. Since many of us have spare time to kill on buses, trains etc - it would be handy to be able to edit items on the move. J2ME supports quite detailed java development on mobiles but the screen size is always a limiting factor. Extensions would include looking at visualisations to support collaboration - an editor that shows what other people have done through visualisation would be publishable. You will conduct a literature review into design of editors for mobile systems; develop a BackPack notes editor in J2ME to run on a range of mobile phones -- ideally tuned to different screen sizes using text visualisation/scaling techniques (optionally a server might be needed to reduce communication with phone - if needed this would be in PHP); test this application in collaborative settings using usability evaluation techniques."(Dr Dunlop M., 2007) 1.3 AIMS OF THE PROJECT As stated in the original specification BackPack is implemented as vanilla XML over HTTP. The major aim of this project is the implementation of a mobile BackPack client in J2ME. The BackPack API is rich and allows the manipulation of several object items such as pages, notes, reminders and tags. However the project requires the development of a collaborative notes editor. Our client application thus focused on the notes object. The building of a generic and extensible program however promoted a page centric design knowing that page objects can hold every other object stated above. The communication mechanism comprised of flipping XML data packets back and forth from the client to the server using HTTP as transport mechanism. Encoding and decoding of data into XML is a major requirement and thus an XML parser was

needed initially in the first prototype. But after implementation of the intermediate PHP server most XML manipulation was handled by using an extension known as SimpleXML in the scripts. The application also has to provide an intuitive interface to a mobile user allowing the creation, deletion, editing and sharing of notes. A user interface engine should enhance navigation, graphical display, and device functionality. Visualisation is an important feature of the program. The ability to crop up a whole array of information on the small screen is a determining factor for the efficiency of the application. Collaboration brings more complexity to the information feedback requirement of a client application. Knowing when a document was last edited and by whom is as important as the text itself. The application should convey all this meta-data in an effective and intuitive interface. The use of an intermediate server could reduce communication load with the mobile system. As stated in the original specification this should be in PHP. This server should act as a cache to hold object attributes as well as the valuable meta-data. The mobile system requests would thus target the intermediate server instead of the BackPackit one. The intended aims of the project can be summarised as listed below. 1. Gain knowledge of the design of current notes editor for mobile phones. 2. Investigate current visualisations techniques and user-interface engines that can enhance user interaction and make the user interface more intuitive. 3. Implement a mobile BackPack client in J2ME. 4. Optionally implement an intermediate server in PHP to reduce

communication load on mobile system and hold meta-data. 5. Implement visualisations that convey meta-data and enhance usability. 6. Submit the application to a collection of test cases to verify if the program functions well. 7. Test the application in collaborative settings using evaluation techniques.

1.4 WORK OUTLINE The very first step was to conduct a literature review in the design of editors for mobile phones. This background study brought much insight into the design considerations of user-interfaces and visualisation techniques used to make the application more immersive and intuitive to the user. User interface engines were also

investigated in terms of their architecture and portability while capturing the specific features that make them intuitive, flexible and powerful. The next task was the detailed specification of the project requirements. This section was achieved using a scenario-based approach to depict user requirements. Representing the use of the system with a set of user interaction scenarios makes the system's use explicit and thus orients design and analysis. The scenarios contained all the important characteristic elements that reflect the complexity of the system and unveil all underlying system requirements. Techniques such as activity diagrams and Use cases complemented scenarios as a means for specifying required usages of the system. With a set of requirements specification the next step was be the system design phase. This is where the logic of the application was investigated. Exploiting some of the modelling components of UML was an excellent way to depict ways to model the system logic. In terms of structure class diagrams were useful to reflect the objectoriented nature of the system. Object modelling and system architecture was essential to the efficiency of the program. Behaviour and data flow were also highlighted by using modelling techniques such as activity diagrams and flow charts. After that the first prototype was implemented in J2ME. The software construction approach lines up with the waterfall model with the exception that design and implementation had a degree of overlap. Successive prototypes interleaved with design to ensure that the program fulfilled all the initial requirements. A three phase approach was adopted. Initially the first prototype was implemented to lay down the base components of the system such as the communication mechanism and object modelling and abstraction. The prototype was evaluated and a new set of system requirements extracted from that for the next one. Then phase 2 incorporated the optional requirements such as the implementation of an intermediate server while fine tuning and rectifying the data structures from phase 1. Finally the last phase involved the investigation and implementation of visualisations to convey meta-data and enhance the application's usability. Testing of the program will also be a continuous process so as to rectify and fine tune the former. When the prototype is fully functional a running version was submitted to a set of test classes and then evaluated in a collaborative setting. This was achieved by using evaluation techniques such as questionnaires, think aloud experiments and user reaction

surveys. The feedback from the last evaluation produced a set of guidelines for redesign and future works.

1.5 SUMMARY The chapter has presented an introduction to the project along with its intended aims. An outline of the work plan required to achieve those aims was then highlighted. As specified the first step was the investigation of topics related to the project which is discussed in the next chapter.

Chapter 2
Literature Review

2.1 INTRODUCTION The project specification conveys in a few sentences the inherent complexity of the features involved in the implementation of such an application. The latter can be viewed from different perspectives. From a client or server point of view the underlying technical considerations are different. Furthermore mobile environments are resource limited and more issues such as usability and interface enhancement add up onto that. This chapter makes an attempt to investigate common issues and solutions pertaining to such a project. It starts with an introduction to J2ME and an explanation of how mobile applications use the libraries to implement different functionalities. Then the classical client/server communication is investigated with an interest in XML as data format. Common graphical user interface engines are also reviewed and analysed in terms of their architecture and system features. Architectural pattern of software development as related to the project is also discussed. On a less technical level issues relating to mobile interface design and visualisations are also discussed. Investigating current research in those domains provide an awareness of common problems relating to mobile environments and techniques used to react accordingly. A section on collaborative editing concludes the literature review. 2.2 JAVA 2 PLATFORM, MICRO EDITION (J2ME) The Java 2 Platform, Micro Edition (J2ME) also referred to as Java ME was designed by Sun Microsystems to enable developers to create Java applications for consumer and embedded products. Examples of such products are resource-constrained devices such as Personal Digital Assitants (PDAs), mobile phones and other consumer appliances. Those devices are programmed using the Mobile Information Device Profile (MIDP), a set of J2ME APIs. MIDP, together with the Connected Limited Device Configuration (CLDC) which is a set of Application Programming Interface (API) targeted at devices that have limited processing power, display and memory form a complete Java runtime environment. Figure 2.1 below shows the architecture of MIDP.

Figure 2.1 MID Profile architecture At the base is the Operating System (OS) of the host machine or mobile device. The K Virtual Machine (KVM) sits on top of the OS. KVM is clearly not the traditional Java Virtual Machine (JVM) but is rather a reference implementation of the virtual machine for CLDC. As such CLDC core libraries is next in the architecture followed by the MID Profile which provide libraries for developers to write applications. Some examples of such libraries are as listed below.

The Limited Connected Device User Interface (LCDUI) API to program user interfaces. The Record Management Store (RMS) API for permanent storage. The Generic Connection Framework (GCF) for networking with a server or another device. Developing application with a combination of those libraries enables developers to create highly interactive and flexible user interfaces. Many high level components such as lists, forms and textboxes are available in the LCDUI API. Those offer a standard way for managing a User Interface (UI). However low level components such as the canvas allow for more customised interaction like creation of custom components. The RMS API allows the system to retain data in permanent storage. Developers can thus produce MIDP applications that work even when the device is disconnected from the network. Connectivity is made possible by using the GCF which was designed to provide an extensible framework for input/output and networking. Mobile devices can thus stretch beyond their limited memory for networked data and files. Such client applications connect to wireless services using standard networking protocols. The

Hyper Text Transfer Protocol (HTTP), which is the same protocol for the Web, is the Connection standard that all MIDP devices support. Developers need only understand HTTP and the APIs for HTTP networking which offer an abstraction to the more complex operations involved for such communication. For example the MIDP device deals only with HTTP requests and responses without caring if data is transferred using Transmission Control Protocol/Internet Protocol (TCP/IP) or other protocols. Figure 2.2 below shows a conceptual overview of the communication of a MIDP client with an application server in (PHP) which is a server side scripting language.

Figure 2.2 Client/Server communications HTTP is used as a communication protocol where the mobile client sends HTTP request and receives back HTTP responses from the server. The networking APIs make HTTP programming easier. MIDP includes standard support for HTTP 1.1 and APIs for generating GET, POST, and HEAD requests along with basic header manipulation, stream-based consumption and generation of messages. The format of the communication can reside between the two extremes of a simple binary message or a complex XML one. Those two formats are referred to as extremes because they are inherently different from each other. Binary messages are small in size but messages sacrifice self-descriptiveness while XML ones are the opposite. Data Streams are used to read and write binary messages and because both the client and server must know the format of binary messages prior to communicate they are tightly coupled. On the other hand XML format brings space decoupling but requires more resources which are

actually very scarce on mobile devices. An architectural pattern, Model-ViewController (MVC), is discussed in the next section that exploits MIDP's capabilities while taking into account the constraints on resources such as memory, processing power and storage.

2.2.1 MODEL-VIEW-CONTROLLER (MVC) ARCHITECTURAL PATTERN

The MVC is an architectural pattern for implementing applications that reside in limited resource environments such as mobile phones. The pattern consists of three elements which are the model, the view and the controller. The model concerns the data present in the application, the view is about presenting and gathering this data and the controller governs the application logic. While being distinct all three elements are loosely coupled. By adopting this formal architecture the data, UI and logical flow are separated into distinct entities. This allows for their individual management giving the developer better control over the application and the ability to focus on particular aspects of it without affecting other ones. Figure 2.3 below shows the MVC pattern and the relationship between the elements. Note that the solid lines indicate a direct association, and the dashed lines indicate an indirect association.

Figure 2.3 MVC pattern The introduction of an intermediate component, the controller, may increase the size of the code on the client but the benefits gained using the MVC outweighs that cost. Some of those benefits are listed below.

Application logic is separate from data and presentation. Content and presentation are separate.

Presentation is not contingent on how the data is serialised.

The separation of the application flow from data and representation allows the developer to understand the system requirements just from the controller element. The latter isolates the flow and allows its manipulation with little or no disruption on any other aspect of the code. Similarly separating content from representation allows manipulating the look of the client without changing the data model in any way which is a more generic approach to convey information. This makes the UI more flexible to changes and amendments. The last point is about insulating the representation of data from how the model is implemented. For example the view is unaware if the model gets its data from the RMS or using HTTP or even from an in-memory cache. Those details are encapsulated from the view. This abstraction is particularly useful for mobile clients which experience interrupted communication and ad-hoc networks. The latter are usually used sparingly and thus such application need to remain usefully active when disconnected. Data may then be fetched from the local storage and commands shelved for server updates upon reconnection. The fact that connectivity is non continuous imposes some further limitations to mobile clients. The constraints on mobile networks are more significant than typical Web browsers. High latency, limited bandwidth and intermittent connectivity make that mobile client have to address additional objectives. For example connecting to the network only when required and consuming only required data from it can help in addressing those issues. Those communication limitations are however only a subset of the overall constraints. Mobile devices have limited memory, processing power and local storage capabilities. Furthermore small screens and reduced input capabilities can ruin the user's experience interacting with the UI. The next section introduces some interface design guidelines that address those limitations.

2.2.2 RULES OF MOBILE INTERFACE DESIGN

Making reference to Shneiderman's "Golden Rules of Interface Design" (1998) for general desktop application Gong and Tarasewich (2004) have identified a subset of those guidelines that carry over to mobile devices. They suggest that half of Shneiderman's eight interface design guidelines also directly apply to mobile devices. The rules are listed below.

Enable frequent users to use shortcuts Offer informative feedback Design dialogs to yield closure Support internal locus of control

The first rule relates to the frequency of use of an application by a user. When the latter is more familiar with the steps involved in interacting with the software he/she will develop a desire to reduce that number of interactions and achieve the task more quickly. Shortcuts are an excellent way to achieve that. The second rule also applying to mobile systems is to always offer the user with informative feedback. This can be in the form of sound such as beeps to indicate error messages, tactile with vibrations or visual like pop-up dialogs. The user needs to be guided and comforted by the system rather than being led by it. Third rule is about sequence of actions organised so that the user feels he has accomplished something. Dialogs that yield closure reassures the user that he is doing well and thus feels he is truly interacting with the system. This is the concept emphasised in the last rule that specifies that systems should be designed such that users initiate actions rather than respond to them. A satisfied user is one that feels that he is in charge and is controlling the system. There are also many additional guidelines that are relevant to mobile applications but those will be discussed more in the design chapter when building up the UI components. The guidelines will be observed to enhance the user experience and satisfaction. With the J2ME platform and design aspects investigated the next section covers XML and the structure of the Backpack API. 2.3 XML AND THE BACKPACK API XML stands for eXtensible Markup Language and was approved by the World Wide Web Consortium (W3C) in February 1998. XML is not really a new language but is more perceived as a meta-language. XML is designed to describe data and to focus on what data is. It is also used to define other languages such as eXtensible Hyper Text Markup Language (XHTML). XML creates documents that are well structured and as a result all languages based on XML are also well structured. What this means is that the data in XML format is more easily used. So, XML is the foundation for a whole new way of communicating across the Internet, because it enables businesses and their computer systems to communicate more easily. XML is becoming one of the most used

means of data transfer. 37 Signals, the company that launched the BackPackit web service, have fully grasped the inherent benefits of XML as a data exchange mechanism. This is why they have provided an easy-to-use XML based API that allows users to interact with one of their core products. With XML as a data exchange medium to encode and decode information a carrier protocol is now required to form a complete client/server communication mechanism. The ability to post XML data to an HTTP server or get XML back from it forms the very essence of the BackPackit web service. This is an easy way to become truly server independent because a client program does not need to know what HTTP server it is talking to, or even what operating system is running on the server. All that the HTTP server needs to do is have the capability to receive HTTP calls such as POST or GET and then pass the calls on to some form of program (PHP, CGI, Java Servlets, etc). The combination of XML via the HTTP calls can be viewed as a kind of middleware to link systems together. 2.4 GRAPHICAL USER INTERFACE ENGINES Graphical User Interface (UI) engines have emerged as a general trend in phone design that shifts focus from external display to user screens. Mobile phone companies have aligned to employ flash-like graphical user interfaces for handsets. The moves toward flash-like GUIs came as mobile chipsets experienced upgrades and phone makers increasingly sought to appeal to consumers with more dynamic and colourful GUI. Vibrant animated screens and vector graphic are fast emerging as an alternative to the fading simple bitmap user interface. TWUIKTM, Swerve Client and Flash LITE are examples of such UI engines. 2.4.1.1 TWUIKTM TWUIKTM Rich Media Engine (RME) is a multi-platform (UI) technology for J2ME devices and purposely optimized for the limited capabilities and constrained environment of mobile devices. TWUIKTM has a unique, flexible and modular architecture that allows its easy integration with operating systems, low level hardware and software functionality. The RME is a revolution in terms of rich graphics, multiple

media support and highly immersive animations. TWUIKTM strives to enhance navigation and bring advanced interactivity to mobile systems. Mobile web technologies inherit many of the characteristics of desktop web ones while remaining aware of resources limitations and constraints inherent in mobile systems. Technologies traditionally emerging from desktop programming have been ported and tuned for those constraints. An example of such technologies is widgets. Widgets are interface elements that a computer user interacts with, such as a window or a text box to access web data without the need to fire any browser. TWUIKTM the true reflection of this innovative mobile web technology. Its engaging animations and dazzling graphics give users the dashboard-like information they get from their favourite site. Coupled with engaging graphics and animations the UI engine is also highly portable to an array of mobile phones and operating systems. The supported platforms are listed as follows with Qualcomm BREW 3.x and Blackberry coming soon. J2ME/MIDP 2.0/CLDC 1.1 Windows Mobile 5.0/6.0 J2ME/Doja 4.x/5.x Notice MIDP 2.0 and CLDC 1.1 which form the latest configuration of the J2ME platform is fully supported by TWUIKTM. It on any Java enabled phone as well as Windows Mobile OS. A complete list of all currently supported handsets adding up to a total of 67 can be found in Appendix A. This includes among others the most pervasive models for Nokia, Sony Ericsson and Motorola. 2.4.1.2 ARCHITECTURE TWUIKTM has a modular architecture and allows developers to freely choose components they want to plug-in into the mobile applications. Examples of components are widgets, windows, forms and fonts. The Software Development Kit (SDK) comes in two flavours which are mainly LITE and STANDARD versions. Figure 2.4 below shows a visual representation of TWUIKTM's architecture.

Figure 2.4 TWUIKTM's architecture As illustrated in Figure 2.4 TWUIKTM has built in parsers that make the architecture flexible and applications portable, renderers that allow high graphics quality rendering and interpreters. TWUIKTM has a double buffering ability that constituent components of the GUI can exploit. When a component is requested for frame update TWUIKTM uses the additional buffer to paint the update on instead of directly on the underlying canvas. This improves the painting efficiency of rendering each screen update. TWUIKTM can also make use of hardware graphics accelerators to further enhance the user experience. This architecture makes it possible for applications to scale on a range of target platforms starting from low-end 39MHz ARM7 to high-end 208MHz ARM9. As stated earlier TWUIKTM RME consists of a collection of libraries centred on the core module itself. Rich animated FLASH-like GUI components are accessible to be picked freely from those libraries. Another feature is the ability to package portions of the whole library collection into an API package so-called TINY API . Those API can then be distributed as packaged JAR. As shown in Figure 2.4 TWUIKTM RME

currently provides the following main TINY APIs: TINY Form, TINY Window, TINY Widgets, TINY FX, and TINY Font. On a lower level TWUIKTM `s architecture is based on animation elements and systems. An Animation System is made up of animations elements which are linked to an animation engine. Furthermore Each animation system consists of one AnimationCanvas object, which works at the same rate as the animation engine, and also a set of Component objects. Animation rates of components are named as tick-peranimation (TPA). This is the number of ticks involved per animation step for the particular component. An important condideration is that a component object can work at a different animation rate as compared to the animation engine or AnimationCanvas object but it should be a sub-rate of the latter. For example in an animation systems having an animation engine x frame per secons (FPS) any created components working at y TPA will have an actual frame rate of x/y FPS. There are three types of events that are supported in TWUIK: canvas events, component events and FX events as illustrated in Figure 2.5 below.

Figure 2.5 TWUIKTM's Events and Handlers Generated events have a set of corresponding event listeners. For example instances of canvas events are handled by the CanvasEventListener interface implementer. Such events are canvas-related events, animation-related events, key-events, and pointer-

events. The AnimationCanvas also has a specific component known as the MainInputHandler. This component acts as a container to handle input events directly among all the other components it contains. Key and pointer events are typical input events handled by this component. Similarly to CanvasEventListener the ComponentEventListener interface implementer handles instances of specific component events. TWUIKTM has a universal listener model. Only one listener is responsible for all component events. Each event has an event ID which corresponds to the component that is responsible for trigging the event. This is how the event listener can thus differentiate between different events fired by different components. The third type of event supported in TWUIKTM is FX events. However TINY FX consists of three types of effects engines: transition FX engine, motion FX engine, and transformation FX engine. Those three engines in turn generate different FX events and are handled by three corresponding event listeners' interface implementers. 2.4.1.3 SAMPLE SCREEN SHOTS The following screen images gives an indication of the type of interaction and user interface that TWUIKTM is capable of. Figures 2.6, 2.7 and 2.8 show how text entry can be handled in such a way that a whole array of information spread over multiple tabs can be entered without the user exiting the current window. Using a tabular structure similar to desktop applications the information is logically grouped together while still remaining distinct.

Figure 2.6

Figure 2.7

Figure 2.8

Tiny Forms and the FX Engine can be used to create mode and mode-less pop up windows and dialogs with transparency, transitions, and shapes. Those transparent popup windows that overlay the current window shifts the user's focus on required parameters in a truly elegant manner as shown in Figure 2.9 and 2.10

Figure 2.9

Figure 2.10

(TWUIKTM's Dialog Box) Figures 2.11 and 2.12 give other examples of overlaid screens which is a typical aspect of applications built using TWUIKTM.

Figure 2.11

Figure 2.12

(TWUIKTM's Overlaid Screen) TWUIKTM's Powerful user interface is not limited to text entry and pop-up transparent windows. Many other features such as rich forms, "skinnable" themes and navigation widgets make this API a really attractive one both from the user and the developer's point of view.

2.4.1.4 TWUIKTM SUMMARY TWUIKTM is a powerful GUI engine with graphical rendering capabilities that create Flash-like user interfaces with advanced animations and effects. With its modular and flexible architecture customizable UI components can be included that are specific to device or application requirements. Having support for a huge range of mobile phones and operating systems the API is highly portable and cross platform. 2.4.2 SWERVE CLIENT

Visualisation and animation on mobile handsets can be implemented by using 3D graphics libraries. Swerve Client is a fast and efficient standards based 3D graphics solution available for virtually all mobile handset software execution environments. By using a technique known as model description data Swerve Client applications can generate and manage interactive 3D scenes screen. Building interactive 3D can be very complex and code intensive and this technology gives and abstraction to developers to create content more effectively without the need for detailed knowledge of such techniques as 3D rendering. However Swerve Client also provides a low level immediate mode API that offers more flexibility and freedom for expert graphic programmers. Swerve Client is the world's first and leading commercial implementation of JSR 184, the Mobile 3D API for J2ME devices from the Java Community Process. Leading mobile players such as Motorola, Siemens and Samsung have adopted this implementation as their engine. This is reported due to its ability to combine small file sizes with console quality graphics and its portability. Supported platforms are namely J2ME, BREW, Symbian, Linux, and Pocket PC.

2.4.2.1 SWERVE CLIENT EDITIONS Two editions of Swerve Client are available for licensing which are namely Swerve Client SR and Swerve Client ES. The former Original Equipment Manufacturers (OEM) with the lowest cost bill of materials (BoM) for the delivery of console quality games and other applications on mass-market devices. No additional graphics libraries are required as the Swerve Client SR renderer supports the full range of screen sizes and colour depths available on all mobile devices. On the other hand

Swerve Client ES makes use of OpenGL ES to execute many of the rendering functions required in JSR 184. OpenGL ES is a low-level API for embedded graphics between software applications and hardware. In this implementation OEMs benefit from increased graphic quality delivered by dedicated hardware accelerators and high-level scene tree API for Over The Air (OTA) deployment and low cost development. 2.4.2.2 SWERVE CLIENT SUMMARY Swerve Client delivers High quality interactive 3D experiences in very small compact content files and fully compliant with the JSR 184, the Mobile 3D standard for J2ME Java devices. It also supports multiple hardware acceleration solutions and major wireless execution environments including J2ME, BREW, Symbian, Linux, and Pocket PC. 2.4.3 FLASH LITETM

MacromediaTM Flash LiteTM 1.0 was launched by MacromediaTM, now Adobe, in 2003 aiming at the Japanese leading mobile network provider NTT DoCoMo in house Java-based technology i-mode. Flash Lite was designed to run Flash based content on the latest generation of mobile phones and devices. The next version of Flash LiteTM, Flash LiteTM 1.1, was released in 2004 with major improvements such as network access optimisation and integration. This version is however still based on FlashTM 4 structure which helps reduce the processor demands of the player thus relieving load on the host operating system resources. Flash LiteTM can be implemented in two main models in Flash LiteTM enabled mobile devices. When Flash LiteTM is a separate media application installed on the mobile device it represents the stand alone model. Examples of such implementations are large applications and games that are processor intensive. In the other model Flash LiteTM is a plug-in that integrates the mobile phone browser. This model is referred to as the browser based model. Flash content can thus be accessed OTA without requiring a separate application. The advantage is obviously less demand on the processor. Sony Ericsson uses such implementation model. Flash LiteTM was designed as a solution to a gap in the technologies already present on the mobile device market. MacromediaTM claimed that its new product was meant to fulfil a need that existing technologies had not fully addressed. The design of

Flash LiteTM made is appropriate for rapid prototyping. Its design allows for the efficient and rapid creation and deployment of content and interfaces to mobile phones. Mobile companies can thus customise their devices with powerful user interfaces, content, and applications. A mobile concept can be easily and rapidly tested and evaluated by using a set of sketched with limited functionality. Flash LiteTM also supports OTA management of content. So even the mobile device has been purchased content modification and creation is possible. All those features would give a competitive advantage to carriers and distinguish them on the market. 2.5 VISUALISATION IN MOBILE SYSTEMS As highlighted earlier in this report mobile devices are inherently limited in resources such as memory and processing power. Those are restrictions that need to be considered when developing visualization applications. High quality graphics and animations are indeed impressive and enhance the user's interaction with the application but they increase the demand on resources. Furthermore there are also Human Computer Interaction (HCI) considerations involved in dealing with such graphics. Having dazzling graphics should not mislead users by being too complicated and disruptive. UI should remain intuitive and promote navigation. Chittaro (2006) has identified six major steps that provide designers with a methodology for creating mobile visualisation applications. The steps are listed below. Mapping. That concerns how information is visually encoded. Visual features such as lines, colours and animations represent data graphically. There need to be a consistent mapping defined between data objects and visual objects that is consistently applied throughout the application. Selection. There need to be an optimal balance in visualising data. If insufficiently done users could be lead to make suboptimal decisions. On the other hand too much information conveyed can be bulky for limited spaces such as mobile screens. Presentation. An intuitive and convenient way of displaying information on available screen space is vital for making the interface easily understandable and clear. The layout of elements should be appealing to the user while respecting its mental model and perception of the system.

Interactivity. This concerns the means of exploring and rearranging the visualisation in the device itself. Interactivity with visualisations enhances the user's engagement with the system. Human factors. It is of utmost importance that users are able to quickly recognize and easily interpret a visualisation. This involves the science of human perception and cognition as adapted to program interfaces. Evaluation. Visualisations need to be tested rigorously on users. This will reveal the degree of effectiveness they have brought to the application. User evaluation procedures are an important aspect of software development as regards to mobile applications. The presentation problem is inherent in mobile visualisations and the next section introduces new approaches in this domain. 2.5.1 EMERGING MOBILE SOLUTIONS 1. Visual references to off screen areas. Due to the small size of mobile phone screens it is not possible to completely show the context of a view, i.e. the whole overall picture. However interactive visual references can augment the restricted view making users aware of some parts relevant to the current task. For example, arrows in a map's detail can indicate the direction of Point Of Interests (POIs) outside the view area and specify their distance with a number. The Halo technique which uses arcs to estimate POI distances from a given view is an implementation example of this concept. 2. Intuitive navigation techniques. Another approach involves the traditional scroll and zoom functions already in use in mobile phones but also takes into account the device input techniques. For example, ZoneZoom automatically divides a smart phone's context view into nine areas and maps them onto the keypad. By pressing a number an animated zoom-and-pan is produced to the corresponding area. This allows an easy one handed navigation with the interface and the technique can be recursively applied to support multiple zoom levels.

2.5.2 MOBILE VISUALIZATION RESEARCH Research is underway for better visualisation of data for mobile applications. Five data types have been identified which are subject to visualisation. They are text, pictures, maps, physical objects and abstract data respectively. This section covers the techniques being currently tested for text, pictures and abstract data as they are more relevant to the scope of this project. 1. Text Mobile devices suffer from restricted textual presentation due to their small size. This can affect interaction and make tasks such as selecting from long menus or reading lengthy texts cumbersome and painful. Ongoing research in this area is focused on text presentation that requires very limited screen space. For example, leading presentation scrolls text horizontally on one line, while rapid serial visual presentation (RSVP) displays text in which each piece of information is displayed briefly in sequential order. RSVP is already used in mobile devices to enhance the reading of text (Wobbrock, Forlizzi, Hudson & Myers 2002). 2. Pictures While text presentation is problematic in mobile phones browsing large pictures is even more a hassle. Mobile screens have limited resolution and colour depths and viewing photos, diagrams or charts can require much scrolling and zooming operations. Research by de Bruijn & Spence (1999) has suggested that RSVP could be implemented effectively to search and browse electronic information. 3. Abstract data Abstract data can be temporal such as weather information or stock's share prices. Calendar based application such as agendas or to-do lists are current in mobile devise. However, visualizing a simple one-month calendar on current small phone displays can be impossible. The fish-eye technique is a solution to such problems. If offers the ability to focus on content expanding its details without losing the global context. Datelens is and example of an implementation of such technique .It is a unique calendar interface for PCs and Pocket PCs developed at the University of Maryland uses an animated fisheye representation of dates coupled with compact overviews and integrated search.

2.6 COLLABORATIVE DOCUMENT EDITING The current BackPack desktop version supports many collaborative features. Clients can share/unshared pages, edit page items concurrently and view last versions of updates. The writeboard object which is particularly tuned for collaborative note editing also supports text highlight and comments. However collaboration can be hindered by the number of people involved in editing a particular note or document. Multiple updates can lead to race conditions depending on the technology used to synchronise the online resource. The use of locking can affect usability in certain circumstances. The desktop application also does not suffer from additional constraints such as screen size in mobile systems. Techniques such as non-intrusive visualisation are preferred over traditional one which involves presenting information over secondary displays. In this technique the visualisations are overlaid over the screen data itself to enhance the navigation and support the given task. 2.7 SUMMARY This chapter has provided an insight into the topics relating to our project. Investigating current research and the technologies involved in the implementation sheds light on the global picture of the task. The next step is now to produce a set of system requirements for the mobile application. This is where the project diverges from the waterfall model. The next three chapters combined relate the evolution of the project through implementation of three successive prototypes. Each chapter starts with a set of requirements, describes the design decisions involved in the implementation and concludes with an evaluation based on the initial requirements. Each prototype evolves from the previous one with added functionality and implementation of additional features to ultimately form our last running version. The next chapter reveals more on this methodology.

Chapter 3
Requirement Specification & Design Phase 1

3.1 INTRODUCTION Studying the original specification for this project shows that there are some components referred to as optional that form part of the overall requirements. The implementation of an intermediate PHP server and advanced visualisation to support collaboration are examples of such aspects that promote the overall design to an upper quantum level. Their implementation however induces more functional requirements and system design. The optional features make the overall requirements of the project inherently flexible. This is obviously in sharp contrast to the use of the waterfall software construction methodology and thus a more flexible three phase approach to requirement specification and design has been adopted. The next section highlights the principle behind this methodology and the expected outcomes from the first phase. 3.2 METHODOLOGY This approach can be regarded as a combination of prototyping with structured development. The prototypes implemented at each phase will be used to evaluate and refine the specifications for the next phase. It exploits the fact that the project has a flexible requirement specification and thus varying levels of difficulty and complexity. At each phase a set of requirements drawn from activity scenarios form the input for design and prototyping. The application thus built can be studied and evaluated to form a new set of requirement for the next phase. The latter will also be more complex with successive addition of optional project requirements. This chapter outlines phase 1 of this methodology. It starts with problem specification and uses a scenario based approach to identify functional requirements of the initial prototype. System design features are then discussed and it concludes with a technical evaluation of the prototype built and inputs for redesign. 3.3 USER INTERACTION SCENARIOS

Carroll & Rosson (1990) defined a user interaction scenario as a story about people and their activities. This definition reveals the user-centred aspect of scenariobased methods. Functionality depicted from scenarios are thus in the context of use. The following problem scenario lays the structure for analysing system requirements in a

deliberately underspecified way so that the system complexity and functionality will progress arithmetically with further scenarios in the successive phases.

Problem Scenario 1: John the student John is a computer science student at the University of Strathclyde in Glasgow. Same as all his fellow students John frequently have written group assignments where all members have to collaborate and produce a report on their findings. As such a research topic on the evolution of mobile internet browsing has been assigned to John's group which include three other members which are Jane, David and Nancy respectively. Even if those members are engaged in the same course they all have different modules taken as electives. This makes that their time-tables are different and they do not share the same free slots as that of John. The research requires that each member investigates a sub topic and the group to produce a common report that contains all the concepts studied separately. Right before leaving the lecture John's group has suggested a division of work and John has been assigned the role of coordinating the final draft. This will include keeping a continuous flow in the literature while merging all separately covered concepts. Referencing the same material may also cause too much overlapping of the sub topics and bring duplication in the text. As the coordinator he has to ensure that all group members are not late in their respective topics so that submission in the tight deadline is possible. He needs to monitor the progress individually and as a group so as to depict if something is wrong and perhaps encourage, motivate and guide his group members. John realises that he will require the assistance of a collaborative authoring tool that will help him monitor all parameters involved in such tasks. While Google Documents and Backpack are proven online collaborative authoring technologies John wants this service to fit his context and be thus able to collaborate anytime and anywhere. The desktop applications obviously do not offer him this freedom and he thus opts for a mobile version of the collaborative tool. He realises that an implementation of Backpack on mobile phones already exists and hopes this will carry through all the interesting and helpful features already present in the desktop one.

John's problem scenario has described the setting, actors and task goals that form his problem domain. Those aspects of the scenario have implications for the system design. The scenario has highlighted the requirements that John has to fulfil

being the project coordinator. Those requirements can be refined further and made more concrete by further extending the scenario into an activity scenario as shown below. It relates how the mobile Backpack tool can help John with his tasks and helps us depicts the requirements of the system.

Activity scenario 1: John the student So as to use the BackPack mobile notes editor John has to first open an account from his desktop. Having done so he can thus identify his unique key which will recognise him on the mobile application. For collaborating on the same document he also prompts all the group members to do the same through an e-mail. Because of the tight time constraints John wants to be able to access the document anytime and where ever he may be. For example when going to university on the morning bus, during any free time he has or even sitting on a bench in the near green gardens. So having downloaded the mobile Backpack on his mobile phone John quickly fires the application. Being a first user he is prompted for authentication. He has to enter the API key he was assigned which can be found on his backpack account web page. He is also prompted to enter a username and password that will identify him for latter use. When opening his Backpack account from his desktop John has already created a document, added sections for each group member to input their sub topics and finally shared this document to the rest of the group. He is not concerned whether they will access the document via the desktop web page or even on the mobile version. What he wants is to be able to monitor the whole progress at a glance and also know what is being covered by which group member. John sees a list of notes that he recognises to be present on his web page. He selects the appropriate one to open the Backpack editor. It shows all collaborators working on this particular file and their connection status. While all other group members are offline John instantly sees how Nancy and David have already added some inputs to their sections. On the other hand Jane has not even started anything. He also noticed that Jane last edited the document in the morning but did not bring any changes. He concludes that she might be in lack of inspiration and decides to send her a text to ask if she needs any help.

The activity scenario can be investigated in terms of the features involved in John interacting with mobile Backpack. The claims associated in the text are identified in the claims analysis below. The consequences are divided as positive and negative which are

respectively the upsides and downsides of the features. Those claims will contribute to critically analyse and refine the prototype during evaluation.

Claims analysis 1: John the student scenario Situation Feature Possible Pros (+) or Cons (-) of feature

Opening Backpack account from the + Eliminates several screens would that desktop task be done on the mobile system. + Gives user a desktop point of access to pages and notes. Entering API key from online account for + Ensures mobile client is properly authentication authenticated as the key is unique and only known to the user. - Can be a tedious task as the key is a long sequence and has to be masked when entered. Opening editor from notes listed on + Allows user to focus on notes only mobile without the need to bother about other page items and relations. + Adheres well to user's mental model. Pressing a selected item to expand it. + Visualisations could show if the note was edited by collaborators upon selection without requiring loading the editor. View collaborators and connection status + Give meta-data that enhances

collaboration awareness.

Scenarios and claim analysis are particularly useful when evaluating the system and producing points for refinement. Having a more enhanced user-interface with few screens enhances the user's exerience but let us now focus on the functional requirements of the mobile application. Those will form the aspects that the first prototype has to support initially. Viewing John's scenario from a functional point of

view we can translate what John expects from the system into a list of requirements. More precisely the system; 1. allows user to enter his credentials 2. displays a list of pages from John's site 3. allow a page to be selected 4. display all notes present on the page 5. opens an editor upon selectin a note 6. allow manipulating the note Those requirements are made clear wih the use-case diagram below, figure 3.1 involving the system and 2 contributig actors which are the user and the server.

Figure 3.1 Login Use Case Scenario Following the principle of an incremental approach this prototype will attempt to cover the functional requirements of the first phase while remaining utterly simple and flexible. This version allows the manipulation of notes with the application being

actively online. Due to ad hoc network communication inherent in mobile systems it is obvious that both online and offline backpack should be supported. The ability to monitor network connectivity and react as per required is essential in such medium. Serialisation issues will however crop up in such implementation adding to the complexity of the program. This initial prototype lays the foundation for further versions to build upon and improve. First the establishment of a communication mechanism is of primal importance. Data structures and flow also need to be designed further. This initial design phase will however emphasise on interacting with the BackPack web service and connecting to the server to send commands and data back and forth. A rough and textual user interface will serve as our application to model the available operation involved in the note object. But first of all the XML Token is required for authenticating a given client prior to communicating. The next section covers how to create a free BackPack account, grab the token and explains the interchange requirements of the API. 3.4 THE XML TOKEN & BACKPACK API A client can be identified on the BackPack server by a SHA1 security token that is unique to him. This token can be viewed in the account details when a user opens an account with backPack. The service token is found at the bottom of the account page. The BackPack API is very clean, simple and logically constrained. Small XML packages are sent up to logically defined URLs on the server for each method, and packets of XML data are sent back down for consumption. The BackPack API does however require an additional header to be sent, which will identify the format of the data being sent. That header is X-POST_DATA_FORMAT which should be set to "xml". The API is well documented with excellent examples on the BackPack site. The introduction to the API defines the interchange requirements and presents a handful of examples showing both the posted data, and the corresponding response. The following examples show typical requests with Curl with the following server responses.

1. Complete query example with Curl: The request
curl -H 'X-POST_DATA_FORMAT: xml' -d '<request> <token>40bd001563085fc35165329ea1ff5c5ecbdbbeef</token> </request>' \ http://david.backpackit.com/ws/page/1

The response
<response success='true'> <page title='Ajax Summit' id='1133' email_address='ry87ib@backpackit.com'> <description>With O'Reilly and Adaptive Path</description> <notes> <note title='Hotel' id='1020' created_at='2005-05-14 16:41:11'> Staying at the Savoy </note> </notes> <items> <incomplete> <item id='3308'>See San Francisco</item> </incomplete> <completed> <item id='3303'>Meet interesting people</item> <item id='3307'>Present Backpack</item> </completed> </items> <links> <page title='Presentations' id='1141' /> </links> <tags> <tag name='Technology' id='4' /> <tag name='Travel' id='5' /> </tags> </page> </response>

2. List notes for page: /ws/page/1234/notes/list The request
<request> <token>202cb962ac59075b964b07152d234b70</token> </request>

The response
<response success='true'> <notes> <note title='My world!' id='1132' created_at='2005-04-30 19:15:55'> It's a pretty place </note> <note title='Your world!' id='1132' created_at='2005-04-30 19:20:00'> Also pretty </note> </notes> </response>

3.

Complete post example with Curl:

The request
curl -H 'X-POST_DATA_FORMAT: xml' -d '<request> <token>40bd001563085fc35165329ea1ff5c5ecbdbbeef</token> <item> <content>Hello World!</content> </item> </request>' \ http://david.backpackit.com/ws/page/1/items/create

The response
<response success='true'> <item completed='false' id='5'>Hello World!</item> </response>

A user is identified by accessing a url that belongs to the user, like http://david.backpackit.com, and by passing in the web service token as part of the XML request. As stated above the token which represents the user's password for use with the web service is a 40-char SHA1 hash and can be found on the user's account page. BackPack has a surprisingly simple desktop interface that shields the user from the complexity of the underlying mechanism. This simplicity makes the product easy to understand and quickly adopted. BackPack can be used in a personal way but its capabilities are really stretched when used in a collaborative setting. BackPack's simplicity which is carried over very well into the XML API will be determinent helping us to hook it in our mobile application. Notice in example 1 the additional header with value set to "xml" sent to specify the type of data sent. Apart from the personal token used for authentication the last part of the url acts as a method locator that identified the command requested. More precisely "ws/page/1" will return all information from the user's page bearing the identification number 1. Another example is ending the url with ws/pages/all. This method locator will instead return all pages found on the user's site. Figure 3.2 below shows the network components involved in a simple client server interaction with XML data packets sents over HTTP.

Figure 3.2 Client/server network components XML messages are at the complex end of the range of message formats. However as useful as it may seem for mobile applications to converse over networks the MIDP specification does not require XML support. Java XML API support for mobile devices is fragmented and developers are free to add XML support to a MIDP application by incorporating additional libraries. Two popular XML processing models are the Document Object Model (DOM) and the Simple API for XML (SAX).However the Java Community Process (JCP) is about to release the Java Specification Request 280, XML API for JavaTM ME. This JSR is designed to provide a general purpose XML API for the next generation of mobile devices. The request will support both SAX 2 event handler-bases parsing and efficient DOM-style processing. XML support does also come at a cost in memory, processing and storage but event-based parsers such as SAX are considered more appropriate than DOM. But before delving into XML parsing models and manipulation lets take a look at the system logic as modelled in the following section.

3.5 INTERFACE DESIGN The screen shots below reflect the interface design for the first prototype. Firstly the user has to enter the correct credentials to be authenticated on the backpack server. The login screen, Figure 3.3, requires both a username and the API key for proper method call. Upon connection the user is now presented with a list of pages available on his profile as shown in Figure 3.4. He/she can thus select the appropriate page to

view/edit/delete or create notes pertaining to that page. Figure 3.5 shows the options available to the user. In the case a note is selected the application opens an editor where the title and body can be updated as shown in Figure 3.6.

Figure 3.3 Login credentials

Figure 3.4 Selecting page

Figure 3.5 Selecting note

Figure 3.6 Editing note

3.6 APPLICATION LOGIC The flow chart below models the logic of the application. Initially the user will be prompted to enter his credentials for authentication. The system will then initiate a web

connection to check the validity of the XML token supplied. Upon validation pages are the pulled down from the server into memory. The application is page centric and all manipulations revolve around page objects. Note objects are so far not individually supported in the API and are thus not directly accessible. The user can however decide to load particular notes from chosen pages. Upon clicking on a note the editor will open holding the note attributes such as title and the body. He can then view and edit content as desired.

Figure 3.7 Application logic

The system has to pull information from the server and also send updates if the user saves a note file. This communication involves sending data in XML format as stated earlier. The next section covers the components of the communication mechanism which is at the heart of the program.

3.7 COMMUNICATION MECHANISM The core of the client application is undoubtedly its communication mechanism. It is also highly prone to optimisation as effectiveness is a major concern here. Being a classical client/server communication the mobile client inevitably adopts HTTP, the well known request/response protocol. With portability being an important requirement the communication need to be through a connection interface that is guaranteed to be implemented in mobile hosts. J2ME provides an extensible framework for i/o and networking known as the Generic Connection Framework (GCF). The Connector class implemented can create any type of connection such as file, http or datagram but the only Connection interface required in MIDP 1.0 is the HttpConnection. So our mechanism consists of a Connector object that opens and HttpConnection connection with a given URL. The BackPack API specifies that we need to include a custom request header: X-POST_DATA_FORMAT (set to the value of "xml") in order to have our requests properly identified on the server. Optionally the MIME Type is also specified. This is shown in the sample code below.

http = (HttpConnection)Connector.open(url); byte[] data = xml.getBytes(); http.setRequestMethod(HttpConnection.POST); http.setRequestProperty("X-POST_DATA_FORMAT", "xml"); http.setRequestProperty("Content-Type", "application/xml"); OutputStream oStrm = http.openOutputStream(); oStrm.write(data);

After initiating the web communication data is sent either as part of the URL or through a separate stream depending on the method used. After the request has been sent over the network the server sents back a response. Opening an InputStream allows the data to be flushed back into an internal byte array. This data can then be handled by the XML parser to be interpreted.

InputStream iStrm = http.openInputStream(); int length = (int)http.getLength();

The sample code above shows how a stream is opened on the HTTP connection to read the data. The second line attempts to parse the connection length into a local variable. However this length can not always be determined so an alternative way of reading back data is required. This is made possible by using ByteArrayOutputStream objects. The data is thus read character wise into an internal array before being handled as required. When using input and output streams data is sent as byte arrays and does not carry and self-description. However this same data is encoded and will be digested by the server to be interpreted. The system packages the data in XML format and then converts the String object into binary to be flushed over the network. The next section sheds some light over the XML manipulation logic. 3.8 XML MANIPULATION LOGIC The BackPack API specfies that any proper request to the server requires the additional custom header as stated earlier. Basically three elements form a complete data package ready to be sent. They are the XML header, the url defining the command action and the body of the request. While the latter can sometimes be optional the first two parametes are obligatory for a meaningful request. The API gives a list of method locators pertaining to different tasks. For example updating a specific note, id 5, found on a page id 1234 needs the user's url followed by "/ws/page/1234/notes/update/5". Thus every action fired from the system needs to idenfity the purpose of the command and append the corresponding method locator and possibly any relevent data as body. In the update case the title and body attributes are required. However to reduce code duplication and take a generic approach they would all call the same method passing 2 String parameters, the method locator and the xml data pertaining to such task. As shown in the sample code below the method locator is first appended to the user's rl and the xml data passed as parameter is concatinated to the always required token into a request while respecting the XML format.
public void initiateWebCommunication(String methodLocator, String xmlData) { final String uri = url + methodLocator; //concatinate xml node and all child nodes

final String xml = "<request>" + "<token>"+this.apiKey+"</token>" + xmlData + "</request>";

...
The XML data String parameter thus need to be defined according to the event recorded in the system. Listing notes from a given page requires no additional data and the parameter would thus be null. On the other hand events such as updating a page requires both title and body. The String would thus look like as in the sample code below:
//package update data String xmlData = "<note>" + "<title>" + tfTitle.getString() + "</title>" + "<body>" + tfBody.getString() + "</body>" + "</note>";

3.9 DATA LOGIC XML is an excellent transport mechanism and the BackPack API returns data in such format. While it defines the interchange rules for communicating with the BackPack server it is not a concept that maps well into the object-oriented world of Java. The system would rather view data encapsulated as objects with defined behaviour. Defining the rules for those objects gives an abstraction to state what needs to be done without everytime caring on how it is done. This whole concept of information hiding thus allows us to manipulate objects in our application and thus bring the highly desired encapsulation in the system design. As stated earlier the BackPack API provides a number of ways to access user data. For example, all pages can be pulled back by querying a specific URL. The XML data holds the page attributes as well as , as shown in the following sample code taken from the API's documentation:

<request> <token>202cb962ac59075b964b07152d234b70</token> </request> <response success='true'> <pages>

<page scope='personal' title='Example page' id='1134' /> <page scope='personal' title='Movie Titles' id='1136' /> <page scope='friends' title='Ajax Summit' id='1133' /> </pages> </response>

A suitable class abstracting a page consists of the three attributes and corresponding accessor and mutator methods among others. Given there can be several pages on a given URL the data has to stored in a collection object. J2ME provides the Vector class as an excellent and flexible way for storing and manipulating collections. The figure below shows a vector holding page objects.

Page 1

Page 2

..... Page vector

Page N

String title

String scope Page object

String id

Figure 3.8 Page Object Model Similarly to page objects notes also requires being instantiated. The attributes required for manipulating notes is the title and the body. Both can be updated but an extra variable also needs to hold the id of the page that the note belongs to. This will allow the system to package the request to the correct note. This attribute is required as every note is tied to a page and cannot be manipulated separately. Figure3.9 below represents a note object with the variable type defined.

String title

String body

String id

String date

String pageId

Figure 3.9 Note Object Model Data pulled back when querying for a note also gives the note id and date created attributes as shown in Figure 3.9. With objects defined to represent the data points in the system the next section covers how data flows between those objects.

3.9.1 DATA FLOW

The very purpose of this mobile application is the manipulation of online notes. The note object is an abstraction to provide methods for such tasks. Ultimately the user is interested in having a list of notes to pick from and possibly edit. To perform the system needs firstly to pull page information from the server, the application being pagecentric. Digesting the XML sent back thus populates a vector holding all pages visible to the user as shown in step 1 in the figure below. The page vector now holds page objects with useful information such as page Id and title. Upon selecting a particular page the system initiates a web command and all notes present on that page are sent back. Those notes populate another vector. The user is now presented with a list of notes pertaining to the page he had chosen. He can thus edit a particular note and the system shelves command to the server to update its version.

Figure 3.10 Data Flow

3.10 PROTOTYPE EVALUATION

This first prototype is rather rudimentary but serves well its purpose for establishing the fundamental components of the system. We now have our communication mechanism set up and can effectively interact with the BackPack while keeping an online connection. However a key consideration would be to implement local storage of data such that the system supports offline BackPack. A mobile user can be interrupted anytime when using the text-editor. A continuous communication can not be assumed all the time the system is active. The application need to operate against a

local copy of the notes when a web connection can not be established. Note updates can thus be shelved and passed up to the BackPack server upon reconnection. This whole concept of serialisation also dramatically increases the efficiency of the communication channel. When acting against a local copy only updated pages need to be downloaded thus reducing the amount of data flow. This feature will be investigated in the second prototype to bring relief on the mobile application. Surprisingly the UI also can be enhanced with local storage support. Currently the user has to enter a very long API key every time for using the editor. This entry is obviously long and error-prone. The system should be able to retain this key and provide and alternate easy authentication such as a name and password. However this UI enhancement is purely driven by the support for serialisation. The focus for the next prototype remains on the application logic.

3.11 SUMMARY

This chapter has covered the design decisions involved in the implementation of the first prototype. The user activity scenarios have provided a list of system requirements to be used as an initial input. This version is simple but has laid the ground for further improvements which obviously will be implemented in the next prototype. The following chapter explains further what new features have been implemented and how the project is evolving.

Chapter 4
Requirement Specification & Design Phase 2

4.1 INTRODUCTION Using an iterative approach it can be assumed that as the system evolves into successive prototypes the functional requirements of the application build up upon previous ones. That means that the requirements derived from the interaction scenarios of the previous chapter are carried forward into our second prototype. Obviously the support for offline BackPack introduces new requirements too. More precisely the system should be able to monitor the web communication and respond accordingly. When online the local updates can be sent to the server directly. On the other hand commands need to be shelved if the user is offline and sent back upon reconnection. Serialisation also enables the mobile application to mirror a feature present on the desktop one. Storing versions of a given note allows the user to flip back to older ones and also compare changes to a given text by a collaborator. The list below represents the additional requirements of the system. It should; 1. allow the user to work both online and offline 2. monitor the web communication and send server updates upon reconnection 3. update local copy when connecting to server to synchronise data 4. allow user to compare current version of a note to older ones to view amendments

Those requirements all emerged due to the support for offline backpack and the whole concept of serialisation. This additional feature of our system will in fact alter the data design and application logic. A new notion of synchronisation between the data sources need to investigated. But before examining how the application logic is affected the next section reveals an update that is worth considering before moving on.

4.2 BACKPACK API UPDATE This second prototype coincides with the release of a new BackPack version. In their endeavour to improve and promote one of their core products 37 signals have brought some enhancements to the page object. The API has thus been extended to reflect the new page layout. New features such as reordering of page contents and creation of separators are now supported. Our system has adopted a page centric model but still has concern only for manipulating notes objects. It is observed that the notes functionalities have remained the same. Many updates thus do not affect the application

logic. Without diving deeply into major differences that are not relevant to the scope of our project some points can be notes.

Differences from the version 1 API Page belongings position items on the page. Items including notes can be positioned using the "belonging" attribute. While this does not affect the manipulation within the editor it could be considered as an option in future versions. Promoting a note could reflect its relative importance. Page descriptions (bodies) were removed. The old page descriptions are now notes. The XML parser will thus need to be modified to identify notes and page descriptions which seem to have the same opening tags. However so far only page title and id have been used to pull notes from particular pages. Use the Content-Type:
POST_DATA_FORMAT: xml application/xml

header instead of X-

An alternate header is now required for requests to be properly recognised on the BackPack server. This can be considered as the major syntax change.

Version 2 of the BackPack API is a logical extension of the previous one with additional features and no drastic changes. Jeremy Kemper, administrator of the BackPack Customer Forum claims that the API is largely the same with extensions here and there to reflect the new page layouts. He also asserts that both Content-Type and XPOST_DATA_FORMAT headers are allowed but we will stick to the new recommended header to be on the safe side. With all the updates in mind let us now investigate the network topology with the system now supporting offline BackPack.

4.3. NETWORK TOPOLOGY UPDATED It could be argued that including permanent storage is totally independent from the network topology adopted. However desktop BackPack supports a version feature that is somehow useful and interesting in terms of usability. Users are able to view previous note versions, compare change in texts and view what collaborator was responsible for this change. To process such information the system needs to keep record of what user is responsible for what updates. Thus metadata is also required for these added functionalities. While working on stand alone a mobile system could as well store internally an array of such text versions but what if a note is being shared by multiple users. The API does not offer any method to access this metadata from the BackPack server. Thus including an intermediate server in our topology will allow the mobile system to capture such information from this mediator. As shown in the figure below the server running PHP has its own database of valuable information which can be further analysed.

Figure 4.1 Network Architecture

Apart from a usability point of view the implementation of the intermediate server also radically changes the communication mechanism of our mobile system. The mobile system is now no longer responsible for synchronising with the BackPack server. It only needs to communicate with the PHP server and is thus not bound anymore to the XML format. As stated in Chapter 2 XML self descriptive capability comes at a price on the system processing and memory. The use of binary data will reduce load on the mobile system. Thus XML parsing now occurs on the PHP server and binary data sent back to the mobile client. Before investigating the implementation of the PHP server and the data logic the next section shows how the client application logic has been updated with support for local storage. In Chapter 2 we investigated the model-view-controller (MVC) architectural pattern and on of its benefits were that presentation is not contingent on how the data is serialised. It is about insulating the representation of data from how the model is implemented. For example the view is unaware if the model gets its data from the RMS or using HTTP. Notice how this notion is carried forward in our transition. The application now gets data from the intermediate server. Even if the type of data format has changed the system still deals with page and note objects without caring how those are formed. This encapsulation is in line with the architectural pattern adopted. 4.4 APPLICATION LOGIC

Figure 4.2 Application Logic

With the support for permanent storage the application logic is now more complex than that of the previous version. When the program loads the MIDlet first checks if this is a first time user. This situation will occur if there is no record of the API key and user credentials in the RMS. The screen presented will thus be one of a first time user. Otherwise a simpler username/password authentication is required to log on to the system. Right after that there is a need to synchronise local data with the online one. Many scenarios are possible. In the simplest case it might be that the local copy is still up to date with the server one and thus no download or upload is required. The system loads the local copy into memory. But it could also be that there is data waiting to be sent to the server from the last time notes were edited and commands were shelved. This will require upload of information to the server. Moreover shared notes may have been updated when the mobile client was offline meaning that the latest versions need to be downloaded. Unfortunately the fact that those scenarios are not independent of each other adds to the complexity of the system. The latter needs a way to depict what updates to send first to prevent race conditions and maintain data integrity. A time stamp is obviously required to process commands accordingly.

4.5 LOGIN INTERFACE DESIGN BackPack currently offers 4 types of user accounts which are referred to as the premium, plus, basic and free accounts. As many of its counter companies its marketing model allows users to open a free account and prompt them to upgrade for more functionalities and productivity. Examples of restrictions on the free account are limited number of pages and minimum file storage capacity. But there is one restriction worth considering. All other accounts other than the free and basic plan have Secure Sockets Layer (SSL) support turned on by default. It is a commonly-used protocol for managing the security of a message transmission over the Internet. Therefore a call over https for such accounts is required. Otherwise the connection will give a redirect answer back to the client. It was observed from the first version that entering the API key everytime the application was used was not efficient in terms of usability. Therefore an initial screen capturing all required authentication details could record information such as the API key, account type and user credentials thus allowing the system to store those permanently. The screen shots below show the initial screen layout referred to as the

"Login Settings". Notice the change in emulator to the Sony Ericsson K750. While still running with relative low screen capabilities such as resolution and space this emulator gives a realistic view of the program running in a mobile system that shares commonalities with a large range of Java-enabled mobile phones.

Figure 4.3 Initial Login Settings This one off login screen is obviously for the first time user and will capture its credentials for future reference. The figure below shows the login screen the user will use as from then on. It is simple and really less cumbersome than the one from our previous version. This sheer simplicity will allow a familiar user to quickly login and get access to the BackPack notes. A technical aspect worth highlighting here is that no second form is required for this screen. Instead by changing the title and removing the API Key text field and user account type list it creates the illusion of a new window. This reduces an extra class required to handle login and login settings. If the user wants to modify his credentials or has upgraded to another plan a "Login Settings" option should repopulate the same screen as the initial one-off one for modification.

Figure 4.4 Simple Login 4.6 DATA DESIGN As stated in the application logic section the system now has to determine if there are any saved authentication records. This new data point needs to be abstracted so that the system deals with a corresponding object rather than data stored as bytes in permanent memory. A client object is thus created that encapsulates all of the mobile client credentials allowing useful methods to be called on the data. This class should allow manipulation of the user credentials as per required. Figure 4.5 below represents the Client class responsible for representing a mobile client in the system.

Figure 4.5 Client Data Model

The new client is loaded into memory when the MIDlet starts. The password attribute has the sole purpose of authenticating any user interacting with the software. The apiKey and username on the other hand are essential for web communication and proper BackPack API calls. The account type is also kept so as to determine whether a call on http or https should be made upon communication.

With a local copy of all pages and page items stored on the mobile system there is a need of determining whether an object, e.g. a note was modified since the last time the user edited it. The result of synchronisation will then make explicit if the object is dirty or not, dirty being used to refer to its non-consistent state with the online version. Data abstraction from the first prototype need thus be revisited. Let us take the page object first. The object diagram below illustrates the changes to our previous object model.

Figure 4.6 Page Object Model

Attributes such as scope, id and title have remained unchanged. Those are explicitly required for proper API calls except for scope. The latter reflects the scope of the page. E.g. the scope can be personal where the user does not intend to share this page or perhaps public on the opposite. However the most interesting updates are the Boolean "isDirty" and String "contentLength" attributes. To determine if a page was updated since the last time the mobile user edited the page there must be a way to compare the specific variables that have changed with the updates. There exist an HTTP header, the "Since-Last-Modified", that can specifically determine that. Making a request with that additional header should produce a reply only if that particular page was modified since the date specified. Unfortunately the BackPack server does not recognise this header. So instead of keeping the date of the last edit the content length of the page is stored. This can then be compared to the content-length header of the requested page to determine if

the page was modified. If the content lengths differ then the page is considered to be dirty and the attribute isDirty is set to true. Keeping a notice of such state is important for proper visualisation. The state of a dirty page, highlighted with an orange bar, will not change until the user opens that page to view the changes. But the page can be updated in contents in the meanwhile but will still be flagged as dirty. In the same fashion as pages, notes also need to be monitored for their states. The class diagram below shows the changes that the new issues have introduced in the note object model.

Figure 4.7 Note Object Model

Similarly the attributes such as title, id and body have been carried forward from the previous model. The note object also keeps track of the parent page id. This parameter is required in most API calls concerning notes. Notes are also monitored for their state with the isDirty parameter. The determining factor is the length of the body. While this is not the best way of comparing for changes it is the simplest implementation of this feature.

With an appropriate insight in the revisited data model let us now have a look at the data flow of the entire system involving all actors. The overall picture reveals to be very interesting with the additional layer of the intermediate server.

4.7 DATA FLOW With the addition of our intermediate server the data flow in the system has also evolved accordingly. Let us go through the steps required for loading page objects into the mobile system's memory. Figure 4.8 below represents the data flow involved in such a task. Being a page centric application most task involving notes will be dealt by using the page objects first to locate the notes. In step 1 the application requests page

data using the client's credentials. As stated in the previous section the data is abstracted as a client object in the mobile system. However this request is now handled by the intermediate server. The mobile client thus triggers a PHP function responsible for fetching the XML data from the BackPack server and parsing it to send back meaningful information to the system. This data is first flushed into the RMS as shown in step 2. The system then populates the page vector from the just saved local copy. This data can be used to populate a page list and update a given screen to capture further events fired by the user. Let us assume that a note item is updated from a given page. The next step will be to update the RMS accordingly as shown in step 5. Furthermore if the system is still connected the server updates need to be sent again through the intermediate server in step 6.

Figure 4.8 Data Flow Model

This sequence of data flow promotes the update of the RMS before any manipulation in live memory through the vector collections. This ensures that even the server connection is lost a local copy persists that can bring back the mobile system to a previous stable version. The Note vector is not shown in the figure above but it is only manipulated through the page objects themselves. Notes and other objects such as tags and items and reminders are all items present on a page object. Thus any manipulation of page items will follow the data flow as shown above with the difference of one more data entity extending from the page vector. The next section reveals some design considerations on the server side now implemented.

4.8 SERVER SIDE DESIGN The introduction of an intermediate server was an optional requirement of this project and PHP was the implementation recommended in the requirements specification. The intermediate server can of course cache client data and hold its own database of meta-data which will be used as input for the visualisation interfaces of the last phase of this project. The main achievement of adding a tier to the architecture is that the mobile system now receives meaningful information that can be easily interpreted. XML parsing is handled by the PHP scripts rather than the resource limited client. Let us investigate how our mediator will handle such tasks starting with the BackPack API calls in the next section.

4.8.1 PHP SERVER API CALL The intermediate server is now responsible for calling the appropriate method calls depending on the corresponding task. There are quite a few ways to implement remote method invocations. Command Uniform Resource Locator (CURL) is and example of such techniques. Curl is free and open software that compiles under a wide variety of operating. Most major functions desired when connecting to remote web servers are included in curl, including POST and GET form posting, SSL support, HTTP authentication, session and cookie handling. Libcurl is the corresponding library that users may incorporate into their programs. The same holds for PHP. PHP 5 does not support CURL by default and this extension has to be added. To start a curl session the curl_init() function is used. Options for the curl session are set via the curl_setopt() PHP function. Once you have the options set execute the request with the curl_exec() function. So our communication mechanism has now evolved from XML parsing module on the mobile client to PHP scripts invoking remote server commands through CURL on the intermediate server. The following sample code shows the function responsible for managing the communication:

The method takes 2 parameters which are the URL that points to the method location and any data that needs to be parsed along. The data is of course in XML format in our case. Notice after initialising the session with the curl_init () method the options such as data to be sent and special headers are specified. The first section of this chapter highlighted the subtle differences inherent in the second release of the BackPack API. This is why the additional header, Content-Type, is now required instead of the former custom one. The function returns data pulled down from the BackPack server in the expected XML format. Up to this point no parsing has been implemented. Thus this data needs to be digested before it is sent back to the mobile client. The next section reveals how PHP5 manages that through an extension.

4.8.2 XML PARSING IN PHP5 Just like BackPack many web services return API calls in XML format, so it is just handy to know how to parse these results quickly. With PHP4 there is a need to rely on some large parsing library to get the job done or deal with overly complicated PHP functions, but PHP 5 has a great extension called SimpleXML. The SimpleXML extension provides a very simple and easily usable toolset to convert XML to an object that can be processed with normal property selectors and array iterators. So the data returned by the curl function just has to be fed as a parameter to create a

SimpleXMLElement object. The sample code below shows how SimpleXML is used to extract the page id and titles from the raw XML returning all pages present on a user's URL.

To understand how this data is extracted we also need what tags are being used to nest the XML elements. The sample response taken from the BackPack API shown below illustrates precisely how page elements are nested within pages elements. This syntax is important so that the SimpleXMLElement object created upon that XML data knows exactly where to fetch particular information of interest. For example to fetch the page id it will have to go through the parent tag `pages' and then get the attribute of the elements of this parent tag.

<response success='true'> <pages> <page scope='personal' title='Example page' id='1134' /> <page scope='personal' title='Movie Titles' id='1136' /> <page scope='friends' title='Ajax Summit' id='1133' /> </pages> </response>

4.8.3 THE GLOBAL PICTURE Lets us shift for a moment from our XML standpoint and have a view of the global picture. The system now involves a mobile client, an intermediate PHP server and the target BackPack server. To help visualise the data flow the aid of standard UML will be most appreciated. Figure 4.9 below shows the data flow involved in a particular scenario where the mobile client is requesting for all pages present on a user's URL. The diagram is highly self descriptive. Observe however how method calls are delegated from the mobile client through the intermediate server and then finally to the target method location. The figure also implies that some components like the mobile

client have to wait for data to come back before taking any further decisions. This implies much thread synchronisation and will be explained further in the implementation chapter.

Figure 4.9 Activity Diagram 4.9 PROTOTYPE EVALUATION & SUMMARY This chapter has discussed the design features of the second phase of the project. It showed how both the data model and data flow have evolved from their previous states. Additional considerations brought by the implementation of the PHP server have also been analysed.

The second prototype has brought the application to an upper level of complexity in terms of data flow and implementation issues. The fact that XML parsing is now handled on the intermediate server brings utmost relief to the mobile client. This is an excellent step towards performance. The updated data model also now permits some degree of meta-data to be kept without the need of database records on the PHP server. The latter however remains what I think is the best option to produce data for our visualisations. While the intermediate PHP server has been successfully implemented there is one particular issue that has raised a major concern for the coming third phase of the software development. The fact that BackPack server can communicate with both mobile and desktop clients requires that the intermediate server be aware of all updates happening to the online resources. For mobile clients this is straight forward. Our server could keep a database of all meta data pertaining to mobileserver transactions. However desktop clients bypass our server and there is thus a synchronisation issue in keeping data consistent. The PHP server needs synchronisation to the millisecond. This unforseen aspect of the project brings it to a level of complexity which is not within the scope of our time resource. Unfortunately this issue also prevents the implementation of notes version which was a feature of the system requirements. While storing arrays of notes versions is still possible on the mobile client the issue of consistensy and synchronisation still crops up to ruin the beauty of this feature. But at least 2 versions of the notes will be compared with only the latest one stored in the record stores. This comparison will be on the fly with downloaded data as opposed to stored one. The next chapter reveals the design issues in the implementation of visualisation to enhance user interaction.

Chapter 5
Requirement Specification & Design Phase 3

5.1 INTRODUCTION The last phase of the project design is really all about usability and the use of visualisation to enhance the user's experience with the application. The first two prototypes have resulted in a fully functional mobile client where the user can edit, create, delete and share notes. This chapter covers some design issues pertaining to the visualisations implemented in the application and the use of some extra classes to enhance the HCI part of the project. The colour code adopted for visualisation is highlighted through the use of screen shots.

5.2 META-DATA LIMITATION

The last prototype evaluation has shed light on an unforeseen limitation of the project. The fact that both desktop and mobile clients will interact with the same online resource requires that desktop updates be also recorded on our intermediate PHP server. With of use of databases meta-data information could be easily captured upon and stored for interpretation. The mobile system is designed to access that server prior to hit the backpack one and all updates such as the author, date and time can easily be captured. On the other hand the intermediate server is totally unaware of desktop or other clients updating the resources. A solution would be a dedicated server that monitors the backpack one up to the millisecond to record any relevant traffic and update the PHP database and maintain consistency. So with such limitations lets take a look of what can be achieved on the client side that gives some user feedback but still remains consistent with the overall topology.

5.3 COLOUR CODE In our literature review we highlighted that one of the rules that Gong and Tarasewich (2004) have identified about mobile devices is to offer informative feedback to the user. Now a mobile user manipulates note objects directly by creating, editing, deleting and sharing them but has no control over the same functionalities for the pages. Once the application starts they can only view the online pages and select them for interacting with the notes. This is perfectly inline with the requirements of the project as the user is concerned with notes editing. What would be helpful is to enable the user to know if a page was updated since the last time he viewed it from his mobile handset.

This could indicate that some objects on that page were modified. A note could have been added or another one deleted. It could also be that some other objects such as tags and page content have been updated but right from here the user can decide to view a page or not depending on its status. Using a colour code is a very convenient way to flag a page's status. It takes little screen space and is non-intrusive. Let us go through some screen shots to demonstrate this concept. If the pages have not been updated since the last time the mobile user viewed them they will all bear a green flag as shown in Figure 5.2 below.

Figure 5.2 Same Page Visual Feedback

Using the green colour maps well to the fact that there are no updates in particular to flag. If the user was waiting for a text update he can quit the application right from here without having to go any further. On the other hand if a page was edited the green colour changes to orange to flag that. In Figure 5.2 below the graduation page has been updated and thus the visual feedback react as such.

Figure 5.2 Edited Page Visual Feedback

There are two other possibilities at this stage. A page could also have been deleted or a new one added. In the former case the deleted page will simply not appear in the list. But for a new page a new colour is required. A blue flag shows such event as shown in the figure below.

Figure 5.3 New Page Visual Feedback This colour code is also ported to the notes object for the corresponding events. The figures below show the same events occurring for notes object. They represent same and remotely updated notes respectively. This helps to maintain a consistency in the visual feedback.

Figure 5.4 Same Note Feedback

Figure 5.5 Edited Note feedback

The visualisation is simple but remains consistent with the overall architecture. The variable comparisons are being made solely on the client system. The next section highlights the design features of the classes used for informative feedback. 5.4 USER FEEDBACK In sharp contrast to the abstract window toolkit of the standard Java 2 Edition, J2ME offers limited graphical user interface components. Components such as dialog boxes overlaid over the screen are not supported. The application requires much web communication and thus need to frequently alert the user if a problem has occurred or if the data is being downloaded. The alert screen should then offer the user a choice of action. CLDC supports Alert components as shown in figure 5.6 below.

Figure 5.6 Downloading Feedback

Unfortunately they do not have menu choices built in. Their sole purpose is to indicate and event and then fade away. This is where our Dialog class emerges. This class creates a custom alert screen while still offering a menu of choices for the user to select. The figure below shows how this concept has been implemented. For example when the user tries to delete a note a confirmation screen pops up prior to that.

Figure 5.7 Confirmation Dialog

The Dialog class will be explained further in the Implementation chapter.

5.5 CONCLUSION This chapter has given an overview of the last phase of the project which focused on the HCI side. The use of screen shots has showed how a user can be supported in his task by visual feedbacks from the system. Informative feedback was also a major concern with confirmation screens and feedback screens interweaved with the main screens. This chapter concludes the design part of the project. Many classes have contributed in making those features possible. This is investigated in the next chapter about implementation.

Chapter 6
Implementation

6.1 INTRODUCTION This chapter covers the implementation phase of the project. It can be divided into two main categories as client classes and server scripts respectively. While it is not possible to go through all implementation issues the most important codes are highlighted. But before drilling into the details of the codes the next section gives an indication of what type of resources are required for the software to run. 6.2 HARDWARE & SOFTWARE REQUIREMENTS Our application architecture is a tiered one. Having implemented the intermediate server two different sets of requirements can thus be highlighted. The software being implemented in J2ME requires a Java-enabled mobile system to be deployed. More precisely the mobile phone needs to support MIDP2.0 to be able to host the software. This is the only thing a user needs to be aware of for using the system. There are no further restrictions for the mobile client. The application makes use of very little space and will fit any common mobile handsets. Moving up a tier we know that the server was implemented in PHP. However the use of the SimpleXML extension now requires that the web host has at least PHP 5 versions running as PHP4 does not support SimpleXML. Another requirement is that CURL extensions are also enabled on the web host. For some reasons they are not available by default. Now that those technical specifications have been highlighted the following sections covers the most important implementation details starting with the client side. The implementation has been carried out over three prototypes and the following details refer to the last running version. 6.3 CLIENT CLASSES The mobileBackPack class The client system consists of 11 classes. Let us start where the program execution starts itself. This is obviously in the constructor of the main MIDlet. The class responsible for creating the MIDlet is the mobileBackPack one. This is where all record stores are created, streams initiated and instances of all required classes created. At this stage the collection objects such as the vectors are also initialised. The sample code below shows part of the constructor.



...
The code is pretty self descriptive. It is all about initialisation and object creation. It is worth mentioning a couple of points here. Notice how the main MIDlet is passed into all the other objects being created. This is how the other classes have a handle on the running MIDlet. This is highly desired so as to be able to alter the main Display which is private to the main class. Then the Display object can be shared among all other classes being the only available per application. After initialising the objects the next task to handle is to detect if there is already a client object present on the mobile host. This would be true if the application has been used already. As covered in the design section the first time user is showed with a first time login screen where he has to enter all required coordinates such as username, password, API key and account type. Any login after that will remove the one-off screen with a simpler one requiring only a username and a password. On the code level this means that the constructor has detected that user credentials already exist in the system. Then the last thing is to set the current display to the appropriate login screen. This is handled by the startApp() method as shown below.

Let us now have an overview of this class and understand its importance.

The APILoginForm class The sample code below shows the structure of the attributes present in this class. As expected it extends the Form class and provides graphical user components required for input with a handle on the running MIDlet.

public class APILoginForm extends Form implements CommandListener { private mobileBackPack midlet; private Command cmExit, cmOk; private boolean showLoginSettings; private TextField tfUsername, tfPassword, tfAPIKey; private ChoiceGroup cgAccountType;

...
This class is the first one to set the application connection status. When the user presses the Ok button the application makes a request to check for web connection and then sets the status as appropriate. The application will evidently react differently in the 2 cases. The networking implementation details are handled by the Request class which will be discussed shortly. Before that lets us investigate how a user is authenticated when trying to login. The isValid() method handles that feature of the program. The MIDlet will accept the user only if it returns true. First of all the method checks for empty text fields and return false if such. The sample code below show how this is implemented.

...
...
Notice how the user is given visual feedback through a screen alert before the boolean false is returned. If the components are not empty the text field values are thus compared to the stored credentials. Upon authentication this class then compares all the stored pages with the corresponding online ones in terms of their page-content attribute. This is achieved by retrieving all pages from the RMS into live memory in a page vector. The system then loops through each page element, extracts the page-id attribute

and calls a script on the server side with that attribute as parameter. The code below shows how it all starts in the loop.




The initiateWebCommunication method from the Request class handles this script call. Three possible scenarios can be expected from here. First the page id is not recognised on the server-side meaning that the page has been deleted from the online site. Secondly if recognised the script returns the content-length of that particular page. This length is then compared to the local page to determine if there have been some changes on the server-side. This comparison is essential for the proper flag colour to be appended to the page. One last point worth highlighting about this class is that the intermediate server returns data in a certain sequence. For example single page information is returned as a string like scope¦id¦contentLength¦title. This data still have to be digested and interpreted. This is handled by the
writeFromServer2PageVector(String

serverResponse)

method. It loops through all the characters until the delimiter

character `¦' is found. The string is thus split into the four attribute values it really represents. Once the pages have been checked the application sets the focus to the page list item from the PageImplicitList class.

The PageImplicitList class This class follows the same logical pattern as the previous one except that this case the comparison is for note objects. When a user selects a page from the list the application loads note objects into the note vector and loop through it to compare the note content

with that of the online copy. Similarly to pages many scenarios are possible and the code checks for destroyed notes and newly added ones also. The sample code below shows how the comparison operation is carried out. Notice how the pattern strongly resembles that for page comparison.

...
The main difference is the parameters sent for the web method call. To be properly identified on the backpack server the page Id containing the particular note is also required. Thus the selected page title is compared to the page vector values until a match is found. The id is then used to add to the parameters for calling the get_note_body.php script. The class then populates the note list with the corresponding colour flags based on the content comparison. The user can now select any note or create one or share one. Once a note has been selected the application opens a note editor. The latter is a simple editor with limited basic functionalities. Two interesting classes however remain to be discussed. The Request class is the one responsible for handling all networking communications. The Request class The following sample code shows the attributes belonging to the Request class.
public class Request { private mobileBackPack midlet; private String php_url; private String responseStr;

private HttpConnection http;

...
Communication is done using the HTTP protocol. The most interesting method probably initiateWebCommunication(). The sample code below shows how this method starts.


...
This method takes only two parameters but can still handle any type of operation. The first parameter refers to the PHP script that needs to be called. The other one is all extra data that is required as parameter to the current operation. For example for adding a new note to a page the page id, note title and note body are required. All this data is sent as parameter to the call. The next step is to open an Http connection to the given URL and finally digest any data sent back. The last class worth discussing is the Dialog class. While very small and simple it turned out to be a very useful one.

The Dialog class To create a new Dialog, we need a DialogListener to act in response to user input. In our implementation, DialogListener is a class, not an interface. In this way, we simply override any method necessary without implementing all the methods. In the code below, we use an anonymous inner class as DialogListener, and override the onOK() method.
Dialog dl = new Dialog ( "Destroy note", "Are you sure you want to destroy the selected note?", Dialog.OK | Dialog.CANCEL, midlet, new DialogListener() // Anonymous inner class. { public void onOK() { //get note id and page id of selected index for(int i = 0; i<midlet.getVcNotes().size(); i++) {

...
The onCANCEL() method need not be overridden as it will not do anything by default as can be observed in the DialogListener class show below.
class DialogListener { public void onOK() {} public void onYES() {} public void onNO() {} public void onCANCEL() {} public void onCONFIRM() {} }

With an overview of the classes on the client implementation the next section covers that of the intermediate server. It gives an overview of how data was packaged and appropriate method requested from the BackPack server. 6.4 SERVER SCRIPTS On the server side all the scripts include the script MobileBackpack.php. This file holds all the methods required for interacting with the backpack server and is thus worth examining. The content of the script is a single class. The server-side also has been built

in an object oriented fashion. This main class has all required methods such as list_pages(), show_page() among many more to cover all the corresponding functionalities present in the mobile application. We saw that variables were sent as parameters to the script. Let us take an example script to understand how the main class is instantiated and the required method called. The sample code below represents the script to destroy a backpack note.

<?php include('MobileBackpack.php'); $username = $_GET['uname']; $token = $_GET['tok']; $page_id = $_GET['pageId']; $note_id = $_GET['noteId']; $client = new MobileBackpack($username, $token); $client->destroy_note($note_id, $page_id) ?> First of all we need to include the main script where the class is found. The variables sent as parameters are then extracted and passed into local variables. In this case page Id, note Id, username and token are required. Then a client object is created with the username and token as parameters. The destroy_note method is then called for this object. This code is surprisingly simple and yet the implementation is powerful. As highlighted in the design section the intermediate server makes call to the backpack one using CURL functions. Another script worth some explanation is the one that returns all pages present on the user's URL. The code below shows part of this script.

...
$result = $client->list_pages() ; $xml = new SimpleXMLElement($result);

for($i=0; $i<sizeof($xml->pages->page); $i++) { echo $xml->pages->page[$i]['scope'];

echo '¦'; echo $xml->pages->page[$i]['id']; echo '¦'; $page_result = $client->get_page_content_length($xml->pages->page[$i]['id']); echo $page_result['download_content_length']; echo '¦'; echo $xml->pages->page[$i]['title']; echo '¦';

} The method call $client->list_pages() returns all page details into an array. Using SimpleXML exact page attributes can be extracted. The script loops through all data to send back the page scope, id, content_length and title separated by a delimiter character. However the page content_length has to be determined. This is done by extracting the header value `download_content_length' from the result sent back from another method call within the loop itself. The method get_page_content_length($xml->pages>page[$i]['id']) indeed returns an array of headers and the next step is to extract only what is required from it. 6.5 CONCLUSION This chapter has covered the main details of the client and server implementation. While is it not possible to scrutinise every piece of code the main classes have been highlighted. The next logical step is to test the application and see how it reacts to different cases. The next chapter covers the test strategies adopted and the software evaluation details.

Chapter 7
Testing & Evaluation

7.1 INTRODUCTION

This chapter covers the testing and evaluation aspect of the project. It starts with the testing strategies adopted through the project development. A set of test cases are then investigated to show how the software reacted to user inputs. Conclusions were drawn from the outputs. Then the chapter covers the evaluation of the application which was carried out in a collaborative setting. It highlights the evaluation materials needed to perform the experiments and conclude on a discussion of the results found. Finally a set of recommendations are extracted from the results analysis.

7.2 TESTING

A systematic approach was adopted throughout the project life-cycle. The concepts of verification and validation were carefully implemented so as to effectively reduce the number of errors occurring in the program. Throughout the different design decisions verification can resume at asking a simple question; "Are we building the product right?". Validation on the other hand resumes at; "Are we building the right product?". Those 2 questions may seem fairly simple but they summarise 2 powerful concepts that need to be followed through the program construction. Unit testing was carried out all through the implementation phase. The design of separate methods made it possible for them to be tested independently using a driver program to ensure that they behaved as expected. The testing strategy adopted here was mainly that of the well known black box. This modular testing allowed confirming that the module/method would react according to what was expected. Care was taken that the inputs for the tests were small enough to be time-effective but large enough to test thoroughly the program. Temporary output statements were used to compare actual results with those expected. This strategy was helpful to reveal the values of intermediate variables and anonymous variables during program execution. With all those small units of codes or modules thoroughly tested another test strategy was adopted when interconnecting some or all of them in the driver. White box testing was implemented here. The structure of the code was monitored through test inputs so as to possibly exercise all possible paths in the codes. The construction of all those separate modules is of primal importance for getting the right results and making the program reliable. When the program was completed and thoroughly debugged

another level of testing was then required. A number of test cases were designed. The focus of Black box testing is to investigate the I/O behaviour and if the result can be predicted for all output, the module passes the test. The test cases below illustrate input, the output investigated and the conclusions drawn. It has been tabulated for simplicity.

Input task 1. User starts application

Output

Conclusion

The first time screen pops The system has identified up. that this was a first time user.

2.

User

enter

correct Application informs user The that files are

application

has web

credentials

being established connection.

downloaded. 3. User enter wrong Application flags

wrong The validation process has been tested.

credentials 4. User selects a listed page

entered credentials

All notes pertaining to that Note download module is page are listed. operating well. 3 Application allows for

5. User presses menu on A the notes screen

menu

containing

options pop up.

selecting options from the menu.

6. User tries to delete a note A confirmation screen pops The application supports up asking if user really deletion of notes. wants to proceed. 7. User adds a new note to The note editor opens with Application a given page a default title and body. has already

supplied a title and body for new note. It supports note addition.

8. User shares a note with a The share screen opens to Whole page is shared on collaborator get e-mail of collaborator the server-side. Application supports this feature. 9. A page is added on the A new page appears on the Application adds any new desktop version list with a blue label page added from server.

10. A page is deleted on the The deleted page does not Application deletes local

desktop version

appear in the application pages not found on server. page list

11. A page's not item is The page and note label Application detects when updated on the desktop both turn orange there has been a note update 12. A page is shared on the No apparent changes. desktop version. No visual feedback of

shared attribute has been implemented.

13. User presses cancel The screen flicks and the The cancel option is being when the application is operation do not yield and supported. downloading 14. User invites application exits. many The share screen opens to The application supports get e-mail of collaborator. multiple collaboration. All invited. 15. User tries to unshare There is no option to The unshare functionality is from a collaborator. unshared. not actually supported in the mobile client. collaborators are

collaborators on a note

Table 7.1 Test Cases The results from the test cases show that application behaves exactly as expected. All note operations are being supported. Changes made on the mobile client are reflected on the desktop version and vice-versa. There is however a feature that has not been implemented. The user can not unshare from a collaborator from the mobile handset. This can only be done using the desktop version. Another thing related to collaboration is the lack of feedback on whether a page is being currently shared or not. This does not however hinder any all other operations. After the software has been thoroughly tested the next step is to evaluate it in collaborative settings. 7.3 EVALUATION Due to the nature of the project the software had to be evaluated in real settings. A set of evaluation was carried out. It consisted of a set of preliminary tasks that the participants were asked to follow. 6 participants were involved in these tasks. After a

briefing of the purpose of the experiment they were asked to perform preliminary activities such as creating an online backpack user account to get their own XML token and start the mobile version which has been deployed on their own mobile handsets. After getting used to the system a think aloud experiment was carried out. Participants were then given exact tasks to perform and asked to think aloud as they were doing them. After that they were prompted to complete a set of post-task questionnaires to capture their impressions of the application. 7.3.1 USER BACKGROUND SURVEY The user background questionnaire was designed to get data concerning the type of participants engaged in the experiment. It was important to define if the users were in a novice category or were comfortable using their mobile handsets for activities other than text messaging and phone calls. This information will be useful for interpretation of results. The artefact below shoes the structure of this survey. First the participants had to sign a consent form: User Consent Form

Study Goals This research is being conducted to explore the usefulness, ease of learning and use, and satisfaction experienced by users collaborating on a given project using their mobile handsets. This prototype simulates a mobile collaborative note editor. The results of this study will be used to refine the prototype interface and functionalities. Procedures You will begin by filling out a brief background survey. Then, after reading some brief instructions you will be asked to work through several tasks designed to introduce you to and test how easily you interact with the features of the mobile backpack. These instructions will be deliberately brief, in order to see how well the system can support use on its own. After the tasks, you will be asked to fill out a user reaction survey, and then will be given an opportunity to ask any questions you have about this study's goals, procedures, or outcomes. Throughout your interactions with the mobile backpack, we will be collecting several sorts of information: we will be capturing what happens on each screen of your mobile handset as you interact with it. One or more evaluators will be taking notes, measuring task start and stop time, and noting any problems that you encounter. To help us gather as much information about mobile backpack as possible, we also will be asking you to think aloud about your goals, expectations, and reactions to the system as you work. At times we may prompt you to tell us what you are thinking. We realize that providing a think-aloud commentary may be distracting, but it is important for us to know what you are thinking as you carry out the tasks. Participant Consent

Your participation in this experiment is entirely voluntary; there will be no remuneration for the time you spend evaluating it. All data gathered from the usability study will be treated in a confidential fashion: it will be archived in a secure location and will be interpreted only for purposes of this evaluation. When your data are reported or described, all identifying information will be removed. There are no known risks to participation in this experiment, and you may withdraw at any point. Please feel free to ask the evaluators if you have any other questions; otherwise, if you are willing to participate, please sign and date this form: ________________________________ Name (print) Signature ________________________ Date

After that the background survey captured user details: User Background Survey

Thank you for agreeing to participate in the study. Before we begin, it will be useful for us to know more about your background--your experience with mobile phones, technology, and any commuting web sites, etc.,. This will help us to better understand your interactions and reactions to the system. Remember that all personal data will be treated confidentially and reported with no identifying information. General Information: Name Occupation Years resident in Glasgow How many years have you been using mobile phones?

Age Years of Education How many years have you been using computers? Describe a typical weeks activities on a computer.

Describe a typical weeks activities on a mobile phone.

Do you have group work assignments?

Have you used any collaborative tool previously?

If you have used online collaborative tools please list them.

Answer the following three questions by circling the most appropriate response. 1) I am used to browsing the Internet to find information I am looking for Strongly Disagree Neutral Strongly Agree

2) I use my mobile phone to perform a variety of options beyond just a phone and to send text messages Strongly Disagree Neutral Strongly Agree

3) I collaborate on documents using my mobile phone Strongly Disagree Neutral Strongly Agree

7.3.2 PRELIMINARY TASKS The preliminary tasks consisted of creating a desktop backpack account for those who did not have one yet. This was necessary for them to grab the API key required to login to the system. They were then prompted to download the application from a URL sent as bookmark through a text message to their handsets. They could then proceed to install the software. They were then asked to start the application and enter their credentials. After that they think aloud experiment started. 7.3.3 THE THINK ALOUD EXPERIENT The users were given a specific set of tasks to complete and were asked to think aloud as they proceeded through them. Some of the tasks were about them working on their own while others were about collaboration. The artefact below shows what tasks the users were asked to perform.

Specific Task Instructions The general task is to use the mobile backpack application to collaborate on a note. You will collaborate with the administrator that will invite you on a specific note item. Every participant will then interact on the same note and exchange views. Task 1: Task 2: Task 3: Task 4: Task 5: Open the mobile backpack and list the page items View and edit the shared note that will appear on the shared page. Create a new note and share it with a collaborator. Delete the shared note Create another note, share it and start a text conversation on any topic of your choice.

After the tasks were carried out the participants had to complete a post-task questionnaire as shown in the artefact below. 7.3.4 POST TASK QUESTIONNAIRE Description The following semi-structured interview questions were asked after the usability test. Artefact

1. 2. 3. 4. 5. 6. 7. 8. 9.

What is your first spontaneous impression of this application? Did you experience something very positive? Was there something you really did not like? What would you change? Did you always know where you were in the workflow and what the next step would be? Did you feel supported by the system and if necessary guided as well? Did you find the navigation intuitive? Did you notice terminology or names, which you did not understand? Is this a service that you feel you would make use of? Do you have further comments? Did I miss anything important?

Ease of use questionnaire Description

Participants are asked to rate the ease of use after completing particular task. A 4-point rating scale is used, where 1 = very easy and 4 = very difficult.

Artefact Task 1. 2. Open the mobile backpack and list the page items View and edit the shared note that will appear on the shared page. Create a new note and share it with a collaborator. Delete the shared note Create another note, share it and start a text conversation on any topic of your choice. Ease of use Rating

3. 4. 5.

7.4 RESULTS There were some difficulties that were encountered during the experiment. While the system has been thuoroughly tested on the emulator the participants experienced some connection problems while trying to download information. The mobile application would not respond and they had to cancel the download. Even if eventually they all managed to complete the assigned tasks this hindered the collaboration. On the positive side the participants felt much supported by the system. They knew exactly what they were doing. They found the navigation intuitive and the visualisation helpful. The table below gives the average values of the data recorded after evaluation. Task 1. 2. Open the mobile backpack and list the page items View and edit the shared note that will appear on the shared page. Create a new note and share it with a collaborator. Delete the shared note Create another note, share it and start a text conversation on any topic of your choice. Table 7.2 Average calculations Ease of use Rating 1 1

3. 4. 5.

3 1 2

It can be observed that many tasks were carried out without any trouble. All participants were able to open the application and view their pages. Viewing and editing of notes also scored 1. The task that was found to be the most difficult was the sharing of a note with a collaborator. The system prompts for an e-mail address to be entered. The users did not know what e-mail they should provide. Every user has an email associated with its backpack account. There was some confusion at this level. The same problem arose in the last task where a newly created note had to be shared. 7.5 LIST OF RECOMMENDATIONS The evaluation has shed light on many aspects on the usability of the program. The main concern was about network connection. The prototype seemed to be unable to connect to the online resources at some given point. There could be many reasons for that. The network connectivity could be poor and thus cause much delay. This is a point that will require more investigation afterwards. The participants also mentioned that they were not aware if a page was already being shared or not. The application does not give any feedback concerning that. They thought it would be helpful to know who was actually collaborating on a given page through some sort of visualisation. When asked for further comments some participants mentioned that they were expecting to see the text comparison feature already present on the desktop version. The agreed that this would really enhance the collaborative task. 7.6 CONCLUSION This chapter has covered the testing and evaluation part of the project. Test cases have revealed the potential weaknesses of the system. The evaluation has on the other hand investigated the usability side of the project.

Chapter 8
Conclusion & Future works

8.1 FUTURE WORKS There can be many aspects of the system that could be enhanced given more time and resources. Following is a time-line that shows what I could have changed given the extra time and resource. 1 month- This would be enough to fix all remaining bugs and test the program more thoroughly. More visualisation could also be implemented such as the text comparison visualiser and visual aids to determine what persons are actually collaborating on a given note. 6 month- Given since month a more audacious aspect of the project could be implemented. For a complete set of meta-data to be pulled back from the server there is a need for a constant monitoring of the backpack server. This would require our intermediate server to be synchronised to the millisecond. 12 month ­ Over a year a complete change of skin would be desired. The program could the be fitted with GUI engine such as TWUIK to support many more desktop like features and also provide a decent text editor with more functionalities. 8.2 CONCLUSION This project has opened a new set of perspectives and broadened my knowledge of the mobile application world. The prototyping approach has enabled a smooth and incremental development starting from a set of basic system requirements up to the implementation of optional features of the project specification. The fact that running prototype was implemented at each level comforted me in the sense that there was always something concrete to fall back in the event of an unforeseen problem. I have acquired much skills going through the server side implementation. The fact that the intermediate server had to make remote calls to another has opened a new set of web programming that I was not really exposed to before. My knowledge of open API's and the way to exploit them has also increased. I am fairly satisfied with the overall design architecture and the state of the program. It reflects the amount of work I had to put in over the last three months.

Appendix A
(References)
o

de Bruijn, O. & Spence, R., Rapid serial visual presentation: a spacetime trade-off in information presentation, Proceedings of theWorking Conference on AdvancedVisual Interfaces, 1999
ACM Transactions on

Information Systems
Editor-in-Chief Jamie Callan Associate Editors James Allan Ricardo Baeza-Yates Andrei Broder Hsinchun Chen Tat-Seng Chua Susan Dumais Edward A. Fox Norbert Fuhr Mounia Lalmas Elizabeth Liddy Ee-Peng Lim Wei-Ying Ma Alistair Moffat Javed Mostafa Douglas W. Oard Edie Rasmussen Berthier Ribeiro-Neto Stefan Rueger Mark Sanderson Fabrizio Sebastiani John Tait ChengXiang Zhai Justin Zobel Information Director Dana Houston Headquarters Journals Staff Mark Mandelbaum Jono Hardjowirogo Irma Strolia Media Content Marketing

ACM 2 Penn Plaza, Suite 701 New York, NY 10121-0701 Tel.: (212) 869-7440 Fax: (212) 869-0481 TOIS Home Page: http://www.acm.org/tois


The ACM Transactions on Information Systems (ISSN:1046-8188) is published four times a year by the Association for Computing Machinery (ACM), 2 Penn Plaza, Suite 701, New York, NY 10121-0701. Periodicals class postage paid at New York, NY 10001, and at additional mailing offices. Printed in the U.S.A. POSTMASTER: Send address changes to ACM Transactions on Information Systems, ACM, 2 Penn Plaza, Suite 701, New York, NY 10121-0701. For manuscript submissions, subscription, and change of address information, see inside backcover. Copyright © 2008 by the Association for Computing Machinery (ACM). Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, or to redistribute to lists, requires prior specific permission and/or a fee. Request permission to republish from: Publications Department, ACM, Inc. Fax +1 212869-0481 or email permissions@acm.org. For other copying of articles that carry a code at the bottom of the first or last page or screen display, copying is permitted provided that the per-copy fee indicated in the code is paid through the Copyright Clearance Center, 222 Rosewood Drive, Danvers, MA 01923.

ACM Transactions on Information Systems
http://www.acm.org/tois Process for Manuscript Submission. Manuscripts intended for publication, with a submittal letter, should be sent in quintuplicate, to the Editor-in-Chief. Papers will be refereed in the manner customary with scientific journals before being accepted for publication. Authors should keep editors informed of change of address. Electronic submissions are encouraged when possible. Please email the Editor-in-Chief, Gary Marchionini at march@ils.unc. edu, for ftp instructions. Correspondence regarding editorial matters should be addressed to Roma Simon, Managing Editor, 2 Penn Plaza, Suite 701, New York, NY 10121-0701, simon@acm.org. Subscription, Single Copy, and Membership Information. Send orders to: ACM P.O. Box 12114 Church Street Station New York, NY 10257 For information, contact: ACM Member Services Dept. 2 Penn Plaza, Suite 701 New York, NY 10121-0701 Phone: +1-212-626-0500 Fax: +1-212-944-1318 Email: acmhelp@acm.org Catalog: http://www.acm.org/catalog Subscription rates for ACM Transactions on Information Systems are $39 per year for ACM members, $34 for students, and $160 for nonmembers. Single copies are $18 each for ACM members and $40 for nonmembers. Your subscription expiration date is coded in four digits at the top of your mailing label; the first two digits show the year, the last two show the month of expiration. Notice to Past Authors of ACM-Published Articles. ACM intends to create a complete electronic archive of all articles and/or other materials previously published by ACM. If you have written a work that was previously published by ACM in any journal or conference proceedings prior to 1978, or any SIG Newsletter at any time, and you do NOT want this work to appear in the ACM Digital Library, please inform permission@acm.org, stating the title of the work, the author(s), and where and when published. About ACM. ACM is the world's largest educational and scientific computing society, uniting educators, researchers and professionals to inspire dialogue, share resources and address the field's challenges. ACM strengthens the computing profession's collective voice through strong leadership, promotion of the highest standards, and recognition of technical excellence. ACM supports the professional growth of its members by providing opportunities for life-long learning, career development, and professional networking. Visit ACM's Web site: http://www.acm.org. Change of Address Notification. To notify ACM of a change of address, use the addresses above or send an email to coa@acm.org. Please allow 6-8 weeks for new membership or change of name and address to become effective. Send your old label with your new address notification. To avoid interruption of service, notify your local post office before change of residence. For a fee, the post office will forward 2nd- and 3rd-class periodicals. Mail:

This Thesis is submitted to the University of Strathclyde in partial fulfilment of the Regulations for the Degree of MSc in Computer & Internet Technologies.

Mobile Tourist Guide
Frøy Birte Bjørneseth

Supervised by Dr Mark Dunlop Department of Computer & Information Sciences September 2005

Except where otherwise expressly indicated the work reported in this document is my own. It has been performed during my MSc Degree in Computer & Internet Technologies, and has not been submitted for assessment in connection with any other award whatsoever.

1

Acknowledgements

I would like to thank my supervisor Dr. Mark Dunlop for his help and guidance throughout this thesis. I would also like to thank my fellow CIT students who have given me advice and answered questions during the development of this prototype. Iain Hale, Adnan Syed Mazher, Lynsey Hanlon and Catheren Beaton have given their undivided support when questionnaires were to be handled out and questions were asked. And also, I would like to thank my loved ones in Norway who have pushed me forward and given me mental as well as academic support, and most important helped me reach my goal. To my family in Scotland, I would like to thank for giving me guidance and help during the time I have been living in Scotland.

2

Abstract
Tourism today, is one of the largest, if not the largest, industry in the world and the majority of the public have been travelling at one point in their lives. The holiday experience is a business with unlimited resources and the experience is taken further and developed every single day. Holidays that are fitted to suit the individual needs are offered, but there is one issue regarding tourism that have not changed for many years, the traditional tourist maps and guidebooks. Most people at one time or another has used maps and guidebooks and the experience using these helping "tools" are divided. The latest decade the technology have developed rapidly and computers have become smaller and available for the private users as well as for business purposes. This opens a door to a new market where handheld computers and mobile technology can improve and renew areas that have been the same for years, like the usage of the traditional tourist maps and guidebooks. The mobile tourist guide takes advantage of the latest technologies and can take tourism to a new level when it comes to navigation and guidance of tourists. This thesis investigates the issues around the mobile tourist guide and how it can be made more suitable for people who travel in groups and also how mobile tourist guides will be welcomed on the market, which is already fully booked with gadgets and electronic devices. A prototype was developed using a smartphone connected to GPS where the focus is sat on the group rather than the individual and localisation of fellow travellers is simulated.

3

List of Figures

Fig. 1-1: Project timescale Fig.2-1: The Hummingbird prototype Fig.3-1: Pocket PC, Pocket PC Phone edition and SmartPhone Fig.3-2: Smartphone input controls Fig.3-3: Communication within Mobile Tourist Guide Fig.3-4: Illustration Latitude and Longitude Fig.3-5: Start page Fig.3-6: Menu structure Fig.3-7: Get Map Fig.3-8: Activity Diagram illustrating the flow of the system Fig.3-9: Illustrating coordinates on the map Fig. 3-10: MySQL database illustrating the GUIDE table Fig.4-1: Age division between MALE and FEMALE participants Fig.4-2: Consider use of Mobile Tourist Guide, MALE + FEMALE Fig.4-3: Frequency of grouptravels, MALE & FEMALE Fig. 4-4: Which type of group do people travel in? Fig.4-5: Usage of traditional maps and guidebooks Fig. 4-6: Mobile Tourist Guide: A better service than traditional maps and books? MALE & FEMALE Fig. 4-7: Would you trust a mobile tourist guide? MALE & FEMALE Fig.5-1: Orange SPV E200 Fig.5-2: NAVMAN 4400 Fig.5-3 Power supply NAVMAN 4400 Fig. 5-4: EMTAC CRUX II Fig.5-5: Interface GPS application Fig.5-6: Interface MTG Fig. 5-7:Structure of menu Fig.5-8: Get Coordinates Fig.5-9: PHP output in Internet Explorer Fig.5-10: Simple HTML

4

1. Introduction
1.1 Background

The ever-growing tourism industry results in greater numbers of tourists from many nationalities visiting cities and places of interest. In order to inform and entertain these visitors in an efficient and personalised way, mobile tourist guides have been provided in some attractions. These portable devices can provide an audio description of what the tourist is looking at. However, the rapid development of Information Technology and Communications systems provide a potential for more sophisticated tools that can enhance the tourist's experience. The purpose of this study is to explore the technical possibilities and to obtain feedback from a sample of today's tourists as to the acceptability of such devices. Mobile Tourist Guides might be a revolution within tourist industry in the future, if all the pieces of the puzzle are put together in the correct pattern. The research conducted on this area started in the 1990's and the development has naturally improved with technology becoming more sophisticated. Several different prototypes have been created that have touched on different concepts concerning mobile tourist guides, but most of the prototypes like Cyberguide (Abowd et al.,1997), GUIDE (Cheverst et al.,1999) and CRUMPET (Schmidt-Belz et al., 2003) focus only on the single user, while the Hummingbird- study focuses on people in groups, in other words, group-awareness. There are several different aspects of mobile tourist guides that can limit their functionality. Most of the prototypes that have been developed are developed on small handheld devices like PDA's, tablet PC's or SmartPhones. The size of the screen on handheld devices is small compared to desktop and laptop computers and the challenge is therefore to be able to fit all the information needed in the display available. The interface must be fitted to the needs of the user without forcing too much information into it. If a poorly developed interface is released, the user will lose overview of the information displayed and the product will not be 8

as interesting to the user as if the interface was well designed. Dunlop and Brewster (Dunlop and Brewster, 2002) also explain two other aspects: in addition to the one mentioned above, that can limit the usability of small handheld devices, poor audio interaction facilities limited input techniques. What also seem to become new challenges are the device's contextawareness and also the networking facilities that are implemented in the device. Networking and context awareness are crucial to mobile tourist guides, so that the device's location can be determined and also to provide the users' preferences at all times.

1.2

Project Proposal

Personalised mobile tourist guides can help give individual tourists a better experience of a tourist location by giving each one an individually customised experience that matches personal preferences better than what can be provided by standard guidebooks. Mobile tourism systems, however, tend to support only individual tourists and give little support to groups. Groups have many special requirements. For example tourists on bus tours arrive together in a location and leave together. Some elements of the tour may be scripted (e.g. a prior arranged tour of an important site), while other elements are free form. There is considerable scope for mobile tourist guides to take into account group requirements, individual preferences and knowledge of the agenda to provide freedom to individuals where possible but still allow them to participate in group-activities when appropriate. This project will develop a mobile tourism guide for a major tourist location that better supports groups. The project will cover aspects such as development on palmtops, recommendation systems, timetable planning and location monitoring. [Dr. Mark Dunlop, University of Strathclyde]

9

1.3

Aims for Project

The aims of this project are to provide a prototype of a mobile tourist guide, which focuses on the needs of tourists and especially tourists travelling in groups. As mentioned earlier, the majority of the prototypes that have been presented until now, have focused on the individual (i.e. Cyberguide (Abowd et al.,1997) and GUIDE (Cheverst et al.,1999) and not the group. This thesis has been inspired by research on Cyberguide, the Lancaster GUIDE and, concerning group awareness; the Hummingbird- study (Holmquist et al., 1998) has played a role. This project will aim towards giving the foundation of a group- aware mobile tourist guide that can put the focus on the user being able to explore tourist sights alone, while at the same time being able to follow a group. This will protect the individual's interest and also provide the user with a group social opportunity. To detect and connect with fellow travel companions through smartphones will give the advantage regarding the issues of localizing persons of interest to the user to interact with and also to be able to spot lost persons/friends/family in a busy tourist spot.

1.4

Aim achievement

To achieve the aims for this thesis, a study of tourists' behaviour was performed be required to examine how tourists move around when they travel in groups. Some might stick to the group, while others might want to explore on their own. To fulfil this requirement interviews were conducted be carried out targeting groups of tourists and also a number of questionnaires were handed out to investigate the opportunities in the market for mobile tourist guides. Questions were asked regarding the general requirements for the software and the device, like a mobile tourist guide and also what preferences the public have regarding the issues concerning what the software should contain. The investigation was be carried out on popular tourist sights in the Glasgow area, covering the city centre, the Burrell Collection and also the annual World Pipe Band Championship. The most suitable technology for this type of software development is the .NET Compact Framework from Microsoft. The Microsoft standards are open and ease the search for information and help. There are also well-developed help functions available and a 10

comprehensive API. Development and coding was carried out in Visual Studio .NET 2003 with the Microsoft SmartPhone 2003 SDK was imported and used. The programming language fitted best to these types of development tools is C#. To navigate in an outdoor environment, a Bluetooth GPS receiver was connected to the smartphone to feed the application with input data for processing. The final choice of GPS receiver was the CRUX II from Emtac. To host the prototype of the mobile tourist guide, an Orange SPV E200 was chosen. This smartphone is a part of the Windows Mobile- family and has the Microsoft SmartPhone 2003 operating system implemented. The Microsoft framework was adapted to the different parts included in this project and minimized the risk of compatibility problems between the development tools and the actual hardware, the SmartPhone.

1.5

Timescale
Research, planning, explore equipment and start making questionnaires and prepare interviews.

Week 1 - 3

Week 4- 5

Visit out.

tourist

spots

and

observe.

Questionnaires and interviews will be carried Week 6- 12 Week 13- 16 Week 17 Fig. 1-1: Project timescale Develop the prototype, software and testing Write up report and make sure everything is working. Deadline Monday 12.09.05

11

1.6

Chapter Outline

This thesis highlights the major issues concerning group- aware mobile tourist guides and contains the development and research of a group aware mobile tourist guide prototype. The thesis begins with the basic research around mobile tourist guides and further explains and illustrates hoe the prototype was built, why it was built this way and also what results that was an outcome of the research. A market survey was carried out to investigate how a part of the public would welcome such technology on the market, how people travel and what the preferences of implemented facilities would be. Chapter 2: Research and Related Work

Chapter 2 gives an outline of the research that has been done on mobile tourist guides and a brief overview of the different prototypes that have been developed over the last years. This chapter also gives an introduction to research done on electronic maps and a discussion concerning context- awareness and context- aware computing. Chapter 3: System Design and User Interface

Chapter 3 illustrates how the system was designed and what design decisions were taken. The chapter give an overview of the system and how the flow though the system is designed. Chapter 4: Market Survey

Chapter 4 give a summary of the market survey that was carried out to investigate the interest around mobile tourist guides and also how people travel. Here the main results are discussed while the full analysis of the survey is given in the appendices. Chapter 5: Software Implementation and Development

Chapter 5 describes how the system was implemented and illustrates the main point by using screen shots and snippets of code. A presentation of t hardware requirements will be given and also a discussion of the development issues. Chapter 6: Evaluation and Results

Chapter 6 gives a discussion regarding the final system and possible limitations of the system. Issues that arose during development will be discussed and there has been given a brief summary of the results in the market survey. 12

Chapter 7:

Future Work

Chapter 7 give an introduction to ideas of future work and describes the possibilities of further development. A section regarding marketing suggestions is included and also suggestions on how to develop the mobile tourist guide in accordance with what the users would prefer. Chapter 8: Conclusion

The conclusion gives a summary of the outcome of the thesis and how the development was experienced with learning outcomes. Chapter 9: References

13

2.0 Research and Related Work
2.1 Introduction

In the last decade computer technology has made a large jump forward and Moore's law1 has been proven correct many times. The rapid development of mobile technology has created new markets for mobile applications and mobile phones have more or less become commonplace. In the mid 90's the development of mobile technology turned from being simple mobile phones to becoming more and more powerful devices. Computers became smaller and PDA's (Personal Digital Assistants) started to appear on the market. This triggered new needs on the market and new needs were also created. The public has become increasingly more dependent on their mobile devices and researchers came up with new ideas to combine the powerful mobile technology with other common activities. Travelling and tourism are two important features in most people's lives. In recent times researchers have worked on the issues regarding a possible replacement of the traditional tourist guidebooks and maps with electronic equivalents. Since the middle of the 1990's several prototypes of context-aware mobile guides have been developed. Abowd and Dey (1999) state that context can be defined like this: "Context is any information that can be used to characterize the situation of an entity. An entity is a person, place, or object that is considered relevant to the interaction between a user and an application, including the user and applications themselves." If the word awareness is taken out of its context from the word context-awareness, it can be discovered if it is looked up in a dictionary, that when a user is aware of something, the user is aware how to use i.e. a device, which can be connected up to the word information. Korkeaaho (2000) means that context- awareness is the ability to use context information. Not all of the prototypes developed were meant for the tourist market, but they still have relevance when developing this kind of software on portable devices. Some of the focus on mobile guides has naturally been based on the use of electronic maps. The car industry has used electronic maps together with GPS (Global Positioning System) for a number of years already and there is also now available a quantity of detailed and well-designed maps online.
1

http://www.intel.com/technology/mooreslaw/ [Last accessed: 12.09.05]

14

GPS2 was developed by the U.S. Department of Defence and was given public accessibility on President Bill Clinton's order. GPS is now free for everyone to use and is built up of 24 satellites and their collaborating ground stations. The system is considered a worldwide radio navigation system that is using the infrastructure of the satellites. The satellites use what is called triangulation of signals, which means that the GPS receiver must "see" three satellites to be able to triangulate the signal and measure the distance to get an accurate location. The distance is measured by calculating the times the radio signals travel and together with the triangulation this give you a position that is accurate up to 50 cm. GPS can therefore be used to advantage of tourism and is now used and tested on PDA's. It can also be used together with some models of mobile phones that in recent years have moved towards becoming pocket PC phone editions, also called SmartPhones. The different ideas and prototypes of mobile guides that have been researched cover a range of interesting areas and some also vaguely cover the area group-awareness. Group-awareness can be described as when the device used is aware of similar devices nearby with similar or identical software. One of the prototypes touching the issue of group-awareness is the Hummingbird project (Holmquist et al., 1998) Prototypes that cover other interesting areas are CRUMPET (Schmidt-Belz, [Last accessed: 12.09.05]), GUIDE (Cheverst et al., 1999), Cyberguide (Abowd et al.,1997) m-ToGUide (Chanan, 2004) and Taeneb CityGuide (Dunlop et al., 2004).

2.2

Context- aware Applications

Context-aware applications are naturally connected with computers, which are well known as powerful devices that can do complicated tasks in a matter of seconds. However, computers are machines and cannot be compared with the complexity of the human brain, which can think for itself without any necessary input. To illustrate: it is easy to imagine two human beings interacting with each other through speech and body language, the responses between the persons are dependent on how they act towards each other and automatically the body and brain will adapt to any situation that might occur. To make computers "think" on their own, applications are needed to process input from the device's surrounding environment. This is what makes the device context-aware.

2

http://www.trimble.com/gps/index.html [Last accessed: 12.09.05]

15

What can be seen as most important is the fact that the application must comprehend and act fast enough when input is provided from the user to the device through sensors. Movements can be fast when mobile devices are being used, voices can be raised quickly if sound sensors are being used and the location can also change in rapid speed if driving or walking fast. It is then crucial that the application can keep up, or else the whole point of context- awareness is not of any use. To make systems context-aware, we need to take into consideration the different types of context-aware information is provided to the system. When information is provided to a system there must be something to catch the information to be able to make it adapt to the situation. For this we need sensors and different devices that can provide input to the system. Examples on such devices can be: GPS, temperature sensors, camera technology, physiological sensors etc. These devices provide low-level data to the system, which must interpret the data and make it understandable for the application using the data. A context-aware system is described by J. Pascoe (Pascoe, 1997) as a system that can extract, interpret and use context information and adapt it self to the current context and situation. What is also mentioned is that the real challenge for these kind of systems, lies in how complex it is to catch the data, to represent it and how to process it. There are three main areas that are important when discussing context- aware applications. Korkea- aho (2000) refers to the work of Schilit et al. and Pascoe, when the important features of applications are described. The main feature is the information and services available that must be presented to the user according to the context and situation they are in. This can include an application implemented in the device being used to tell the user where the nearest bus stop is and when the next bus will leave the stop. The second feature covers the automatic execution of an action when the correct context occurs. The application must then adapt to the environment. To take the example of the bus, a bit further, it can be imagined that when the user enters the bus, the credit card details will be available to the bus's payment system. The ticket can then be paid without using money that has to be physically present.

16

The third feature contains tagging of context- aware information. This is to provide information that can be retrieved at a later stage. To reuse the example about the bus, imagine that the user wants to catch the bus next day at that exact time. The information is tagged so the user can have a look at it later and plan when to leave i.e. home to get to the bus stop in time. These features cover what Pascoe (2000) describes as the capabilities of context- aware computing.

2.3

Electronic Maps

To be able to guide tourists with a mobile tourist guide, maps have to be implemented in the software. The users must have the possibility to have an overview of their whereabouts and to be able to understand where they are going next. There have been presented many different types of maps that have been used in the mobile tourist guides, without necessarily finding which type of map is the most suitable for this kind of devices. In the Tellmaris project mentioned by Kray and Laakso (2003) a combination between 2D and 3D maps were used. This particular type of map was tested on a limited number of people and the 3D map was the one that gave the best result. The 3D map gave the user the possibility to have two types of views while using the map, pedestrian view and birds-eye view. Pedestrian view illustrated the view on walking level, while the birds-eye view illustrated the feeling of flying or hovering over the ground. The issue raised here, was the problem with how far up the hovering should take place. If it took place too far up, there would be difficulties to keep track on the map, while too low would make the user lose overview over the map and feel disoriented. The ideal solution is not yet clear, but to hover approximately 10 meters above ground seem to be a good height which will give the user a good overview of the map and where to go (Brewster and Dunlop, 2004). Zipf and Hunolstein (Last accessed: 28.08.05) have introduced what they called task oriented maps. Task oriented maps take into consideration what kind of tasks the tourists normally perform and how the map can be adapted to suit the different tasks in a best possible way. The different tasks are divided into four main groups, which can be subdivided into new subgroups. Zipf and Hunolstein describe the two most prominent tasks a map performs as orientation and navigation, but as close followers, maps are also used as a tool for exploration and planning. The four distinct tasks a map-based mobile tourist guide must consider are therefore: 17

1. Thematic areas, navigation and way- finding, 2. Localisation and orientation, 3. Proximity and events, 4. General information seeking and identification A typical navigation task would be to mark up a route, while localisation will take care of the question "where am I?" and it is also mentioned that for landmarks easy to spot, it is important to point them out on the map. When it comes to the issue of handling events, this will touch on the conditions of a specific location and what is happening when. This can concern opening times in museums, galleries and other venues that can be of interest for a tourist. According to Reichenbacher (Reichenbacher, 2003), to be able to achieve these different tasks, goals and plans must be separated from the user needed to achieve them. This table describe the High-level tasks and their subgroups and describes the typology of tasks in a map-based mobile tourist guide.

Table.2-1: Events and subtasks (Zipf and Hunolstein ,Last accessed: 28.08.05). This table describes what kind of sub-tasks and goals the different main tasks include, when it comes to using task-oriented maps. The majority of the mobile tourist guides on the market and in the research plan take advantage of maps. The main goal for a mobile tourist guide must be to guide the tourist in the correct direction and not lead anyone astray. However, to make the map and the software 18

follow the user in situ is a task that has been researched and tried out by several mobile tourist guides with variable success. The various guides focus on different areas and some of the larger research projects are CRUMPET (Scmidt-Belz et al, Last accessed: 12.09.05), GUIDE (Cheverst et al., 1999), Hummingbird (Brown and Weilenman, 1998), Cyberguide (Abowd et al., 1997) and the now commercial and market available m-ToGuide (Chanan, 2004).

2.4

The CyberGuide

The system that can be found closest to an ideal mobile tourist guide system is the Cyberguide (Abowd et al., 1997). The research on this system started in the early 1990's and the research group developed over a year's time the Cyberguide. The system was developed to be futuristic and the main idea was to continue the research and development later on. The two research groups, Future Computing Environments (FCE) Group within the College of Computing and the Graphics, Visualization and Usability (GVU Center) at Georgia Institute of Technology, developed prototypes for indoor and outdoor usage. Their long-term goal was to develop a system that identifies where the tourist is and can predict any answer he/she might ask about the things he or she are looking at. The possibility of interaction with the environment and fellow tourists is also an opportunity the Cyberguide would ideally offer to its users. The research groups' short-term goal was to prototype different versions of the Cyberguide on comercially available equipment, such as PDAs and pen-based PCs. The equpiment had a large screen for visualisation of the surrondings using maps and the research groups also aimed towards locating the current position of the unit and by that, also locate the user of the unit. The Cyberguide is divided into four main sections of design: the cartographer which is a map component; the librarian that provides the information about the different sights; the navigator that locates the device and the tourist; and last the messenger that allows the tourist to interact by sending and receiving messages like an instant messaging service. These sections are used both in the outdoor and the indoor prototype. The design of the Cyberguide's interface is without colours. The reason for is that the PDAs were unlike those not like their known today, with high resolutiuon screens. The screen had a

19

resonable size, but could move towards being too big when it came to using the larger penbased PCs. The indoor prototype used a simple map to display the facilities in a laboratory where the testing of the prototypes were carried out. The device used for the prototypes was an Apple MessagePad and an icon is indicating where the user is situated on the map. To get the localisation working, the Apple MessagePad was equipped with an IR receiver and a microcontroller. TV remote controls where hanging from the ceiling beaming out a specific pattern for the PDA to recieve. In the Cyberguide survey, the researchers stated that the microcontroller technology was too expensive for large-scale usage, and therefor had to be inventive to make this more available for the market. The Appletalk protocol was used to establish the possibility of sending and receiving emails and HTML documents. This was implemented to improve interaction with the environment. To get information about the specific sights in the laboratory, the user could click on one of the stars on the map indicating a tourist attraction in the lab. The system would display what the sight was about and any needed information. Two implementations provided this: one hard-coded version with quick response time; and one using Newton files to store information. The same structure was used for the outdoor system, but the system was extended and a GPS unit was attached to the Apple MessagePad to send its location to the satellites. The range on this is larger than the indoor system and different types of maps could be implemented (i.e. vector-based maps). The GPS technology was used because the number of satellites providing support to GPS services is increasing and it is the only technology available for this purpose. The Cyberguide is a project that has done empirical research on context aware computing, but there are certain concepts their research has not gone into. When tourists are travelling, most of the time they travel in groups and this is an issue that the Cyberguide has not covered. The "Buddy finder" mentioned by Hunolstein and Zipf (Hunolstein and Zipf, last accessed 28.08.05) can be an interesting feature in mobile tourism guides. Another research group that looked into systems that can be categorised as group- aware, is "The Hummingbird-study" (Brown and Weilenman)(Holmquist et al.). 20

2.5

The Hummingbird- study

This research was conducted by Brown and Weilenman (1998), and the Hummingbirds were prototypes tried out in the Norwegian Alps by a group of eight ski instructors. The device would hum when fellow instructors were located within less than 100 metres and their name would pop up on the screen. The negative part of this study was that the instructors kept missing the humming from the hummingbird, because of their focus on skiing and with that, a bit of the reason for using such a device disappeared. This did not mean that the hummingbird was completely useless, because it was frequently brought out in the skiing slopes to gather the group for lunch and meetings. The hummingbird was also tested on the Roskilde festival in Denmark. This study was carried by Holmquist, Wigström and Falk (Holmquist et al), and the device scanned the area for similar devices. This made it easier for the group to meet, since the festival is an outdoor rock festival with approximately 80,000 visitors. The hummingbird is taking advantage of wireless communication and its range varies between 20 and 200 metres. The prototype has a processor with some RAM, an LCD screen, a miniature speaker and a radio transreceiver to cover the wireless communication. The range of the radio transreceiver depends on external conditions and how the antenna is configured (Holmquist, 1998). The design of the hummingbird is set to be small and portable, and the researchers wanted it to "melt into the background" and when it was desired, the device could be brought into attention. The design is related to principles mentioned by Weiser and Brown (Weiser and Brown) about calm technology and ambient media mentioned by Ishii and Ullmer (Ishii and Ullmer, 1997). The hummingbird did not use any map functionality, but made awareness between friends possible when they where located in big crowds. A negative issue with this was that even though the device was humming and indicating that someone with the same device was close, the person could not be located and if the venue was crowded it would be impossible to spot the person in the crowd as well.

21

Fig.2-1: The Hummingbird prototype (Holmquist, 1998)

2.6

CRUMPET and the Lancaster GUIDE

CRUMPET (Scmidt-Belz et al,2003) and GUIDE (Cheverst et al,) are two well developed mobile tourism guide systems. They are using the basic research from Cyberguide, but with different variations of PDAs and technologies. GPS is widely used, but the technology used in the guides is different. CRUMPET is using a diverse set of technologies, while GUIDE is using high-speed wireless network. The two systems have one issue in common which is that they both focus more on personalisation and have local aware services. CRUMPET is a EU fonded international collaboration developed by Schmidt-Belz, Laamanen, Poslad and Zipf (Scmidt-Belz et al,2003). The focus is more set on the outdoor environment and the technology used is diverse. The technology available when CRUMPET was developed (year 1999-2000) showed that the delay that appeared while using seamless roaming could be too long. Seamless roaming is described by Schmidt-Belz, Laukkanen, Laamanen, Veríssimo, Zipf, Aras and Poslad (Schmidt-Belz et al., ) as a collection of network and Mobile Node side techniques and networking design techniques. The aim is to provide an uninterrupted service and also network connectivity. This is provided regardless of handovers between the different wireless access networks. The design is more directed towards the personal interests of the tourist and can provide services that are directly aimed towards the single individual. CRUMPET has not focused on any research directed towards group travels or similar matters. GUIDE is a system developed by Davies, Cheverst, Mitchell and Efrat from Lancaster University, UK, and University of Tucson, Arizona (Davies et al.). The work started in 1997 22

and the CyberGuide was the main inspiration for this research. The project aimed at developing a context sensitive tourguide for the Lancaster area. The tourguide is dynamic and the technology used for this was a tablet PC with an implemented high speed wireless network card. The screen was 800 x 600 which is large for a mobile tourguide. The only negative issue with this size is that the tablet PC from Fujitsui is rather big and the weight is 850 grams. This kind of weight might seem incignificant in the beginning, but after a period of walking and sightseeing, it can become a heavy burden to carry around in the city of Lancaster. The positive part of having a large screen is that the HTML pages used in the guide is clearly set out and easy to understand. The GUIDE is not using GPS in its system. The reason for this is because of the triangulation problem and that in cities it is not always possible to be able to "see" three satellites at once.

2.7

m-ToGuide

This project is a relatively new project, published in 2004 by Chanan Gabay (Gabay, 2004). This system uses the existing GSM/GPRS mobile phone network and the Internet as the base of the system and it is materialised on a mobile and handheld Motorola terminal. M-ToGuide and also CRUMPET, as mentioned above, is supported by the Information Society Technologies (IST) Fifth Framework Program of the European Commission and targets the European tourist market. The handheld device is used to exchange information between the user and the system and this service is a location-based service that provides information that is of current interest for the user. The service is not only location- based, but also personalised to tailor the user through their personal profiles. The testing of the system was carried out in three different European cities and the system can according to the producer and provider, serve the individual user with up to date information, as mentioned, but also a possibility to buy tickets for attractions and similar matters. However, after the testing of the system was performed, 70% of the users wanted to use it again, but there had to be made improvements on the communication and infrastructure. The GPRS and the GPS was not accurate enough and in narrow streets the well- known triangulation problem for GPS appeared. The developers of the m-ToGuide do think that these problems will be improved with the introduction of UMTS (Universal Mobile Telecommunications System) and AGPS (Assisted GPS). UMTS is today maybe more well known as 3G and it is still quite a way before it is available for everyone. Assisted GPS is a 23

new collaboration between GPS and mobile phones, and can be described as a variant of GPS used in mobile phones. When you use a standard GPS receiver, the signals are triangulated between three satellites, which have to be in sight of the receiver. However when AGPS is used, the mobile base station will do the calculations from the satellites for the user and the only thing the user then needs, is a signal on the mobile phone. This technology will then be able to bypass the triangulation problem, which is the number one problem to limit the traditional GPS technology.

2.8

Conclusion

According to the research that has been done during the last decade on mobile tourist guides, it has been discovered that there is a large potential for these kinds of context- aware applications and devices. Mobile phones, SmartPhones and PDA's might merge together in the future as the standard mobile phones are becoming more advanced every year and this will open the market even more for the new technology. So far it is the m-ToGuide that has come the closest to the commercial market, but there are still improvements to be made and problems to solve. The majority of the guides available within research have focused on the individual tourist. Of the prototypes mentioned above, only the Hummingbird-study focused on the group and on group- awareness. The fact that most people travel in groups has not been taken into consideration in any of the other guides. The Hummingbird's weakness was however the lack of maps implemented in the software and the problems related to locating the rest of the group in crowded areas. If maps following Reichenbacher's standards (Reichenbacher, 2003) had been implemented in this prototype the technology would have taken a large step forward towards more group-aware applications.

24

3.0 System Design and User Interface
This chapter will describe how the Mobile Tourist Guide is designed and how the users interface is developed according to different design principles described in the section concerning initial design. The flow of data through the system will be investigated together with how the devices communicate and the algorithms used. A brief description of the GPS format, concerning latitude and longitude will also be given, together with a discussion around the limitations of the design.

3.1

Initial Design

The initial design will give a summary of the overall design of the Mobile Tourist Guide system, how the user interface of the system is built and last what really matters in design of mobile systems. There are certain issues that must be taken into consideration concerning designing for mobile environments and the challenges of designing for small screens are larger than designing for normal sized screens, like a desktop screen.

3.1.1 Pocket PC v. SmartPhone
There are three types of devices that use the .NET Compact Framework; Pocket PC, Pocket PC Phone edition and Smartphones, where the Smartphone is the device with the smallest screen size, as illustrated below.

Fig.3-1: Pocket PC, Pocket PC Phone edition and SmartPhone (Lee, 2004)

25

The lack of space when designing for smartphones is crucial to design. When it comes to designing in .NET Compact Framework, it provides the developer with several different tools for grouping and structuring data. Microsoft has narrowed down functionalities in the .NET Compact Framework so it would suit the needs of mobile systems and this is narrowed down even further when the Smartphone 2003 SDK is installed. To develop to for smartphones are slightly different to developing for Pocket PCs, not only are the tools available reduced, but also the main reason is the difference of form between the devices. Pocket PC devices have touch sensitive screens to handle any input from the user, while the Smartphone are dependent on two softkeys, mapped to the fixed keyboard, to provide with necessary input and also to replace buttons and feature that softkey entry can not handle.

Fig.3-2: Smartphone input controls

3.1.2 Design Requirements
Designing for mobile systems requires knowledge around how to structure the information implemented in the user interface. It must be easy to understand for the user, well-structured and not too much information gathered on the screen at the same time. This is especially important for smartphones due to their small screen and their limited input possibilities. To design usable systems for smartphones is different from normal webdesign, but the same principles can be used just with a few logic alterations. Four basic design rules can be used to structure the design of both web design and design in general, also including mobile systems. The main task is to design for maximum usability where the goal is to get the user to interact as much as possible. To be able to fulfil this aim, there must be a general understanding of the system. The user must be able understand and interpret the system the correct way without

26

experiencing any larger problems. A good way to make understanding easier is to use familiar patterns and take advantage of standards that are already familiar to the user. (Dunlop, 2005) For the user to be able to fully take advantage of a system and find it easy to use, the design of the user interface on the smartphone must be consistent. It is important to group information that is similar and connected to each other and also make the system behave in a consistent way through all phases of usage. Due to the smartphone's small sized screen, a good and simple design following the above rules is important.

3.2

Specified Design

This section will give a presentation of the specified design of the Mobile Tourist Guide, which will contain an overview of the information/data flow through the system and how the user interface is designed. The algorithms used in the code will be presented and also what limitations here can be in the user interface.

3.2.1 Specification
The Mobile Tourist Guide will assist individual tourists and tourists travelling in groups, to navigate in a city environment using a Smartphone and a Bluetooth GPS receiver. The communication between the devices goes via GPS to get information and coordinates from the satellites and GPRS is used to download necessary information onto the smartphone from the Internet. The system will fulfil the user's requirements, which means it is simple to get an overview over how to use the functions implemented in the system. Options given to the user is predictable in the terms that the user will understand what to do next and also understand what will be displayed on the screen. Communication is important must flow in "real time" to be able to serve the purpose of the system. GPS signals must be processed and converted into x and y coordinates to be fitted on to the map. A conversion algorithm implemented in the software does the conversion of the GPS input. This will eventually give a result that can plot the current available positions on the map. In according to the requirements of the system a database will handle the storage of coordinates and data.

27

3.2.2 System Communication Design
The Mobile Tourist Guide is dependent on communication that can provide the user with information that is of current value. The flow of communication between the client and the server side is crucial and consists of the device and GPS, which is the client side of the system, the MySQL database that hosts the server side and the connection between them over the Internet using GPRS. The GPS unit will also be connected to give exact positions.

Fig.3-3: Communication within Mobile Tourist Guide

3.2.3 GPS: Latitude and Longitude
GPS satellites will provide the Bluetooth GPS receiver with information by using triangulation of signals and in this case only time, latitude and longitude are necessary. This information will eventually be converted into the coordinates that are required for the system. The time given by the GPS is in GMT (Greenwich Middle Time), initializes the longitude that runs through Greenwich in England. The longitude can be described as the measurement taken from the Prime Meridian, which is Greenwich, as mentioned above. The positive values runs eastbound and the negative values runs westbound. However, the longitude is

28

accompanied by the latitude, which can be described as the measurement calculated from the equator where the positive values points north and the negative values points south.

Fig.3-4: Illustration Latitude and Longitude3 All the coordinates are given in degrees and to convert it from degrees in the format: degrees : minutes : seconds to the format of degrees that are familiar, an easy algorithm is used to calculate it. Latitude can be converted into degrees by using the common knowledge concerning hours and seconds. There are 60 seconds in 1 minute and another variable that might not be that familiar, is 60 minutes being 1 degree. Algorithm calculating Latitude and Longitude: Latitude in Degrees = (degrees + min * (degree/60 min)+ sec * (1 min/60 sec)) When the signal from GPS is received, the GPS receiver will talk to the smartphone via Bluetooth. The device will process the input by using C# and the application will load a server - side web page that contains information about the current users in the system and their coordinates. This page will be downloaded by the smartphone and processed so the information on the web page can be processed and converted into map-coordinates. To download information from the Internet, GPRS will be used. GPRS is short for General Packet Radio System and are today the most used type of wireless mobile communication for
3

http://jwocky.gsfc.nasa.gov/teacher/latlonarchive.html [Last Accessed: 11.11.05]

29

Internet connection. GPRS is implemented in the smartphone by default and is today the best opportunity regarding Internet access on mobile phones and Smartphones.

3.2.4 Software and User Interface Design
The software is developed to suit the user as good as possible and must be clearly designed following the standard design rules. Having a consistent user interface is important and the user must understand what he or she should do next without having to think or hesitate too much. The initial page of the Mobile Tourist Guide has its colour theme sat to royal blue. This colour was chosen because it is supposed to signalise trust and authority, which is an important feature for the user.

Fig.3-5: Start page

Fig.3-6: Menu structure

Fig.3-7: Get Map

The menus are built up so the user can easily understand what to do and it has four options: GetMap, Get Coordinates, Help and About. The first two options are the main tasks on the menu; option 1 loads the map, while option 2 generates a list of coordinates that are available on the server side web page. On the illustration of the GetMap function to the far right, a small ellipse is visible in the left hand corner. This ellipse illustrates the user and is situated down in the left corner to illustrate that coordinates have been marked off on the canvas. However, what seemed to be the problem were the ellipsoids appearing underneath the map. This problem will be further discussed in implementation of the software where a possible solution to the issue will also be presented.

30

3.2.5 Activity Diagram
The activity diagram illustrates the different activities in the Mobile Tourist Guide. The flow of the system is given and this illustrates what options are available for the user.

Fig.3-8: Activity Diagram illustrating the flow of the system

31

3.2.6 Conversion algorithm
An algorithm to convert the coordinates, latitude and longitude, into map- coordinates was developed. The algorithm uses simple arithmetic to scale the coordinates and according to the grids in on the map the GPS coordinates can be converted into pixels on the map. Conversion algorithms:
lat p - lat1 lat2 - lat1 long p - long1 long 2 - long1

xp = (

)  x2

yp = (

)  y2

These two algorithms specify two points marked out on a map. Xp illustrates the point x on the map and is calculated from the latitude, latp. Yp illustrates the point y on the map and is calculated from the longitude, longp. To calculate Xp , the latitude situated as a point on the map, latp, is subtracted from the initial latitude on the x-axis. The subtraction is thereafter divided on the subtraction between the latitude situated in the right hand side corner, lat2, and the latitude situated in the lower left hand corner. This sum is then multiplied with x2 and the product from this will be the newly calculated x coordinate, xp. This algorithm has now calculated how far left or right the xp is situated. To find the location of the y coordinate, the same algorithm is run and the "height" of the coordinate is found. This settles the how high or low the coordinate is pinpointed on the map and the coordinates haven been converted from latitude and longitude to coordinates fitted on a map.

Fig.3-9: Illustrating coordinates on the map

32

3.2.7 Design of MySQL Database
The database consists of one table called GUIDE, which contains 4 rows, G_username, X_coord, Y_coord and G_TimeDate. In this table the user's name is stored together with the current coordinates and the time and date of the last entry of the user. The database design is simple, because the data must be easy and quick to recover. The screenshot below illustrates the GUIDE table and the tool used for administration is phpMyAdmin. This tool was chosen because it would make the handling of the table easier.

Fig. 3-10: MySQL database illustrating the GUIDE table The table can be extended for future development and contain more rows that store time. This can be used for "ghosting" users. "Ghosting" can be described as when the user is at a current position at a certain time and is display with a clear coloured dot on the screen. After the user has left the location and been away for maybe half an hour, the colour of the dot fades away and the user can at the same time appear at other locations. This phenomenon can be useful to other members in the group if route the "ghost" user is re-used by new users.

33

3.2.8 Design constraints
The design of the Mobile Tourist Guide system must be simple in order to make the user understand and predict how to use the system and to fully take advantage of the user interface. The client side of the system, including the hardware and the application itself, is designed as the largest part of the system. The server side must be limited due to the communication and the limitations that GPRS introduce to the system. It is important that the system is not slow and takes too long to download data, due to the fact that if the system is slow it will defeat its purpose and locations might not be current anymore. The design of the user interface has limitations because of the small-sized screens smartphones have. This will challenge the developer who designs the system and it is important that the information on the screen is not exaggerated. This will confuse the user and the end product will not be used the way it was meant to be. Functions that are hard to locate will be overlooked and the overall impression of the system will fall. Other constraints that were experienced in designing the system were the limitations that were introduced when installing the Smartphone 2003 SDK, which will be discussed in a later chapter. The Smartphone 2003 SDK limits the input methods compared to Pocket PCs and functions like buttons and tabs were disabled. Functions that are not available in the .NET Compact Framework at all are the BackgroundImage- method, which entitles the developer to put an image in the background as a canvas. This was a method that could have been very useful regarding drawing the coordinates on top of the map and not underneath it, like mentioned above.

34

3.2.9 Use cases
The use case diagrams illustrate a unit of functionality in the system and shows how the different parts of the system interact with each other.

Fig.3-11: Use case diagram for Mobile Tourist Guide

35

4.0 Market Survey
A survey was carried out to investigate the conditions and opinions around how people would welcome a Mobile Tourist Guide on the market.. The survey included questionnaires that were handed out during the busiest tourist season in Glasgow. The target groups were mainly tourists and preferably tourists travelling in groups, such as bus tours and other similar forms of travel. The questionnaires were distributed during the weeks of the World Pipe Band Championships 2005. This is an annual event held in Glasgow and 230 bands participate with 8000 pipers and drummers coming from far and near. This was a golden opportunity to investigate people travelling in groups and most of the questionnaires were handed out on George Square, on the See-Glasgow buses, a few were handed out on the ISEC 4conference held at the University of Strathclyde in early August and at the Burrell- collection in Pollock Country Park. The questionnaires were handed out by MSc- students at the University of Strathclyde and by staff on the See-Glasgow buses. 100 questionnaires were handed out and the division between the genders were 53 % of the participants were male and 47 % female. Most of the answers are analysed on the basis of genders to find differences in opinions between the sexes and also a joint analysis to find the trends that are similar for both male and female. Also the age of the participants has been taken into consideration, due to the topic investigated being "modern" and there could be differences in opinion between the age groups. An example to this is that elder people might "fear" the new-coming technology and younger people might have different interests from the elderly as to what a mobile tourist guide should contain. The questionnaire is divided into 13 different questions where the first three are demographic questions, which concerns gender, age and occupation (Appendix A, Section 1). However, gender and age are the most weighted questions, because occupation can merely reflect education and social status, which can be mirrored in how the questions are answered. The next two questions are reflecting the respondents' interest in general in the system (Appendix A, Section 2). How many would consider using the system if it became available and also

4

Inclusive and Supporting Education Congress: http://www.isec2005.org.uk/ [Last accessed: 12.09.05]

36

what they would like the system to contain. Two of the next questions are more aimed towards group-awareness and how many of the participants travel in groups and what type of groups they travel in (Appendix A, Section 3). The next questions concern the usage of maps and guidebooks, and also the advantages and disadvantages of traditional maps and guidebooks over the new technology that includes the electronic versions (Appendix A, Section 4). Questions regarding the extent to which a mobile tourist guide would be trusted are also taken into consideration. If the answer to the question considering trust is negative, the reason for the negative answer is then required. This is to be able to pick up any opinions regarding security and protection of personal space and also if the software and hardware can be trustworthy when it comes to technical breakdowns and similar issues. The last question is dedicated to the participant's own opinions and can here write down some comments regarding either the survey or anything else that might spring to the participant's mind. This question is particularly useful when it comes to mentioning any questions and/or doubts the participant can have about the system. An example can be: "How will the system work indoors?"

4.1

Gender and Age

Concerning the demographic questions, gender and age are investigated together and represents how many males and females that have participated in the survey and how well the different groups of age are represented. Age division between MALE and FEMALE participants

Age %

100 % 90 % 80 % 70 % 60 % 50 % 40 % 30 % 20 % 10 % 0%

13 % 26 % 11,32 % 28 % 21 % 0% MALE %

7 14 6 15 11 0

17,02 % 23,40 % 8,51 % 21,27 % 23,40 % 6,40 %

8 11 4 10 11 3 55+ 46-55 36-45 26-35 18-25 <18

Number of FEMALE % Number of responses responses

37

Fig. 4-1: Age division between MALE and FEMALE participants The age groups 18-25 are equally represented between the genders. This is a trend that goes for all the age groups and from the diagram the percentage representing in each group of age is quite similar. One group that is not represented in both male and female is the group under 18 years old. There are only three participants in this group and they are all female. The reason for this can be that girls can feel more comfortable when it comes to travelling with parents at this age. However, what was experienced while handing out questionnaires and observing the participants while they were filling them in, was that the parents were automatically in charge when the questionnaires were handed out, and often the oldest person in the family filled in the answers after discussing with the rest of the group/family. The group between 36 and 45 years old are not well represented in the survey at all. The reason for this can be the possibility of the majority of people representing this group have small children and do not prefer to go on "city holidays".

4.2

Occupation

The different occupations represented in the questionnaires are very diverse. Most of the occupations represented are one of a kind within the 53 % that represents the male participants and the same trend is visible in the female part of the survey. However, in the group 18-25 a significant amount of the participants for both genders are students. This is considered logical, since the majority of people under education are in the age group 18-25. In general, some stereotypical occupations occur both in the male and female part of the survey. For men the occupations lorry driver, joiner and crane driver are "typical" male occupations and for the women care workers, teachers and housewives appear. For the female part of the survey the amount of teachers represented were significant. Throughout the investigation of the participants' occupations, the same title occurred once or twice, while in the female part the occupation, teacher, was represented quite heavily. The main reason can be that the majority of teachers have summer holiday at this time of the year. Another solution can be the dimensions of the survey and the possibility that it is too small. The details of the investigation of this question can be found in Appendix A, Section 1.

38

4.3

Interest of usage of Mobile Tourist Guide

This question was designed to investigate how interested the participants were in using a Mobile Tourist Guide if it became available on the market. There were differences between the sexes and the female part of the survey was significant more negative to the idea of using this kind of technology. Almost 30 % of the women were negative compare to only 9 % of the men. This development can mirror females' scepticism against what the male part of the survey might call "gadgets" and also the common interest for technology among the female population in general are lower than the male population. This can come from old "patterns" that women grew into decades ago and started to break lose from in the 1960's and 1970's.

Consider use of Mobile Tourist Guide MALE + FEMALE
100 % 80 % % 60 % 40 % 20 % 0%
No Answer % NO% YES % >18 0 0 3 18-25 0 5 17 26-35 2 7 16 36-45 0 0 9 46-55 1 2 22 55+ 0 4 11

No Answer % NO% YES %

Age

Fig.4-2: Consider use of Mobile Tourist Guide, MALE + FEMALE When the whole group of male and female participants are investigated together, the diagram above clearly states that the majority are positive to usage of a Mobile Tourist Guide. A result that could be regarded as surprising is the fact that the age group 26 ­ 35 are least interested in the technology and also have the highest percentage of people choosing not to answer the question. Normally this group would be considered a group that are updated on what is going on technology wise, but it seems here that this group is critical and sceptic to the use of

39

Mobile Tourist Guides. The reason for this is unclear, but it can be that the scale and size of the survey is too small and do not show the real picture of the situation. The overall positive answer from the group 36 ­ 45 can come from the low participation in this group with only 9 people in total. However, this group can be seen as stronger economically than the previous group and therefore be more positive to try new technology, regardless of the price on the device and the software. The details concerning the separate evaluation of male and female participants can be found in Appendix A, Section 2.

4.4

Preferred facilities on the Mobile Tourist Guide

To map what people would like a mobile tourist guide to contain is something that can be found interesting when you want to investigate where to focus your research and development. Fifteen categories were discovered and charts were created concerning which category could be weighted as the most popular. Two charts were created, one for male and one for the female part of the participants. This made it easier to find any difference in preference between the genders. In some of the categories there is almost no interest at all, but they were quite interesting and worth a mention. Other categories have a high level of interest and are very important to tourists if you consider the results of the survey. The weighting of these results has been done on the basis of how frequent the specific category was mentioned by the participants. After mapping the different categories, the charts mentioned above were created and used as a ranking system where the first is the most popular category and the last category considered the least popular. The table on the next page illustrates the ranking of the different preferences.

40

CHART MALE 1 2 3 4 5 6 7 8 9 10 11 12 13 1 Attractions and interesting sights Maps Pubs/Clubs/Bars/Restaurants Information about public transport (travel info, stops, times) Events/Event locations and times Accommodation (including price details) Price aware places to visit Shopping History of buildings, places and people Shared between: Culture (music, arts, architecture, museums) General info about the city Shared between: Opening hours Road info/accidents/incidents What's near Child friendly activities and child adapted software (FREQUENCY = 0) CHART FEMALE Shared between: Maps Attractions and interesting sights Pubs/Clubs/Bars/Restaurants 2 3 4 Shared between: Information about public transport (travel info, stops, times) Events/Event locations and times Accommodation (including price details) Shared between: Shopping Opening hours History of buildings, places and people Price aware places to visit Culture (music, arts, architecture, museums) 5 6 7 General info about the city Shared between: Road info/accidents/incidents Child friendly activities and child adapted software What's near Table 4-1: Preferred facilities on Mobile Tourist Guide

41

Considering the two tables above, they illustrate that the ranking of the different categories are quite similar, except that the female chart has more equally divided frequencies between the different choices. This means that the male part of the participants is more aware and certain of what they would prefer to be implemented in a Mobile Tourist Guide. This can again be placed in coherence with the slightly smaller interest women show for the new technology compared to men. The category that concerns children are not mentioned at all amongst the male part while the female part have mentioned it, but it is not highly ranked on the chart. Overall it is "Maps", "Attractions and interesting sights" and "Pubs/Clubs/Bars/Restaurants" that are the top three categories even though it is slightly more vague and evenly chosen in the female part of participants. There were a few other suggestions mentioned that were not mentioned by many, but could still be interesting to take in to consideration. A participant of the female part of the survey suggested that it could be useful to have the nearest police station, hospital and doctor displayed on the mobile tourist guide as an option, if any unexpected incident happened and emergency care needed. This could be a useful addition to the mobile tourist guide and can also make users feel more secure. Countryside walking and cycle tracks are also interesting suggestions which can help the mobile tourist guide to broaden and catch more users that are interested in more than just experiencing "city life".

4.5

Group Awareness and Group travelling

This part of the questionnaire considers what can maybe be called the "un-investigated" part of the research on mobile tourist guides. Research that has already been done on this issue have focused more on the individual user, while in this case it is of interest to map how many participants travel in groups and what type of group they travel in. The genders are analysed separate and joint, so differences or similarities can be spotted. This diagram beneath, explains how often the participants travel in groups.

42

Frequency of grouptravels MALE & FEMALE
100 % 80 % 60 %

%
40 % 20 % 0% FE MA <1 18- 26- 36- 46- 55 <1 18- 26- 36- 46- 55 MA LE 8 25 35 45 55 + 8 25 35 45 55 + LE 033032 222001 0 0 0 4 4 0 7 4 1 3 3 0 4 7 0 1 4 0 Age 0 1 0 5 4 0 0 8 0 0 3 1 2 9 0 3 3 1

Always Often Sometimes Never

Always Often Sometimes Never

Fig.4-3: Frequency of grouptravels, MALE & FEMALE The part of the diagram showing the females participating in the survey has a more diverse diagram. The comparison by gender of those who always travel in a group, which means more than one person, shows significantly higher incidence for females than males. This can illustrate that women feel more comfortable travelling in a group, than travelling alone. However, not to forget that children are very often involved in women's travelling. The male part has a more equal division between the alternatives available, but the majority of men sometimes travel in a group. If both genders are taken into consideration, the majority do sometimes travel in a group. The alternative "sometimes" can be regarded as sometimes travelling alone and sometimes in a group. If business trips and similar cases are looked into, it is understandable that people might travel alone in some situations. Overall the male and female groups are quite similar. The most distinct difference must be that males seem to travel more often in a group than females. The 55 + group shows that males are more dependent on their partner as they get older than females are. If this is a fact or the scale of the survey can disillusion, remains unclear. The diagram illustrates that the share of men that always travel in a group are larger in the male part of the survey than the female part.

43

A more detailed explanation of the diagram can be found in Appendix A, Section 3.

4.6

Categories of Group travels

There are four categories that represent the different kind of ways of travelling. The different categories are split into participants who travel on bus tours, with partner, with a group of friends and last an option called "Other". This is made available for specification for the participants who travel with either of the above categories. What seemed to be an issue with this question were the participants ticking more than one box, i.e. partner and group of friends. This had to be taken into consideration and the diagram below does not illustrate the "double- ticking" of boxes. The two boxes that were ticked most frequently were `travelling with partner' and also together with friends. The table below shows the first box ticked and does not illustrate that there could be more than one box ticked. That is the reason of the large amount of people travelling with friends and the low amount of people travelling with a partner.
Which type of group do people travel in?
100 % No Answer Other 80 % Partner Group of Friends Bustours 60 % % 40 %

20 % Age
MAL <18 E 0 0 0 0 0 1825 0 0 1 10 0 2635 1 3 3 8 0 3645 0 1 1 3 1 4655 1 2 7 1 3 55+ Sum: 0 0 3 3 1 2 % FEM <18 ALE 0 1 0 2 0 1825 0 2 1 8 0 2635 0 2 1 6 1 3645 1 1 0 0 2 4655 0 3 0 7 1 55+ Sum: 2 0 1 4 1 3 %

0%
No Answer Other Partner Group of Friends Bustours

3,80 % 6 11,30 % 15 28,30 % 25 47,20 % 5 9,40 %

6,40 % 9 19,20 % 3 6,40 % 27 57,50 % 5 10,60 %

Fig. 4-4: Which type of group do people travel in? The combined picture of both parts of the survey, male and female, the amount of females not answering this particular question is higher than the male part. In addition to this, the female

44

part of the survey is smaller than the male part. In the diagram this is illustrated as the blue part of the columns and the no answer part will then be displayed as a larger section in the female diagram than the male diagram. The female part of the survey also has a higher percentage where the option "Other" is chosen. Females have been more specific than the males and specified more thoroughly that they go on holiday and trips together with their family and children. Another result that comes as a surprise is the number of females who travel without a partner. 25,5 % of the female participants travel with a partner while the percentage of males who travel with a partner is 43,4 %, the double-ticked options are included for both parts. The reason for this is unclear, but it can be the size of the survey and the population not being big enough. This can change if you increase the size of the survey or it will remain stable and females do prefer to travel with friends more than they prefer to travel with a partner. If the overall result is analysed, you can see that most of the participants prefer to travel with a group of friends. A part of the percentage that travels within a group of friends do also travel with a partner or with one of the other options mentioned. However, what can be a solution to the high percentage of people travelling with friends, can be the circle of friends people have around them is often more stable and concise, while especially early in life, the partner can change frequently. A more detailed explanation of the diagram can be found in Appendix A, Section 3.

4.7

Usage of the traditional Maps and Guidebooks

The traditional maps and guidebooks have been used through decades and this part of the questionnaire investigates how maps and guidebooks are being used. There are advantages and disadvantages to consider and also what can be the best alternative to use: The traditional navigators or the electronic Mobile Tourist Guide.
8% 2% YES, maps and guidebooks YES, maps YES, guidebooks NO No answer

3% 7%

80 %

Fig.4-5: Usage of traditional maps and guidebooks 45

The sector diagram illustrates clearly that the majority of the asked use both maps and guidebooks when they travel. The reason for this can be the functionality between maps and guidebooks are different. Maps will guide while guidebooks will mostly give summaries and tell about the different places lead to by maps. There is a significant difference between the usage of only maps and only guidebooks and the reason for this is the guidebooks' drawbacks. A book is heavy and bulky to carry and as mentioned above, does not give proper guidance and directions. A more detailed explanation of the diagram can be found in Appendix A, Section 4.

4.8

Advantages and Disadvantages

There are certain advantages and disadvantages concerning the traditional maps and guidebooks versus the electronic mobile tourist guide. The pro ad cons mentioned by the participants were gathered in two tables where the frequency of appearance of each category decided what was ranked highest.
Ranking ADVANTAGES Frequency, f 1Trustworthiness 1Easy to read and use 2Size and Details 3Electronic version 4Cost 5Damage 6Souvenir 7Current and updated information 15 15 10 7 6 2 2 1

Table 4-2: Advantages traditional maps and guidebooks
Ranking DISADVANTAGES Frequency, f 1 Size and Details 2 Current and updated information 3 Electronic version 4 Hard to read and use 5 Damage 6 Cost

Table 4-3: Disadvantages traditional maps and guidebooks

28 18 8 7 5 2

From the tables, four categories are mentioned both in advantages and disadvantages. The explanation on this is the terms of condition for the categories are different. The category "Damage" is present in both advantages and disadvantages. This category can be present in both sections on the basis that for "Advantages" it is positive, because if you lose a map or a guidebook it is not the end of the world. In "Disadvantages" this category is 46

negative, because maps and books are easy to tear and get easily wet in bad weather. Many people also seem to think that maps are quite hard to fold and keep in good shape. The overall picture of how the advantages and disadvantages are rated, give the impression that the stabile and hard copy maps and books are highly appreciated, but the drawback with this is that they are heavy and bulky, and also maps can be hard to read and understand if there is little knowledge about how to interpret them. The electronic version is also mentioned. The main advantage is the size and the amount of information that can be fitted in it, while the main disadvantage is the cost of the device and if it is trustworthy. A more detailed explanation of the diagram can be found in Appendix A, Section 4.

4.9

Mobile Tourist Guide: A better service than the traditional?

The participants were asked if they thought that the Mobile Tourist Guide would provide a better service to the public than the traditional guidebooks and maps. The majority agreed, however the female participants are again more negative than the male participants. This pulls the average down and the section of the diagram that is positive shrinks in favour for the negative part.
Mobile Tourist Guide: A better service than traditional maps and books? MALE & FEMALE

14 %

7% YES NO MAYBE 56 % NO ANSWER

23 %

Fig. 4-6: Mobile Tourist Guide: A better service than traditional maps and books? MALE & FEMALE The overall impression is positive, but there is also left a part of the participants who are uncertain and can change their minds in either direction. The negative influence on the diagram is mirrored from earlier questions where the interest around using the mobile tourist guide is low. A more detailed explanation of the diagram can be found in Appendix A, Section 4.

47

4.10 Trustworthiness and Security
The last question in the survey concerns the trustworthiness of a mobile tourist guide. This question investigates if people would trust this kind of technology and in case the technology is not trusted, a valid reason is given. The trustworthiness of the mobile tourist guide can include the application running correctly and give the correct guidance at any time or also include the hardware and technological breakdowns and similar cases. To trust is also an issue that has to do with personal safety and that personal details stored in the device and such issues are protected.

Would you trust a mobile tourist guide? MALE & FEMALE

6% 17 % YES NO NA

77 %

Fig. 4-7: Would you trust a mobile tourist guide? MALE & FEMALE Technology in general is more trusted now than before, but hardware and software "crashes" are a well-known problem. When the joint diagram is investigated it illustrates the large majority who will trust and support a mobile tourist guide. The explanation to this can be that technology certainly goes wrong sometimes, but it is improved every day and also the support structure around hardware and software today are very solid. Help can be given sometimes on a 24-hour basis, just by pressing a button or dialling a number. However, the reasons for why the mobile tourist guide is not trusted are spread over an area that covers economy, technology and difficulty level.

48

4.11 Comments and Opinions
The last part of the questionnaire was reserved for the participants' own opinions. There were many interesting suggestions and they varied from excitement over the idea to people who would like to keep their human tour guide and also keep their holiday technology free. Two tables illustrates the opinions, one male and one female table: MALE: 1. 2. 3. 4. 5. People from USA are not as technological enlightened as the Europeans. The mobile tourist guide technology must therefore be adapted to different markets. Excellent! How does this work indoors? Well done! Good stuff! Do not often rely on guidebooks, because it is preferable to talk to locals instead. The reason is that a guidebook cannot really tell you if a pizza place is good or not. It might be ranked as a good pizza place, but can in reality be bad. This information is what you get from the people in the local area. 6. 7. 8. 9. Navigation system Must be updated and reliable Prefer cycling and hiking free of any electronics. This might be a good product for people who are not very fit in English. Must consider the costs versus the costs of the traditional maps. Will this be an upfront fee system or a user paid system? 10. Success! 11. Not an enthusiastic cell-user. 12. Software must be easy to update and cheap. 13. The guided tour is best! Table 4-4: Male comments

49

FEMALE: 1. 2. 3. 4. 5. 6. 7. 8. 9. I am sure it can interest other people. Price of software Keep the tour guide! Sounds fascinating and would be interesting to try out. Do not think it will replace the maps or the guidebooks. If such technology would become available outside the US, usage would be considered, but probably not. Interesting to find out if the mobile system is an improvement on maps and similar. Not brought up in the technology age. Easily understandable design and affordable by all. No taxing! This is just the start! Looking forward to try it!

10. Would have liked to have this on a recent trip to Prague. 11. Depending on the country you are from, will it work on a mobile? Maps etc. are often free. Impressionable communication and more fun verbal. Technology is ok at work, but not on holiday. 12. Like the idea, but not necessarily on a mobile phone. Table 4-5: Female comments

4.12 Summary
The survey has given an interesting insight in how people would welcome the mobile tourist guide on the market. Even though the majority is very positive to most of the issues mentioned in the survey, there are some, mostly female, who are not very excited about the idea. That means that the development of a system ready for the market must think of how the doubters can be turned into believers and also how to make the negative responses into positive by adapting the system to the user in a way that makes it easy and understandable for all users, both young and old.

50

5.0 Software Implementation and Development
Software Implementation and Development deals with the issues concerning how to develop software for smartphones, what hardware requirements there were to build the Mobile Tourist Guide and what problems occurred during the development of the system, including how to overcome the specific problems.

5.1

CLIENT

5.1.1 Hardware requirements
To be able to build a prototype, the software needs a "host" to run on and to display the facilities implemented in the software. For the Mobile Tourist Guide a smartphone, Orange SPV E200, was chosen to be the device to host the Mobile Tourist Guide software. A smartphone was chosen because it is a device that has extended memory and this particular phone also runs on an operating system that is well supported. GPS is used to provide the Mobile Tourist Guide with coordinates that are transformed into x and y coordinates to position the user on the map. Compared to a Pocket PC or the extended Pocket PC phone editions, the smartphone is smaller and handier. The drawback is the challenge of designing for a smaller screen where all menu choices are limited and grouped to two soft keys. 5.1.2 Orange SPV E200 SmartPhone The device used to host the Mobile Tourist Guide or what can be called the client side of this system, is a smartphone of type, Orange SPV E 200. This phone runs on the Windows Mobile 2003 for Smartphone operating system that gives open access to creating new software for the device. Windows Mobile 2003 for Smartphone has wide support online on Microsoft's own homepages and is an open standard where the API is easy to use and the MSDN library is well developed. The smartphone has both IrDA and Bluetooth connectivity. In addition to that it has a docking station with ActiveSync software to handle synchronization between the computer and the device. ActiveSync is also required to upload applications to the device. The screen resolution is 176 x 220 and the smartphone supports GPRS connection to connect to the Internet. A Texas Instruments OMAP 710 processor running at 132MHz powers the smartphone and the internal memory is 32 MB and is also supported with 64 MB of flash ROM. There are

51

possibilities of extending the memory with a SD/MMC card. The Bluetooth connectivity is important in this case. The GPS device will use bluetooth to connect to the Smartphone to provide GPS coordinates to the software and this leaves Bluetooth as an essential feature concerning the choice of smartphone.

Fig.5-1: Orange SPV E200

5.1.3 Global Positioning System
Since the beginning of times people have tried to find out where they are and where they are going. Different positioning systems have been tried out over the years, but all had their disadvantages. In the beginning of the 1970's the U.S. Department of Defence started the testing of what is know today as GPS, the Global Positioning System. GPS is a worldwide radio-navigation system that was made public in the 1990's and consists of 24 satellites and their ground stations. By using triangulation of signals from the satellites, the system is able to localise the receiver as close as a few centimetres from the actual location. When a receiver "triangulates" a signal, it means it measures distance using the time radio signals travel from the satellite and down to earth. When three satellites triangulate, they minimize the area the receiver can be in down to two points and most commonly one of the points is completely irrelevant and can be excluded without taking further notice. The receiver is then left with one point, which is the receiver's location. However, if the second point cannot be discharged immediately, a fourth satellite must be used and the signal is now as accurate as can be. In the Mobile Tourist Guide, GPS is used for marking the tourist's location so the user can navigate through a city and also spot other tourists that are in the same group on their map. Two different GPS devices were tried out for the Mobile Tourist Guide, NAVMAN 4400 and EMTAC CRUX II. Both devices were connected to the SmartPhone via Bluetooth connectivity.

52

5.1.4 NAVMAN 4400
The first GPS Bluetooth GPS receiver tested with the SmartPhone was NAVMAN 4400 from the New Zealand based company NAVMAN5. This receiver is driven by three AAA batteries and is not dependent on a charger, which is a positive feature with the device. The NAVMAN 4400 is larger than other GPS receiver, but the batteries support it for up to 30 hours of power.

Fig.5-2: NAVMAN 4400

Fig.5-3 Power supply NAVMAN 4400

NAVMAN 4400's antenna is multi-directional and has possibilities to plug in an external antenna. The receiver has implemented 12 parallel channels and it updates every second after a fix is obtained. The Bluetooth software that is situated in the receiver, implements the Serial Port Profile (SPP) and this is where the problems with the NAVMAN 4400 are introduced. The PIN code was not mentioned anywhere and had to be looked up online. To pair the GPS receiver with the SmartPhone the default PIN code was set to "NAVMAN", which is an alphanumerical PIN. PIN codes are usually set to a four-digit code, but not in this case. This caused an interesting and time-consuming problem concerning smartphones. Smartphones like the Orange SPV E200 do not have alphanumerical PIN input enabled and is also the issue with some Pocket PCs as well. However, for the Pocket PC platform software was developed to automatically enable the alphanumerical PIN input. This was not compatible with the Windows Mobile 2003 platform and other solutions were sought. To hardcode the PIN into the code was one option, but connection between the devices could still not be established and a new GPS receiver with a four-digit code was provided. Another interesting issue that appeared after testing the NAVMAN 4400 on a Pocket PC device where connection could be established was that the device was extremely inaccurate.

5

http://www.navman.com

53

An inaccuracy of up to 250 meters was discovered, which is unacceptable for a GPS receiver and the device was discarded for use in other purposes.

5.1.5 EMTAC CRUX II
EMTAC CRUX II6 is a bluetooth GPS that has the four-digit PIN code required for smartphones and paired easily with the bluetooth connection situated in the smartphone. EMTAC is powered by a rechargeable and built-in lithium ion battery, which can power the device for up to 6 hours. This makes the user dependent on electricity and rechargeable batteries can also have a limited "lifetime", which can wear out the battery quite quickly if the device is used on a daily basis. Apart from the issues regarding power supply and PIN code for pairing, EMTAC CRUX II and NAVMAN 4400 have similar specifications.

Fig. 5-4: EMTAC CRUX II

5.1.6 Developing applications for SmartPhones
The client side of the system consists of the smartphone, as described above, with software implemented and the GPS device to provide input to the system. The software implemented on the phone is developed in Microsoft Visual Studio .NET 20037 and the language used is C#. The Microsoft documentation is open and is cooperating well with the operating system, Windows Mobile 2003 for Smartphone. To be able to work with smartphones in Visual Studio .NET, the Microsoft Smartphone 2003 SDK8 had to be installed. This would give the opportunity to test the applications on an emulator as well as on the device itself. This could be practical, since it takes more time to deploy the application on the actual device than on the emulator. To locate the folder where the applications are being
6 7

www.emtac.com http://msdn.microsoft.com/vstudio/ 8 http://www.microsoft.com/downloads/details.aspx?FamilyId=A6C4F799-EC5C-427C-807C4C0F96765A81&displaylang=en

54

stored, an application called Smart Explorer9 was installed. This piece of software gives the opportunity to browse through the tree structure of the phone and open the folders needed which would normally be hidden if this software were not installed.

5.1.7 Software to capture GPS signals
Software to capture the GPS signals, latitude and longitude, two different libraries were tried out: PocketGPSlib10, which is an open source GPS library developed for Pocket PCs; and GPS.NET where free trial versions of GPS.NET for Compact Framework 1.0 (Smartphone)11 could be downloaded. However, a GPS.NET image referring to the trial version appeared every time the application was run, which slowed down the processing. This was not desirable and the PocketGPS lib was chosen as the main library for development of GPS applications. A separate application, SmartGPS, was developed to process GPS input and check if the communication was flowing between the satellites and the receiver, where the application was built on a piece of sample code from the PocketGPSlib. The interface towards the user is obtained as simple as possible and in the screenshot below the user interface is displayed showing latitude, longitude, GMT (Greenwich Mean Time) and also a textfield where the number of the suitable comport must be entered. When comport is entered, the user presses start and the application will display if the attempt is successful or times out. If a GPS fix is found and obtained, this will also be displayed on the screen.

Fig.5-5: Interface GPS application

9

http://www.binarys.com/SmartExplorer_en.asp http://gps.iter.dk/ 11 http://www.gpsdotnet.com/
10

55

5.1.8 Implementation of classes from PocketGPSlib in methods
A GPS event handler was created to deal with the GPS events and capture the input from the receiver. This handler uses the GPSHandler- class that are predefined in the PocketGPS library and processes the raw GPS data coming from the GPS receiver. Example GPSEventHandler- method:
private void GPSEventHandler(object sender, GPSHandler.GPSEventArgs e) {}

The GPSHandler- class takes care of conversions and introduces and defines a new object, comport. This uses the class Comport, which is also predefined in the PocketGPS library. The Comport- class is used in the SmartGPS application to assign a comport for the communication between the devices and for receiving the input needed. The method "StartComm" takes care of assigning the correct comport using these lines of code:
int iComPort =int.Parse(ComPortNo.Text); GPS.Start(4800,iComPort); //Open port at 4800baud latitude.Text = "ComPort:"; latOutput.Text = iComPort.ToString();

This chunk of code is run when there is a comport need to be assigned and opened at a certain baudrate, for GPS the most common baudrate is 4800, as in this example. The number entered by the user in the textfield, is the comport number that is preferred. This is parsed to an integer by the code shown above and thereafter processed. The most common comport in these cases are comport number six, COM6. This opens for a flow of data between the devices.

5.1.9 Communication issues
The Smartphone paired easily with the EMTAC CRUXII and was organized to give a proper flow of communication between the devices and provide input from the satellites. However, the SmartGPS application refused to take any input at all and connection with comport timed out on COM6. The application, SmartGPS was developed with assistance from the PocketGPS library sample code, but did not give any result. Attempts to connect on the remaining comports failed, but was caught by an exception handler in to code and displayed:

56


A possible explanation to the problem could be the input provided by the user in the textfield is currently the digit 6, while the smartphone might need the input, COM6. This issue was investigated, but found unlikely. The reason for this was there was found a conversion from COM6 to only the input 6 in one of the classes available in the PocketGPS library. A part from this, no reasonable explanation could be brought forward to help solving the communication problem.

5.1.10

Main Application: Interface and Implementation

The main application for the Mobile Tourist Guide is kept as simple as possible, both when it comes to interface and also code structure. The interface is showed below to the left and displays the main interface for the guide.

Fig.5-6: Interface MTG

Fig. 5-7:Structure of menu

Fig.5-8: Get Coordinates

The main menu is situated to the right and has four options available: GetMap, Get Coordinates, Help and About. Each of the choices on the menu is connected to an eventmethod in the code, which executes methods when the menu item is clicked. For instance, if option 1 is chosen, GetMap, an event called menuItem3_Click is called and this triggers a series of events that loads the map of a piece of the Glasgow city centre. To be able to display the map, a method, pictureBox1_ParentChanged_1, where the map is

57

loaded by creating an object of the Bitmap- class containing the path to where the picture is situated. Example:
Bitmap map = new Bitmap(@"\Storage\Program Files\GetWebsite\MapCityCenter2.bmp");

However, the most important event is when the menu item, Get Coordinates, is clicked. This event calls the largest method in the Mobile Tourist Guide application called, Webfetch(). This method is absolutely crucial for the connection between the server side and the client side of the Mobile Tourist Guide. This method fetches a web page using the classes,
HttpWebRequest and HttpWebResponse. HttpWebRequest and HttpWebResponse are in the Compact Framework, what can be called

Pluggable Protocols (Fox and Box, 2004). Pluggable protocols are a layered and extensible mechanism and is a class built on the basis of the abstract classes in the System.Net namespace. The concrete classes inherit from the abstract classes and are registered as supporting a specific protocol. The method WebRequest.Create()returns the registered class concerning that protocol and in this case a URL is situated here and passed into the Createmethod. This URL has a HTTP prefix and the only pluggable set in the compact framework is the HTTP methods HttpWebRequest and HttpWebResponse. These inherit from
WebRequest and WebResponse.

When the Webfetch()- method is called, this triggers the loading of a website processed by the methods described above. This website is situated on the server side of the system and contains a list of who is in the system/group and their current positions. The server side of the system will be described in the next section. However, to be able to process the data from the list and eventually situate the positions on a map, regular expressions were used taking advantage of the RegEx ­class in C#. Regular expressions allow certain parts of the output to be excluded and in this case to get a clean and "parseable" output, both HTML tags and eventually all text and punctuation were removed by creating patterns and filtering the input.


58


The declaration of the string variables introduces the different patterns of regular expressions and the input that contains the information from the website, tempString, is processed and the parts that matches the patterns of regular expressions are being set to empty. After the unnecessary information is removed using regular expressions, the information from the website needs to be processed so it can be converted into coordinates on the map. To do this, the coordinates must be broken down into substrings and processed one coordinate at a time. To break down the input, a for- loop is introduced together with a counter and also the input is read into a charArray.
char[] ca = tempString.ToCharArray(); int start = 0, end = 0; for(int j = 0; j < ca.Length; j ++) { if (ca[j] == ':') start = j+1; else if(ca[j] == ',') end = j; x = tempString.Substring(start, end-1); substrings y = tempString.Substring(end+1); } //breakes down to //loop to display x=what is after colon, y= after comma //charArray to store the strings

The coordinates are then being parsed to integers and stored in an ArrayList. The ArrayList make it easier to handle the values and extract them for conversion to fit on the map. The ArrayList is declared in the top section of the MTG-class together with the struct, coord.
ArrayList GPScoord = new ArrayList ( ); GPScoords //arraylist to store the

To be able to get any coordinates on the map, the ArrayList has to be populated and this is done when the menu item, Get Coordinates are chosen. This must therefore be done before the GetMap option is chosen. The page containing the coordinates is loaded by using GPRS and to display the information on the smartphone, MessageBox.Show(build.ToString()); is used.

5.1.11

Coordination Plotting and Graphical Programming

When the array belonging to the Webfetch()-method is populated, the option GetMap on the main menu can be pressed and the map will be loaded on to the screen. The map used is borrowed from the yellow pages12 and displays a small part of the Glasgow city centre. When the option is clicked, this creates a new instance of the object,Bitmap(),and the image, situated in the same folder as where the rest of the application is stored on the smartphone, is loaded and displayed:
Bitmap map = new Bitmap(@"\Storage\ProgramFiles\GetWebsite\MapCityCenter2.bmp"); pictureBox1.Image = map;

To be able to draw shapes on the canvas, a new event called MTG_Paint(),was created.
private void MTG_Paint(object sender,System.Windows.Forms.PaintEventArgs e) {}

This method makes it possible to use methods from the Graphics-class that has different facilities implemented. To be able to draw anything at all, a pen must be declared to have a "tool" to draw with. For each new set of coordinates available this pen will theoretically draw an ellipsoid that will display the different users in situated on the map.
Graphics g = e.Graphics; Pen pen = new Pen(Color.Black); coord cd = new coord(); this.BringToFront();

12

www.yell.co.uk

60


This piece of code coord cd = new coord(); creates a new instance of the struct coord(), that has been declared in the top section of the class. This struct contains two variables to handle the latitude and the longitude coordinates. This will populate and array called GPScoord, which will handle the storage of the coordinates. The array will be populated in a for-loop and this will then draw the ellipsoids mentioned above.
this.BringToFront() will bring the drawing to the front and the ellipsoids will be drawn

on the top of the map and display the users' positions. While the method where the map is loaded, the similar structure, this.SendToBack(), will send the map to the background.
this.Invalidate() is also situated where the map is loaded and will repaint the screen each

time it is run and call the event MTG_Paint(). However, what seemed to be a problem when the application was run was the drawing not being sent to the front and the map was not being sent to the back. This caused problems and the ellipsoids were drawn on the canvas behind the map. If the map were minimised or removed, the points marking the coordinates would appear, but not on top of the map. To solve the problem a new method called, OnPaint(), was tried out. This method was populated with the same input as the MTG_Paint() event, but did not give the desired result and the initial dot was still situated underneath the map.

5.2.

SERVER

5.2.1 PHP and MySQL
The server side of this system contains a MySQL database that contains a table, GUIDE, which again contains 4 rows, G_username, X_coord, Y_coord and G_TimeDate. These fields 61

contain information about who is in the system, where they are and at which time they were there. The table is connected to a PHP- website that connects the client and the server side of the system. This website is downloaded by the C# application located in the client. The URL downloaded contains PHP code that initiates who the user is and the user's current position. This is extracted from the URL in the code of the website and inserted into the database where the current date and time are added. The content of the table is again extracted and displayed as a list on the website, which again is processed and displayed on the smartphone. Three lines of code are being used to capture the information in the URL, three similar $_GET functions, where the new variable names are displayed to the right.
$u = $_GET["u"]; $x = $_GET["x"]; $y = $_GET["y"];

When the required information needed is captured, it is inserted into the MySQL database using a query and the variable names that were created above. In addition to this, a variable called, $datetime, were created to ensure the time and date the entry into the database were made.
$query = "insert into GUIDE values('$u','$x','$y','$datetime')"; $result = mysql_query($query);

To make sure that it is impossible for a user to enter the same name and details twice, an update statement was developed to update the database. This will ensure not more than one entry per user and also if the positions of the user are altered, the name will stay the same and the positions in the database will be updated.
$query1 = "update GUIDE set G_username = '$u', X_coord = '$x', Y_coord = '$y' where G_username = '$u'"; $result1 = mysql_query($query1);

When the information is captured and processed, it is fetched and displayed dynamically on the screen as a list.

62

Fig.5-9: PHP output in Internet Explorer The output on the smartphone will look similar to the above figure if no regular expressions are added to process the code.

5.2.2 HTML
It is important to keep the server side as simple as possible. The reason for this is to ease the smartphone's processing time, which will gain the system. When the HTML source of the PHP page is displayed, we can see that it only contain 4 tags with belonging end-tags. This is also to improve the speed of the system and saves processing time.

Fig.5-10: Simple HTML

5.3

Client- and Server- side issues

The basic code to retrieve a website and the server side coding on the website in PHP, did not cause any larger problems. However, before a website could be connected to the database the problem regarding secure connection had to be solved. Exceptions occurred when deploying the C# code, the reason was due to the ability to access the database from outside the university network is not possible unless the messagebox is

63

manually clicked and diverts to the secure area. This messagebox caused problems and changes had to be made in the account set-up so the messagebox could be bypassed without any interaction from the user. When the server side PHP- code was designed and the basic features were introduced to the code, a new problem occurring was a lower level problem between PHP and the C#. This caused the emulator in Visual Studio to crash and it was not possible to test either code or applications. The cause the problem seemed to be the browser storing "old" data and it kept on crashing the program. After refreshing and trying different links, the browser would open the URL, insert the data represented in the URL into the database and extract the data and display it as a list without any problems. The problems vanished when deploying the application on the smartphone, but when deploying in the emulator in Visual Studio .NET, the problems were still present. This left the testing of the application to the smartphone and not the emulator. The issues appearing while trying to draw the coordinates was unexpected, since there were methods that were supposed to handle the different situations. What was discovered where that functionalities like setting an image to the background, was disabled in the .NET Compact Framework. Another line of course that was investigated was to make the map transparent. This was possible, but due to the shortage of time, the topic remained investigated, but untried. What could have been the solution to the transparency issue, was to introduce image attributes, ImageAttributes attr = new ImageAttributes(). Drawing an image with transparency requires an ImageAttributes object, which specifies the transparent colour. At the moment, the .NET Compact Framework supports source colour key transparency of a single colour13 and it remains unclear if this means that it is the drawings that are being made transparent or if a loaded image can be converted over to become transparent.

13

http://msdn.microsoft.com/smartclient/understanding/netcf/FAQ/default.aspx#2.4

64

6.0 Evaluation and Results
This chapter will analyse the overall result of the development of the Mobile Tourist Guide and what the outcome of the project is. Testing will be documented and the limitations of the prototype will also be discussed, together with a summary of the general outcome of the market survey. The Mobile Tourist Guide has a bright future if the conditions are right and the financial support for research is provided. A section concerning the mobile tourist guide's future will be presented to describe ideas on how the future work can be carried out.

6.1

The Final System with Development issues

The prototype of the Mobile Tourist Guide was developed to aim towards both individual travellers and tourists travelling in groups. From the survey conducted during the development of the system, the overall result showed the majority of people that participated in the survey travelled either together with friends or with a partner, which could therefore be referred to as a group (more than one person). However, the Mobile Tourist Guide can also be suited for larger groups of tourists. The final outcome of the development of the prototype shows that it is possible for a large group of people to have an overview of where other members of the group are situated. To be able to do this they must all use the same software, the Mobile Tourist Guide, and in this case update their position to the same website, which inserts the data into the database. The prototype converts the coordinates into coordinates fitted on to a map and this displays the user's location. The server side of the system is functioning well, but the client side of the system has experienced some problems that have been difficult to overcome within the limited time that was available to develop this type of software. The main and also the first problem that occurred was the communication between the NAVMAN Bluetooth GPS receiver and the Orange SPV E200 smartphone. The alphanumerical PIN, that was embedded in the GPS receiver, made it impossible to pair the devices and also as an outcome of that, to receive any GPS signals. The problem seemed to be solved by changing the GPS receiver to the EMTAC CRUX II. The devices paired perfectly due to the digit passkey (PIN) that was embedded in the receiver. However, after the testing software for receiving GPS coordinates was developed, problems with reading and connecting to the correct comport occurred and once

65

again hindered the communication flow between the devices. This problem was closely investigated and different strategies were tried out to make the communication flow as intended. The software developed for GPS testing, had a manual input from the user regarding which comport to choose. This solution was discarded by hard coding comport number 6 into the software, as described in the section Software Implementation and Development. This method did not give any results and it was suspected that the reason for the problem could be that the input should be COM6. This was also tested on the software, but gave no results. Due to the time constraints GPS communication had to be discarded and to simulate GPS, fixed coordinates were used to plot locations on the map. The user interface is clean and concise, which is an important feature when it comes to design of software systems. The colour theme in the Mobile Tourist Guide is set to royal blue to represent the colours in Scotland's flag and also to represent authority and trust, which is an important impression to give to the user. The menu system is easy and the user understands what to do out from the names on the menu options. The software itself is displaying the users' coordinates and also loads a map of a selected section of Glasgow city centre. The client side of the system is connected up to the server side and the information given from the server side scripted web page (PHP) is processed by the software developed in C#. The web page is downloaded into the smartphone, processed and filtered so that the relevant information can be extracted, which is the coordinates. The coordinates are parsed into integers and a circle is plotted on the screen. However, the issue that appeared regarding plotting on the map was the lack of a BackgroundImage ­option. This option is available in the .NET Framework, but has been removed from the options in the .NET Compact Framework. When the coordinate was plotted on the screen, the canvas that was used for plotting was underneath the map. To transform the map in to a transparent map was one option that was available and also to use a method, onPaint() which should in theory paint ontop of what was situated on the screen. Either method functioned as it in theory should do and the dot was situated in the right spot according to the coordinates, but could not be visible unless the map was removed.

66

When the code was to be extended to handle more than one set of coordinates from the database, an unexpected exception appeared and the arrays seemed to be out of bound. This was due to the parsing and only one set of coordinates could be parsed at a time. The solution to this problem was to extend a for-loop, but the results did not appear in the format that was expected. The overall experience with the final system is the base for a group-aware mobile tourist guide. This has been developed and the system works satisfactorily, if the problems regarding GPS communication and the lack of a transparent map are discounted. Problems that appeared towards the end of the development presented a particular challenge to sort out due to the time constraint. Communication issues concerning the GPS receiver created a hard nut to crack and required quite some time towards the end of the project: research to solve the problems; and also contact with the manufacturer of the NAVMAN GPS receiver in New Zealand.

6.2

System Limitations

The Mobile Tourist Guide is a system that can experience several limitations, both concerning software and hardware. The limitations experienced during the development of this prototype, was connected to the GPS issues and the lack of available functions when it comes to the .NET Compact Framework. When a Pocket PC and a Smartphone are being compared, it can seem that developing software for Pocket PCs might be easier due to the screen size and also due to some features that have been disabled when the Smartphone 2003 SDK was embedded. However, the functionalities are diverse but limited in the SDK and the Visual .NET 2003 is a tool that are amazingly well functioning when developing software for Microsoft Windows based systems, both when it comes to debugging and suggested code given by the development tool. Systems using GPS can normally have problems regarding the receiver's request of having three or four satellites in sight to get accurate location data. This is due to the landscape in the current area and for cities like Glasgow, tall buildings and narrow streets can block out the GPS signal. There is however a solution regarding this problem available in the near future. The new AGPS (Assisted GPS) technology describes a system where outside sources, such as an assistance server and reference network, help a GPS receiver perform the tasks required to

67

make range measurements and position solutions14. This will almost eliminate the problems regarding loss of GPS signal. If this technology were available today, the problems experienced with the Mobile Tourist Guide regarding GPS connectivity would not be present. The AGPS technology would be implemented in the Smartphone from the manufacturer and the now external and slightly bulky GPS receiver would have been made redundant. This would eliminate both the problems concerning loss of signal and also eliminate one node in the communication flow, the Bluetooth connection between the GPS receiver and the Smartphone.

6.3

Market Survey

The market survey reflects how a system like a Mobile Tourist Guide would be accepted in the market and also what the public would prefer in terms of facilities implemented in the system. The results of the survey were a mixture of some rather surprising results and also some results that were expected. In general the majority of the participants in the survey were positive and open minded about trying new technology and some were especially excited about the size and functionality of a mobile tourist guide. The reason for this excitement was the main disadvantage of size and weight with the traditional maps and especially guidebooks, and also the fact that guidebooks get very quickly outdated. A Mobile Tourist Guide would eliminate large rucksacks filled with heavy books and maps that are hard to fold. However, the disadvantage mentioned regarding the electronic version of maps and guidebooks, the mobile tourist guide, was the price of the device and the software, and also if the software could be adapted to new markets and groups of users, like the elderly and children. A concern that is present in the general opinion is the cost of the system, but also the cost of losing the device. The traditional guidebooks and maps are rather cheap and easy to replace, while an electronic device is considered more of an investment. The overall impression of the survey is positive, but the female part of the participants is more sceptical towards new technology and to technology in general. The attitude in favour of the Mobile Tourist Guide can in some cases be reflected in how well- educated the women are, while in other cases the well-educated women are more negative towards the technology. One of the female participants stated: "Technology is preferable at work, while being holiday I
would like to leave the technology back in the office." (Appendix A, Section 6)
14

http://www.gpsworld.com/gpsworld/article/articleDetail.jsp?id=12287 [Last accessed: 12.09.05]

68

For the male part of the participants the overall attitude towards technology was positive, however there were some men who had similar opinions like the lady who preferred to leave technology behind while going on holiday. The males seemed to be more aware of the technology available and are also more positive when usage of such systems are considered. This reflects some old fashion opinions when it comes to female v. male and the battle of interest around technology. However, the results from the survey also reflect a piece of reality.

6.4

Black Box Testing and Reverse Engineering

Black Box testing was carried out to test the application's functionality. The focus of Black box testing, is to investigate the I/O behaviour and if the result can be predicted for all output, the module passes the test. The testcases illustrates input, the output will be investigated and a conclusion drawn. The testing will commence after the user has opened the first and introductory page of the application. TESTCASES: Input: Output: Conclusion: Input: Output: Conclusion: Input: Output: Conclusion: Input: Output: Conclusion: Input: Output: Conclusion: Input: User press main menu Main menu pops up with 4 options available It is possible to press the main menu and select one of four options. User selects GetMap A clean map loads Map is displayed without coordinates plotted User selects Quit Application exits The application exits if quit is clicked, even though the map is still visible. User selects menu menu pops up with 4 alternatives Back to initial menu stage and map is static on the screen User selects Get Coordinates Coordinates are being downloaded and displayed User coordinates have been downloaded User selects OK

69

Output: Conclusion: Input: Output: Conclusion: Input: Output: Conclusion: Input: Output: Conclusion: Input: Output: Conclusion: PSEUDO CODE:

Application back to startup screen, but with map displayed Coordinates are available User selects Help Guidance tips given Help function displayed User selects About Information about application is given Displays a textbox containing text User selects Get map Map with drawing sticking out on the side Coordinates given and plotted, but map is on top of drawing. User selects Quit Application terminates End of program

I. If mainmenu is chosen II. Display main menu III. If GetMap is chosen IV. Load map V. Else Quit VI. If GetCoordinates is chosen VII. Load web page containing coordinates VIII. Ok is pressed IX. Else Quit X. If Help is chosen XI. Textbox containing guidance is displayed XII. Ok is pressed XIII. If About is chosen XIV. Textbox containing information about software is displayed XV. Press ok XVI. If GetMap is chosen XVII. Coordinates painted on the canvas XVIII. Else Quit 70

The Black box testing illustrates how the system flows and that the options available are easy to understand and the interface is clear to the user.

6.5

Summary

The prototype that has been developed during the work of this thesis makes a good basis for future development. The Mobile Tourist Guide has a large market potential, which is reflected in the market survey and the problems that arose during the development would have been possible to solve if more time had been available for research and software development. Some of the problems, like the GPS connectivity would even get eliminated if the new AGPS technology was available on the market today. The system has some limitations concerning screen size and development tool issues, however both hardware and tools will improve with time and the limitations might be reduced in a few years from today.

71

7.0 Future Work
This chapter will discuss how the Mobile Tourist Guide can be further developed from the stage it has been left. The future of context- and group- aware systems are bright and the technology is improving every day to fit users needs and to fulfil constantly more demanding requirements from both users and developers. This will give mobile systems a possibility to blossom if the conditions concerning timing, marketing and price are right.

7.1

Extended Market Survey

The use of the market survey gives an important pointer towards what the general public would prefer in a Mobile Tourist Guide. This can be used to investigate not only interest, but also, if the survey is done in advance, the system can be adapted to what the participants in the survey would like it to contain. It would be a good idea to extend the survey to cover more participants to get a wider insight and also to get results that are more accurate and statistically correct.

7.2

Navigation

The future Mobile Tourist Guide will have extended features in all sections and the there is a large potential in development. One of the main issues regarding the Mobile Tourist Guide is the possibility of navigation and guidance using electronic maps. The current implementation of the Mobile Tourist Guide use a regular image as a map, borrowed from the yellow pages. The map can be improved to contain a variety of different views the user can choose between. It is important to give the user the possibility to choose what is most suitable and a list of options could be available. The map can have birds-eye view, a ground-level view (pedestrian) or an option where the user can chose how high up he or she would like to hover above ground. The dot illustrating the user's position will be present on the map, and also it could be useful to draw a line to illustrate where the user has been and possible routes the user can go. Routes that have already been walked can be colour coded to avoid confusion with the routes that are possible to walk. The system can welcome the user back to places that have already been visited more than once and a useful facility can be to space out landmarks that are easy to recognize. This feature can make users more secure so it is more certain that they are not lost.

72

7.3

Group awareness

The future system will extend the focus towards group awareness and add features like instant messaging between the members of the group and extended sharing of experience between the group members. If the user is travelling with a human guide and within an organized group, the guide can have "master control" over the group and the guide has an overview over everyone in the group on the Smartphone. The guide can have the possibility to send out a joint message to the whole group (i.e. departure times of bus or boat, changes in schedule, etc.) or send a message to specific members of the group who are moving too far away from the group when departure time for bus/boat/new location is approaching. When it comes to privacy issues, an idea taken from the instant messenger MSN Messenger, have been transferred into being used in the Mobile Tourist Guide. The group members can set their settings to invisible, and be invisible to both the guide and to the rest of the group. The "invisible" member of the group will still be able to see the rest of the group, in case there is a wish to follow the guided group tour again. Both visible and invisible members in the group can spot the group members that have their settings set to "visible mode".

7.4

Introducing user modes

The use of different modes can be introduced to adapt the system to different needs and to different users. The software must have at least 3 different modes that can cover most of the users that can possibly take advantage of using the system. The three different modes that can be introduced are: @ @ @ Kids Mode Normal Mode (for people with no impairments) Special needs Mode (for people with i.e. visual impairments or elder people)

"Normal mode" and "Special Needs mode", do both have three substructures that are called: "Self Exploration Mode", "Personalized Mode" and "Tell me everything Mode". "Self Exploration Mode" is a setting where the only information given, is the necessary information from group members or the guide. This information will be given if the status on the device is set to "Visible" or the human guide overrides the system and announces a joint message. The system itself will not provide the user with information, because the user is now 73

exploring using the device only as a map for guidance. If the status is set to invisible, only emergency messages will reach the user. "Personalized Mode", will only present the things that are in the user's interest. Emergency messages will reach the user regardless of the status on the phone, but in general the visible/invisible issues presented above in "Self Exploration Mode" are activated. In "Tell me Everything Mode", all relevant information that the system contains, is given to the user. This mode will give a lot information and the user should not be in a hurry since nothing is left to chance and the user is guided from A to Z. Emergency messages will naturally reach the user as described in the previous modes. The visible/invisible issues will also be present in this mode. The system will use an instant messaging system between the different members of the group. To be able to send and receive messages, the user must be visible in the system (not set as "invisible"). It is important to be open about who is sending and who is receiving to try and pass problems regarding withheld identity. The system will know where everyone in the group is, regardless if they are visible or not. In case of emergency or disappearance of one of the group members, the guide can then override the system and locate the missing or ill person. To avoid guides with "mastercontrols" to misuse this feature, limitations must be introduced to this issue.

7.5

Utility

The system can take advantage of pop up messages that informs where the user is and what the user can see. The information should be personalized after the user's wish, but there must be a possibility to dig more into the topic if the user finds something of interest. Example: The user walks through an art gallery and finds interest in Monet and Picasso. The user would like to view the pictures painted by these specific painters and the system directs the user towards them. On the way through the gallery the user can get pop ups that informs about other painters, which could be a brief summary and the possibility of making a choice. The message can be formed like this:
"You are now walking past a wonderful national romantic picture, painted by Gude, showing traditional Norwegian scenery.

74

Would you like to know more about the Norwegian national romantic époque and its painters and paintings?" YES or NO

The user can then choose out of interest and have a look if that is desirable. If the user gets truly interested, the topic can be added to a personalized account and stored in a database for later use.

7.6

User Interface

The design must be clear and clean and the ability to use the system easily and understand quickly is important. It could be an advantage to use an interface that is familiar to users initially, like the initial used Windows framework. This is on the other hand something that can be discussed. The design must be, as mentioned, clear and easy, and the different menus and pages must not be overloaded with information. The less information on a page the better it is. Concise and concrete menus and pop ups that leave no doubt what their meanings are.

7.7

Technology

The system must be able to cope with both indoor and outdoor transmitting and receiving. AGPS is the newest technology that is available in the immediate future and this technology bypasses most issues concerning using GPS indoor. If AGPS is not available, the system can use regular GPS for outdoor usage and WLAN or Bluetooth for indoor usage. Bluetooth is cheap and the devices are small, which could be advantage. An assumption must be made if this should be available for the majority in the future, which is that the phones in use must be the Pocket PC Phone editions or Smartphones. These phones use a familiar frameset (Windows), but this can, if preferable, be changed and new the software can be adapted to fit new platforms. 7.8 Problems and Questions

When people travel with good friends and even alone, there is the issue concerning being open and to get to know new people. It is important not to isolate the tourist inside a mobile tourist guide, with earplugs and total devotion to the system. This will destroy the social experience around travelling. We must take in to consideration the preservation of the sensory aspects the feeling and exploring and travelling. A part of being a tourist is to hear, smell, look and listen and it is therefore important not to make the tourist an isolated, asocial and unreachable individual.

75

The device should preferably be apart of the users everyday life and the usage of it be natural. This will make the "job" of purchasing the Mobile Tourist Guide easier when it fits onto a device that is already a part of the user's life. The guide can also be used by the younger generation (children and youth) in Kids Mode. This can solve the problem for parents who need to shepherd their children in fear of loosing them. When some groups of parents are asked after a visit in i.e. a museum, the only thing they remembered were the children running around and not the experience and the sights from the museum. But the questions that can jeopardise this feature are: What if the child loses the device and the parents trust the system and leave the child unattended? The child will still appear on the parents screen as a little dot, but this will be the device and not the child. 7.9 Marketing suggestions

The Mobile Tourist Guide software should be available for all pocket PC's /Phones and hopefully in the future AGPS will be implemented as standard hardware in the majority of phones and pocket PCs. A cheaper version could be available for indoor use (if AGPS is not implemented on the device). This package requires only Bluetooth or WLAN and is the basic package. The outdoor package is an extension on the indoor package and the system can be bought as a whole or the two separate packages. Concerning the maps, the idea used for marketing and selling the GPS maps available for cars, can be used. An example on this is when GPS maps are being purchased, different areas can be chosen. Maps covering the continent, a separate map for UK and Ireland and another for Scandinavia can be purchased. The main idea can be to do the same for the maps for the Mobile Tourist Guide. The software should be updated frequently and a new edition should be available every year. This can be purchased on a separate basis or be subscribed, i.e. like the new software for Norton Antivirus can be bought online.

7.10 Summary
If the work with the Mobile Tourist Guide were to be continued as a research project for one more year, the main task would be to be able to connect the device to GPS and get a flow of communication in the system. The algorithms used to convert the coordinates must be improved and the user interface could be further developed to contain more of the ideas mentioned above. 76

Firstly the market survey should be extended to cover a wider range of people, so the statistical result could be more accurate. The survey should be carried out before further development, because the future users' opinions should be taken into consideration while developing the new and improved system. Secondly, the maps should be improved to be more scalable and from that point the different modes could be developed. If the modes were successful, the next step would be to introduce the sub functions within each mode. To implement all the functionalities mentioned above, the project would last much longer than a year, but the Mobile Tourist Guide has a large potential and it is likely to believe, even though there are no documentation on this issue, that the functionalities mentioned above would be popular if the software became available on the market.

77

8.0 Conclusion
This thesis describes how to proceed and develop the base of a mobile tourist guide, which has its main focus on group-awareness. The aim for the development of this prototype was to make an application that included a client, a server and communication between the nodes. The application was aimed to process data downloaded from the server's web page and process the received data so it could be converted into coordinates fitted on to a map. This would initially illustrate the different users and their positions and in theory these coordinates was received via GPS. The aims were partially fulfilled, but problems concerning GPS connectivity were a drawback on the development, and other solutions had to be sought to simulate the end ­ result. However, what could be an ideal solution would be to have the new AGPS system available. This would bypass any connectivity or compatibility problems and this part of the project would have gone much smoother. The market survey was carried out to increase the knowledge around how tourists would welcome technology into their holidays and also if there was a general interest for software similar to the Mobile Tourist Guide. The survey covered an area there seemed to be little data available and according to the literature researched, the focus in the survey was therefore sat on group- awareness and also what kind of facilities people would prefer the mobile tourist guide to contain. The survey can be considered a success and interesting results appeared, however it can be questioned if the survey was large enough to give accurate statistical results. The development of the software itself, aimed to give the user a simple interface that could easily be used. The end result has a clean and concise interface where the options available point directly to the action connected to them. The problems experienced during the software development, gave the opportunity to extended research within C#, which illustrated that some functions that was under the opinion of being available, was not available in the .NET Compact Framework. This gave unexpected problems that started a lengthy search for solutions towards the end of the project. Some problems were therefore solved while others appeared. 78

The overall impression of the development of the Mobile Tourist Guide is that this prototype is a base for a product that can be extended almost to the infinite if the time is available. The future work can be an important pointer towards further development and the ideas presented are fully achievable.

79

APPENDIX A
ANALYSIS OF SURVEY

86

Analysis of Survey
The questionnaires were distributed during the weeks of the World Pipe Band Championships 2005. This is an annual event held in Glasgow and 230 bands participate with 8000 pipers and drummers coming from far and near. This was a golden opportunity to investigate people travelling in groups and most of the questionnaires were handed out on George Square, on the See-Glasgow buses and also a few were handed out on the ISEC conference held at the University of Strathclyde in early August. 100 questionnaires were handed out and the division between the genders were 53 % of the participants were male and 47 % female. Most of the answers are analysed on the basis of genders to find differences in opinions between the sexes and also a joint analysis to find the trends that are similar for both male and female. Also the age of the participants have been taken into consideration, due to that the topic investigated are "modern" and there can be differences in opinion between the age groups. An example to this is that elder people might "fear" the new-coming technology and younger people might have different interests from the elder in what a mobile tourist guide should contain. The questionnaire is divided into 13 different questions and 6 sections. The 3 first questions make Section 1 and are demographic questions, which concern gender, age and occupation. However, the gender and age are the most important questions in this section. People's occupation can merely reflect their education and social status, which can be mirrored in how they answer the questions. The next section, Section 2, concerns reflecting people's interest in general in the system. How many would consider using the system if it became available and also what they would like the system to contain. Section 3 is more aimed towards group awareness and how many travel in groups and what type of group they travel in. The fourth section, Section 4, concerns the usage of maps and guidebooks, and also the advantages and disadvantages of traditional maps and guidebooks over the new technology that includes the electronic versions. 87

Section 5 is questioning if people would trust a mobile tourist guide and the reason for their answer if it were negative. This is to be able to fetch any opinions about security and protection of personal space and also if the software and hardware can be trustworthy when it comes to technical breakdowns and similar issues. The last section, Section 6, is reserved for comments from the participants in the survey. This can be very useful to show any questions and/or doubts the participant can have about the system. An example can be: "How will the system work indoor?"

Section 1 Gender and Age
This section represents how many males and females have participated in the survey and how well the different groups of age are represented.
Age division between MALE and FEMALE participants
100 % 90 % 80 % 70 % 60 % 50 % 40 % 30 % 20 % 10 % 0%

13 % 26 % 11,32 % 28 % 21 % 0% MALE %

7 14 6 15 11 0 Number of responses

17,02 % 23,40 % 8,51 % 21,27 % 23,40 % 6,40 % FEMALE %

8 11 4 10 11 3 Number of responses 55+ 46-55 36-45 26-35 18-25 >18

Age %

This diagram shows the differences between the groups of age and how some are better represented than others. The percentages in the male column are calculated out of the total number of males participating, which is 53 and represents 53% of the participants in the survey. The 53 % are in the diagram represented as the 100% male group, where the age groups are represented in different colours according to how much percentage they represent. Out of the diagram the age group 26-35 is best represented with 28 % of the males. However, the age group, less than 18 (>18), are not present at all in the male group.

88

The same principle is used for the female column. The females are 47 out of 100 participants and represents 47 % of the total number of participants. The 47 % are then represented as 100 % and the age groups are represented as a percentage out of the total number of females participating. All the groups of age are present in the female group, also the group under 18 years old. The diagram shows that for females the largest represented age group is divided between the group 18-25 and the group 46 ­ 55. Both groups have 23,4% of the participants. When it comes to the overall impression of the diagram the age group 36 ­45 are not well represented in either male or female group. The reason for this can be that this group often have small children and do not prefer to go on "city holidays".

89

Occupation
The different occupations represented in the questionnaires are very diverse. For males some of the stereotypical male professions like joiner and lorry driver are presented. 4 out of 53 males decided not to answer the question, which is 7,6 % of the total number.
Age >18 18-25 Occupation Number of responses NONE NONE Student 7 Software Engineer 1 Sales/ PR 2 Driver 1 Tiler 1 Chef 1 IT Professional 1 Environment Health Safety Responsible 1 Joiner 2 Unit Assistant 1 State Manager 1 Student 2 Youth/Social Worker 2 Architect 1 WorkShop Manager 1 IT SalesConsultant 1 Executive Director 1 Lawyer 1 Manager 1 E-commerce Consultant 1 Vacationer 1 No Answer 1 VP,Marketing 1 Civil Servant 1 Engineer 1 Professor 1 Crane Driver 1 Teacher 1 Business 1 Fitter 1 A/C Director 1 Technician 1 Gas Fitter 1 Sculptor 1 No Answer 1 Retired 3 Teacher 1 Professor 1 Administration Officer Education 1 No Answer 1

26-35

36-45

46-55

55+

90

For females the stereotypic female professions like nurse and care worker are occurring together with a few housewives. However, what seems to be the trend is that only the women in the age group 55+ that are housewives. This can give us a small insight in the homogenous development there are when it comes to equality between the sexes on the job market. Five females decided not to answer the question concerning their occupation and this counts for 10,6% of the total amount of participants.

Age >18 18-25 26-35

36-45

46-55

55+

Occupation Student Student Worker Traveller/Lawyer Teacher Student Social Worker Realestate No Answer Teacher Physical Theraphist No Answer Care Worker Bank Manager Teacher Civil Servant Assistant director administration Operations Manager Nurses Aid Advocacy Project Coordinator Administrator No Answer Retired Teacher Housewife No Answer

Number of responses 3 10 1 1 5 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1 2 1 3 1

The females have some larger concentrations around the occupations, students and teachers. Girls/Women in the age group 18-25 and also the younger girls under 18, are mostly students. A trend that has developed over the later years in western countries, is that girls are more interested in taking higher education than men.

91

Section 2 Interest of Mobile Tourist Guide
Section 2 are more considered about the general information about how people would welcome the mobile tourist guide on the market if it became available and also what could be interesting and preferable by the public to implement in the software.

Consider usage of Mobile Tourist Guide
The participants are also in this section divided into two categories decided by their gender.
Consider use of Mobile Tourist Guide MALE
100 % 80 % 60 % 40 % 20 % 0% No Answer % NO% YES % MALE >18 0 0 0 18-25 26-35 36-45 46-55 0 1,9 18,7 1,9 5,7 20,7 0 0 11,3 1,9 1,9 22,6 55+ 0 0 13,2 No Answer % NO% YES %

Out of 53 males, 46 would consider to use the mobile tourist guide. That represents 86,8 % of the males represented in the survey. 9,4 % were negative to the use of the guide and 3,8 % decided not to answer the question. The diagram represents the overall opinion and it clearly states that most of the men would like to use the system.

92

Consider use of Mobile Tourist Guide FEMALE
100 % 80 % % 60 % 40 % 20 % 0% >18 No Answer % NO% YES % 0 1825 0 2635 1,9 3645 0 4655+ 55 0 0 No Answer % NO% YES %

0 8,5 10,6 0 1,9 8,5 6,3 14,9 10,6 8,5 21,3 8,5 Age

Out of 47 females, 33 would consider to use a mobile tourist guide. This number represents 70,2 % of the females participating in the survey. 14 out of 47 women are negative to the usage of such a system. This counts for 29,8 % of the females participating in the survey and this is considerable higher than the male percentage. All the females in the survey answered this question.

93

Consider use of Mobile Tourist Guide MALE + FEMALE
100 % 80 % % 60 % 40 % 20 % 0% >18 No Answer % NO% YES % 0 0 3 1825 0 5 17 2635 2 7 16 Age The joint diagram covering both male and female, shows that the majority is positive to the use of the mobile tourist guide. However, the diagram shows that it is actually the age group 26 ­35 that are most sceptical to the new technology. The percentage here is higher both in the negative direction and this group has also the highest percentage in not answering the question. This result is surprising, since you would think that the people in this age would be open to new technology and have insight and knowledge about some of the technology available on the market. 3645 0 0 9 4655+ 55 1 2 22 0 4 11 No Answer % NO% YES %

94

Preferred information on a Mobile Tourist Guide
To map what people would like a mobile tourist guide to contain is something that can be found interesting when you want to investigate where to focus your research and development. 15 categories were discovered and charts were created concerning which category could be weighted as the most popular. Two charts were created, one for male and one for the female part of the participants. This makes it easier to find any difference in preference between the male and the female participants. Some of the categories are there almost no interest for at all, but they were quite interesting and worth to mention. Other categories have a heavy interest rate and are very important to tourists if you consider what the survey can show. The weighting of these results has been done on the basis of how frequent the specific category was mentioned by the participants. After mapping the different categories, the charts mentioned above were created and used as a ranking system where the first is the most popular category and the last category considered the least popular. 11 out of 53 of the male participants decided not to answer the question. This represents 20,6% of the total number of male participants. For the females, 18 out of 47 chose to not answer the question. This represents a slightly higher percentage than then male part, counting 38,3 %. According to the table created to get overview over the different categories and the frequency the different categories occurred, these charts were developed:

95

CHART MALE 1 2 3 4 5 6 7 8 9 10 11 12 13 1 Attractions and interesting sights Maps Pubs/Clubs/Bars/Restaurants Information about public transport (travel info, stops, times) Events/Event locations and times Accommodation (including price details) Price aware places to visit Shopping History of buildings, places and people Shared between: Culture (music, arts, architecture, museums) General info about the city Shared between: Opening hours Road info/accidents/incidents What's near Child friendly activities and child adapted software (FREQUENCY = 0) CHART FEMALE Shared between: Maps Attractions and interesting sights Pubs/Clubs/Bars/Restaurants 2 3 4 Shared between: Information about public transport (travel info, stops, times) Events/Event locations and times Accommodation (including price details) Shared between: Shopping Opening hours History of buildings, places and people Price aware places to visit Culture (music, arts, architecture, museums) 5 6 7 General info about the city Shared between: Road info/accidents/incidents Child friendly activities and child adapted software What's near

96

After investigating the charts, it is discovered that the male part of the survey is more distinct and aware of what they would like a mobile tourist guide to contain. The female part has their opinions more equally divided between the categories. A part from this distinct difference the ranking of the categories seem quite similar. The categories 1 to 3 for the males are one joint category for the females. These categories share the 1st place in the female chart as well as they are 1st to 3rd place in the male chart. The 4th and 5th place in the male chart are sharing 2nd place in the female chart and the 3rd and 4th place for females represents 6th place to 9th place for males. This is where the charts start to move in different directions. The further down on the charts we get, we can see that the categories "Culture" and "General information about the city" on the male chart are situated on a shared 10th place. On the female chart these two categories are in 4th and 5th place. The category concerning children and child adapted software is not represented at all in the male chart and end therefore on 13th place with a frequency of zero. For women children may seem as a greater concern and share a 6th place together with the category "Road information, accidents and incidents". This result is surprisingly higher ranked in the female chart than in the male chart. You would think that this category would be more interesting for the male participants of the survey, if you are to follow the old fashion beliefs concerning men and their interest for cars and driving. However, for males this category scores quite low and shares 11th place with the category," Opening hours". This particular category is more interesting for women and is placed on a 4th place together with "Shopping" amongst others. The category "What's near" is a category that scores very low in both charts and is on the last place for females and has the lowest frequency after the category concerning children in the male chart. If the age groups are further investigated, for the male participants the youngest age group, 18­25 years old, there are 5 categories that are no0t mentioned at all (Road info/accidents/incidents, General info about the city, Culture, What's near and Child friendly activities and child adapted software). However, the highest concentration of frequencies occurs around the categories: Maps, Information about public transport, Events/Event locations and Attractions and interesting sights. This result is surprising, since you might 97

think that most young people in that group of age would be more interested in bars and clubbing and also where to find inexpensive places to go. Maps and information about public transport is what is ranked highest and we can see the same trend in the female group. However, for females the ranking is more equal between the most popular categories and bars, pubs, clubs and restaurants is included in 1st place for the female participants. The next age group that shows some interesting results are the age group, males between 2635 year old. In this group the trend anticipated in the younger group is more distinct and this group are more interested in eating, drinking and going out. This category has the highest frequency, but is closely followed by the category "Attractions and interesting sights". The categories that have the second highest frequency are "Maps" and "Events/Event locations and times". Three categories are not represented at all in this group of age: "Opening hours", "What's near" and "Child friendly activities and child adapted software". The last category mentioned is not represented at all within the male part of the participants, as mentioned above, and will now not be mentioned where it is irrelevant. For the age group, 36-45, the frequency is more equal throughout the categories, however the category "Maps" is the most popular category, followed by "Shopping" and "Pubs, Clubs, Bars and Restaurants". The reason why shopping is a popular activity for this group, can be that when reaching this age, they have managed to create a career and earn some money after studying. This will result in more purchasing power than the younger groups of males. However, this group is the one that is weakest represented in the survey and the low number of participants in this age group can mark the results. In the age group, 46-55, the frequencies are even more blurred and equal between the different categories. It seems like the males that have reached this age are more concerned about where to stay, in other words, accommodation. However, the most likely reason for the blurred results can be that 6 of the males in this group decided not to answer the question and this counts for almost 43% of the males in this age group. Why this has occurred seems to be unclear. The 7 categories that are not represented at all are, "Shopping", "Opening times", "Culture", "What's near", "Road info/accidents/incidents", "Child friendly activities and child adapted software" and last "General information about the city".

98

The last age group, 55 +, is the category "Attractions and interesting sights" the most popular and highest ranked category. This is closely followed by "Maps" and "Culture". This group is a fairly small group and is represented by only 7 male participants. The results are therefore spread between the categories and the 7 categories not mentioned are, "Events/Event locations and times", "Shopping", "Opening times", "Accommodation", "What's near", "Road info/accidents/incidents" and "Child friendly activities and child adapted software". It is a surprise that accommodation is not mentioned at all, because you would think that where to stay would concern elder people more than the younger generations. When it comes to investigating the female preferences on what a mobile tourist guide should contain, we can see that there are 3 females represented that are under the age of 18. The results for this group are equally spread over 4 categories, because the number of participants in this group are so low. The categories mentioned are "Attractions and interesting sights", "Shopping", "Opening hours", and "Pubs, Clubs, Bars and Restaurants". The results concerning opening times and shopping were expected. The reason for the expected result is according to the stereotype most people have when it comes to teenage girls and their passion for shopping. In the next group, females in the age 18-25, the results are similar to the male results in the same age group, as mentioned earlier in the analysis. The low interest in the category "Shopping" was unexpected, but can also be seen as logical. We can draw this conclusion on the basis of this age group's economy and the majority's occupation at this stage in life. Most of the females are students when they are in the age 18 ­ 25 and the purchase power is therefore lower than it is for females that are working and earning money. 5 categories have not been showed any interest, "Accommodation", "Road info/accidents/incidents", "General info about the city", "What's near" and the last category concerning children, "Child friendly activities and child adapted software". The age group 26-35, the most popular category is "Maps" with "Pubs, Clubs, Bars and Restaurants", "Price- aware places to visit" and "General info about the city" as close followers on second place. Four females out of 18 did not answer this question, and this can be the reason for the vague trends.

99

The females that represent the age group, 36 ­ 45, are a very small group with only 4 participants. One of these participants decided not to answer the question and that leaves only three women to stick out the trends for this specific group. The results are therefore evenly spread with no distinct categories. With such a small group to work with 8 categories are not mentioned, but where there is frequency it seems to be a wide spread area of interest. The categories mentioned are, "Maps", "Events/ Event locations and times"," History of buildings", "Pubs, Clubs, Bars and Restaurants", "Accommodation", "Price- aware places to visit" and last "Culture". In the age group, 46- 55, the top category is "Attractions and interesting sights", closely followed by "Pubs, Clubs, Bars and Restaurants". Only four categories are not mentioned, which are "Maps", "Opening times", "Price-aware places to visit" and "What's near". You can spot a similar trend in the age group 46- 55 for the male participants. For the group in the age ranging from 55+, the frequencies are evenly divided between the categories. The category that has the highest ranking is "Accommodation", which is a surprise since in the same age group for men this category is not mentioned at all. This can be a coincidence since the numbers of participants are quite low for both male and female or it can be that women are more concerned about where and how nicely they live while travelling. Seven categories are not represented, "Events/ Event locations and times", "Attractions and interesting sights", "Shopping", "Price- aware places to visit", "Culture", "General info about the city" and last category is "Child friendly activities and child adapted software". There were a few other interesting suggestions mentioned that were not mentioned by many, but could still be interesting to take in to consideration. A participant of the female part of the survey suggested that it could be useful to have the nearest police station, hospital and doctor displayed on the mobile tourist guide as an option, if any unexpected incident happened and emergency care is needed. This could be a useful addition to the mobile tourist guide and can also make users feel more secure. Countryside walking and cycle tracks are also interesting suggestions which can help the mobile tourist guide to broaden and catch more users that are interested in more than just experiencing "city life".

100

Section 3 Group awareness
This section of the questionnaire considers what we maybe can call the most "uninvestigated" part of the research on mobile tourist guides. Research that has already been done on this issue have focused more on the individual user, while in this case it is of interest to map how many participants travel in groups and what type of group they travel in. The genders will be analysed separate and joint, so that we can spot any differences or similarities.

When you travel, do you travel in a group (more than one person)?
Frequency of grouptravels MALE & FEMALE
100 %

80 %

60 %

%
40 %

Always Often Sometimes Never

20 %

0%

FE MA 18- 26- 36- 4618- 26- 36- 46>18 55+ MA >18 55+ LE 25 35 45 55 25 35 45 55 LE 0 0 0 0 3 4 4 0 3 7 4 1 0 3 3 0 3 4 7 0 2 1 4 0 2 0 1 0 2 5 4 0 2 0 8 0 0 0 3 1 0 2 9 0 1 3 3 1

Age

Always Often Sometimes Never

This diagram illustrates the division between how often people travel in groups and also the connections between the male and the female groups. 100 % of the participants answered the question and if we consider the male part of the participants first, we can see from the diagram that most of the males sometimes travel in a group. Sometimes means that they can travel alone in some cases, like business travels or similar, while in other situations they travel with companionship. 22 out of 53 males sometimes travel in a group and this represents 41,5% of the total amount of males asked. 19 males out of 53 often travel in a group, which

101

means that they most of the time travel with companionship and within a group and rarely leave on travels without bringing anyone with them. The 19 males that often travel in a group represents 35,9 % of the total number of males and is the second largest option chosen after "Sometimes". The third largest option chosen are the option "Always". 11 out of 53 males always travel within a group and in companionship and never leave to go on holiday or travels without bringing someone. This represents 20,8 % of the total number of men represented in the survey. Only one person answered that they never travel with companionship. This person represents 1,9 % of the males participating in the survey. The diagram illustrates that the columns are quite similar between the age groups, however none of the males in the age group, 36-45, always travel in a group. This can be interpreted in the direction that this group is active in work and most of the times leave on trips without brining any companionship. The part of the diagram showing the females participating in the survey has a more diverse diagram. The share of females that always travel within a group are much higher for the female part of the survey than for the male part. This is quite interesting and can illustrate that women feel more comfortable when travelling in a group and also that children are very often involved in women's travelling. However, the percentages of women that are always travelling within a group are not the group that have the highest percentage. Women that always travel with companion counts 14,9 %, while the share where females sometimes travel in a group counts 59,6 % of all the women represented in the survey. We can here se similarities between the male and the female groups and the people that sometimes travel in a group is distinctively the largest option chosen. The second largest group represented, is the females that often travel n a group. This group represents 21,3 % of the participating females in the survey. Also in the female section, two people never travel together with anyone at all. This counts 4,3 % of the total number of women in the survey, but can be questioned if the person answering the question has misinterpreted the question. Overall the male and female groups are quite similar. The most distinct difference must be that the males seem to travel more often in a group than the females. The 55 + group shows that males are more dependent on their partner as they get older than females are. The diagram shows that the share of men that always travel in a group are larger or men than for women.

102

If you travel in a group, which type of group do you travel with?
Which type of group do people travel in?
100 % No Answer Other 80 % Partner Group of Friends Bustours 60 % % 40 %

20 % Age 0%
No Answer Other Partner Group of Friends Bustours MAL E FEM >18 18-25 26-35 36-45 46-55 55+ Sum: ALE 0 1 0 2 0 0 2 1 8 0 0 2 1 6 1 1 1 0 0 2 0 3 0 7 1 2 0 1 4 1 3 9 3 27 5

>18 18-25 26-35 36-45 46-55 55+ Sum: 0 0 0 0 0 0 0 1 10 0 1 3 3 8 0 0 1 1 3 1 1 2 7 1 3 0 0 3 3 1 2 6 15 25 5

% 3,80 % 11,30 % 28,30 % 47,20 % 9,40 %

% 6,40 % 19,20 % 6,40 % 57,50 % 10,60 %

The table and diagram are an overview over how the different categories are ranked. Out of this we can see that most people travel together with friends. However, what seemed to be an issue was that the participants ticked more than one box. The most frequently ticked boxes were Group of Friends and Partner. For the male part of the survey 30,2 % of the participants ticked more than one box. The table above shows the first box ticked and does not illustrate that there could be more than one box ticked. That can be the reason of the large amount of people travelling with friends and the low amount of people travelling with a partner. In the group 18-25 two participants ticked of that they travel with friends and with a partner. One ticked of travelling with friends and the alternative "Other". However, when "Other" was the only option ticked, the specifications were that they travelled together with family, pipe bands and communities (church community). 103

The group 26-35 had five participants that ticked of that they travelled with friends and with a partner, while two ticked off travelling with partner and chose the option "Other". The specifications on this option were that people travelled with children, pipe bands and family. One person ticked off that he travelled on bus tours with his partner. The double ticking of boxes can therefore explain why the table does not show many people travelling with partners in this group of age. When you are between 26 and 35 it would be logical to assume that a partner has become a part of the majority of people. The age group 36 ­ 45 is as mentioned before not very well represented in this survey, but two ticked off that they travelled together with a partner and friends. Where the option "Other" is chosen, it is specified that the majority is travelling with their co-workers and also together with pipe bands and family. The next age group, 46-55, has no double ticking and where the option "Other" is ticked; the specifications are travelling with pipe bands and family. In this group the bus tours are popular and has the highest rating of all the groups. For the participants over 55 years old, travel with partner and with friends. Many of the females participating in the survey did also tick off more than one box. What seemed to be the situation is that as much as 24 of the 47 participants ticked more than one box. This counts for 51,1 % of all the female participants and the diagram can therefore be somewhat misguiding when it comes to this issue. In the first group of females aged below 18 years old, one out of three girls ticked two boxes. She travels with friends and with her family, while when the option "Other" is chosen; the specification is left to travelling with parents and family. For the next group of females aged between 18 and 25, we can see a higher trend of travelling with friends and only one ticked off two boxes, where it was specified that she travel with both family and partner. Family is an option specified under "Other", but not many in this group specified anything here. The majority of the younger girls travel as singles together with friends. 104

Females between 26 and 35 seems also to prefer travelling with friends, however it must be mentioned that 30 % of the participants in this group travel both with friends and with their partner. 18% travel with friends and family, while two persons ticked off that they travelled with bus tours and friends. When the option "Other " is chosen, the specifications are that the majority travel with colleagues and with their family. The group aged between 36 and 45 are as mentioned with the male group, not very well represented. One person ticked off that they travel on bus tours and with partner. While the specification under "Other" are limited to travelling with family. In this group no participants ticked that they travelled with friends. This can be a misinterpretation based on the reason that there are so few participants, or that the majority of people in his group have family and children at this stage. Participants between the age 46 and 55 are quite well represented and give an interesting and valid result on the question. 36,4 % of the participants ticked two boxes when it comes to travelling with partner and friends. We can interpret this answer in the direction that most of the participants' children will be growing up and start going on holiday together with friends or with their own partners. Their parents, which are now represented by this age group can then start travel with their own friends and also only with their partner again. 18,2 % ticked off that they travel with friends and family. This can maybe represent the younger part of this group, that still have children that have not completely left the nest yet. When the option "Other" is ticked, the specifications are that the majority travel together with colleagues and also with their family. The group over 55 years old travel most of the time with friends, but two of the participant decided not to answer the question and this will affect the result. The reason is that this group does not have too many overall participants. One female ticked off both that she travel on bus tours and with a group of friends. If you look at the overall picture of both the male and the female parts of the survey, we can see that the amount of females not answering this particular question is higher than the male part. More females did not answer the question while also the female part of the survey is smaller than the male part. In the diagram this will be shown as the blue part of the columns and the no answer part will then be displayed as a larger section in the female diagram than 105

the male diagram. The female part of the survey have also a higher percentage where the option "Other" is chosen. Females have been more specific than the males and specified more thoroughly that they go on holiday and trips together with their family and children. Another result that comes as a surprise is the amount of females that travel without a partner. 25,5 % of the female participants travel with a partner while the percentage of males that travels with a partner is 43,4 %. Both for females and males the double-ticked options are included. The reason for this is unclear, but it can be that the population of the survey is not big enough and this will change if you increase the size of the survey, or that females prefer to travel with friends more than they prefer to travel with a partner. If the overall result is analysed, you can see that most of the participants prefer to travel with a group of friends. A part of the percentage that travels within a group of friends do also travel with a partner or with one of the other options mentioned. However, what can be a solution to the high percentage of people travelling with friends, is that the circle of friends you have around you is often more stable and concise, while especially early in life, the partner can change frequently.

106

Section 4 Usage of the traditional Maps and Guidebooks
This section analyses three questions from the questionnaire that concerns traditional maps and guidebooks and how they are used. Are they used separate or together? What are the disadvantages and advantages with the traditional maps and guidebooks compared to the electronic versions? And last but least: What option would people think is better?

When you travel, do you use maps or guidebooks?
In this question the genders are not analysed separate, the reason for this is that the results are very similar and there is not any distinct difference between the sexes or the age groups.

7%

3%

8%

2%

YES, maps and guidebooks YES, maps YES, guidebooks NO No answer

80 %

The diagram shows that most of the participants in the survey use both maps and guidebooks when they travel. 8 % of the participants use no help from either maps or guidebooks, while 7 % only use maps. If guidebooks are also taken into consideration, only 3% use guidebooks as their only help when they travel. The reason for such a large difference between the separate usage of maps and guidebooks is because there are certain drawbacks with guidebooks, such as, they are bulky and heavy to carry and also the fact that proper directions cannot be determined using only guidebooks. While on the other hand maps are easy to carry and do not require a large amount of space. Maps will also provide exact direction details.

107

Advantages and Disadvantages with traditional maps and guidebooks
This question concerns the advantages and disadvantages of the traditional maps and guidebooks over how they think the electronic version would be. During the investigation of the answers given on the question, the same advantages and disadvantages started to reappear and for "Advantages" 8 categories were created and for "Disadvantages" 6 categories were created. The categories in "Advantages" are: * * * * * * * * Trustworthiness No dependence on batteries and technology. Cost The prize and cost of use Size and Details Size and details of books and maps Current and updated information Easy to read and use Damage Souvenir Keep maps and books as souvenirs Electronic version A summary of the advantages of the electronic versions. The categories for "Disadvantages" are: * * * Damage Hard to use and read Electronic version A summary of the disadvantages of the electronic versions. * * * Size and Details Inaccurate information Cost

The different categories are weighted after how often they occurred and the frequency will tell what advantages and disadvantages are the ones the majority think about when they consider the question.

108

The category "Damage" is present in both advantages and disadvantages. This category can be present in both sections on the basis that for "Advantages" it is positive, because if you lose a map or a guidebook it is not the end of the world. In "Disadvantages" this category is negative, because maps and books are easy to tear and get easily wet in bad weather. Many people also seem to think that maps are quite hard to fold and keep in good shape. The category "Size and Details" do also appear in both sections. In "Advantages" because the traditional maps are fairly detailed and there are guidebooks on the market that are pocket sized to be easy to carry around. 22 % of the participants in the survey did not answer the question, while 11% did not fill in the section "Advantages" and 9% did not fill in the section "Disadvantages". The question analyses the genders on a joint basis and not kept separate. This is because there are no distinct differences between the opinions of the genders and there is no trend showing that one category is more popular than others, between the groups of age.

Ranking

ADVANTAGES Frequency, f 1Trustworthiness 1Easy to read and use 2Size and Details 3Electronic version 4Cost 5Damage 6Souvenir 7Current and updated information

15 15 10 7 6 2 2 1

The figure above shows the ranking from 1st to 7th place over what qualities the participants in the survey set highest with the traditional maps and guide books. "Trustworthiness" and "Easy to read and use" share 1st place with an equal frequency. While on 2nd place, where the detailed description of tourist sights and the size and weight of maps are well appreciated. The electronic versions come on a close third place, and there were mentioned a few qualities with the mobile tourist guides that are positive compared to the traditional maps and books. Mobile Tourist Guide was described of the participants as light weight, handy, more information in one device, easier to find places when you can get live directions and also that it could be more detailed than the traditional maps and guidebooks. The fact that they always contain up to date information is also a very important feature.

109

Ranking

DISADVANTAGES Frequency, f 1Size and Details 2Current and updated information 3Electronic version 4Hard to read and use 5Damage 6Cost

28 18 8 7 5 2

The figure above displays the ranking of the disadvantages with traditional maps and guidebooks. On 1st place rules the size and the details, even though this also scores well in the advantages. However, the maps and guidebooks are described as bulky, heavy and the maps are most of the time too big and hard to read if you are on the move. On 2nd place is the category "Current and updated information". A female participant mentioned in the survey mentioned, "the guidebooks can be out dated already the day after publication". This is in majority the truth most of the time, if not exactly the moment it is release, it goes out of date quite quickly. The electronic version is also in the disadvantages given some comments. According to the participants in the survey, Mobile Tourist Guides can he too technological to use, they are dependent on batteries and electricity, does not always function properly and last the cost to purchase such a device and also the software has a much higher cost than the traditional paper maps and books. Some of the elder participants in the survey mentioned that this type of technology is reserved for the younger generations. The overall picture of how the advantages and disadvantages are rated, give the impression that the stabile and hard copy maps and books are something that is highly appreciated, but the drawback with this is that it is heavy and bulky, and also maps can be hard to read and understand if there is little knowledge about how to interpret maps.

110

Mobile Tourist Guide: A better service than the traditional?
This is question is the last in Section 4 and give an overview over the opinions given whether the new technology can provide a better service than the traditional books and maps. The male and female parts are analysed separate and joint to investigate if there are any differences in opinion between the genders. The age groups are not taken into consideration, due to that the results given for both male and female participants are quite distinct.

MALE Response ratio % of total male group FEMALE Response ratio % of total male group

YES 36 67,90 % 20 42,60 %

NO 8 15,10 % 15 31,90 %

MAYBE 8 15,10 % 6 12,80 %

NO ANSWER 1 1,90 % 6 12,80 %

Mobile Tourist Guide: A better service than traditional maps and books? MALE
15 % 2%

15 %

YES NO MAYBE NO ANSWER 68 %

The diagram above illustrates the male part of the survey. 68 % believe that the mobile tourist guide will be a good replacement for the traditional guidebooks and maps. 30 % are not too positive about the new coming technology. This is divided into 15% clear no and 15 % maybe, which means that 15 % of the participants asked might change their mind and try a mobile tourist guide if it became available on the market.

111

Mobile Tourist Guide: A better service than traditional maps and books? FEMALE

13 % 13 % 42 % YES NO MAYBE NO ANSWER 32 %

The female part of the survey is not very positive to the mobile tourist guide. The majority is positive, 42 %, but the negative section is a close follower and counts 32 %. There are still 13% that are uncertain and might change their mind if they could experience the electronic version and compare it up against the experience of using the traditional maps and guidebooks. However, there are 13 % who have decided not to answer the question at all and seem to be a recurrent trend throughout the survey.
Mobile Tourist Guide: A better service than traditional maps and books? MALE & FEMALE

14 %

7% YES NO MAYBE 56 % NO ANSWER

23 %

From the diagrams above it is clearly stated that the male participants are more positive to the mobile tourist guides providing a better service than the traditional guidebooks and maps. However, in the previous section, Section 2, where the interest around the mobile tourist guide was investigated, the male part of the survey had a much more positive attitude towards the new technology than the female part of the survey. This trend seems to be mirrored in the results of this question. When the joint diagram is investigated, the positive participants have a small victory. The negative section is quite significant, but there is also left 14 % that are uncertain and could change their mind.

112

Section 5 The Mobile Tourist Guide vs. Trustworthiness and Security
The last question in the survey concerns the trustworthiness of a mobile tourist guide. Here it is investigated if people would trust this kind of technology and in case the technology is not trusted, a valid reason is given. The trustworthiness of the mobile tourist guide can include the application running correctly and give the correct guidance at any time or also include the hardware and technological breakdowns and similar cases. To trust is also an issue that has to do with personal safety and that personal details stored in the device and such issues are protected. This question is divided in to a gender-divided investigation to spot any differences between the genders, but age will not be considered in this case. The reason for this is the conciseness of the results.

Would you trust a mobile tourist guide? MALE
4%

11 %

YES NO NA

85 %

The diagram above shows that a distinct part of the male participants in the survey will trust a mobile tourist guide. This can be connected with earlier questions where the majority of the men are utterly positive to new technology and is also less sceptical to try new devices and software. 11% of the males participating are sceptical to the mobile tourist guide and 4 % chose not to answer the question. The participants who answered no on the question answered no because they wanted to try out the device themselves before deciding if it is trustworthy or not. One participant mentioned that a mobile tourist guide is only as good as the information given by the administrator. So it needs not to be more recent than books. Some of the participants are concerned of the level of 113

difficulty and not have the opportunity to ask questions, while others were concerned if the hardware could be trusted.

Would you trust a mobile tourist guide? FEMALE

9% 23 % YES NO NA 68 %

The female group is also positive and trusting towards the mobile tourist guide. However, the scepticism is larger in the female section and the percentage of unanswered questions is larger. This can be mirrored throughout the survey and this question can be connected with the other questions where females are sceptical and negative to the mobile tourist guide and similar technology. The reasons for why the mobile tourist guide is not trusted are spread over an area that covers economy, technology and difficulty level. The older generation means that they are too old to handle this kind of technology, while the younger generation believe that technology always go wrong at some point and it will be boring not to interact and communicate with real persons. How the service is supposed to be supported economically is also an issue and what can be a reason for this, is the fear against large phone bills.

114

Would you trust a mobile tourist guide? MALE & FEMALE

6% 17 % YES NO NA

77 %

When the joint diagram is investigated it illustrates the large majority who will trust and support a mobile tourist guide. The explanation to this can be that technology certainly goes wrong sometimes, but it is improved every day and also the support structure around hardware and software today are very solid. Help can be given sometimes on a 24-hour basis, just by pressing a button or dialling a number.

Section 6 Comments from the participants
This section concerns the part of the survey where a possible future user of a mobile tourist guide have been given the opportunity to give comments on what they think of the system and the general idea around implementing a mobile tourist guide in the holiday and travelling environment. The comments are represented in two tables, one for the male part of the survey and one for the female part. The comments are diverse and interesting and mention the participant's personal opinions and overall impression of the system.

115

MALE: 1. 2. 3. 4. 5. People from USA are not as technological enlightened as the Europeans. The mobile tourist guide technology must therefore be adapted to different markets. Excellent! How does this work indoors? Well done! Good stuff! Do not often rely on guidebooks, because it is preferable to talk to locals instead. The reason is that a guidebook cannot really tell you if a pizza place is good or not. It might be ranked as a good pizza place, but can in reality be bad. This information is what you get from the people in the local area. 6. 7. 8. 9. Navigation system Must be updated and reliable Prefer cycling and hiking free of any electronics. This might be a good product for people who are not very fit in English. Must consider the costs versus the costs of the traditional maps. Will this be an upfront fee system or a user paid system? 10. Success! 11. Not an enthusiastic cell-user. 12. Software must be easy to update and cheap. 13. The guided tour is best!

116

FEMALE: 1. 2. 3. 4. 5. 6. 7. 8. 9. I am sure it can interest other people. Price of software Keep the tour guide! Sounds fascinating and would be interesting to try out. Do not think it will replace the maps or the guidebooks. If such technology would become available outside the US, usage would be considered, but probably not. Interesting to find out if the mobile system is an improvement on maps and similar. Not brought up in the technology age. Easily understandable design and affordable by all. No taxing! This is just the start! Looking forward to try it!

10. Would have liked to have this on a recent trip to Prague. 11. Depending on the country you are from, will it work on a mobile? Maps etc. are often free. Impressionable communication and more fun verbal. Technology is ok at work, but not on holiday. 12. Like the idea, but not necessarily on a mobile phone.

117

APPENDIX B CODE LISTING

118


COLLOCATION EXTRACTION

· A collocation is an expression consisting of two or more words that correspond to some conventional way of saying things (Manning and Sch¨tze 1999: p151) u · The difference between comprehensible and natural-sounding language usage · CAUTION: "collocation" is an ill-defined term!!!

1

APPLICATIONS

· Information retrieval (query expansion, query segmentation) · Language modelling in Speech processing (N-grams) · Parsing (symbolic, statistical) · Generation (symbolic, statistical) · Word sense disambiguation ("one sense per collocation" principle) · Lexicography (e.g. COBUILD) · Terminology · Text simplification · Machine translation (multi-word translation pairs)
2

EXTRACTION PARADIGMS

· Segment-based knowledge-driven/statistical extraction: extract multi-segments as part of segmentation process · Word-based, knowledge-driven extraction: extract word sequences of pre-defined type (e.g. nominal compounds) POS-based regular expressions, structural analysis · Word-based, statistical extraction: extract statistically idiosyncratic word sequences

3

STATISTICAL TESTS USED IN COLLOCATION EXTRACTION · Simple frequency: f (XY ) · Pointwise/specific mutual information: log P P (x,y) (x)P (y)
2 f (x,y) · Dice's coefficient: f (x)f (y)

· (Student's) t score · (Pearson's) chi-square (2) · Z score · Log likelihood · Selectional association . . .
4

BIGRAM RESULTS FROM THE WSJ
Rank 1 2 3 4 5 6 7 8 9 10 . . . Frequency of the in the to NUMB for the to the of NUMB on the NUMB to that the the company Mutual information Quadi Doum Wrongful Discharge Seh Jik Noo Yawk WESTDEUTSCHE LANDESBANK Naamloze Vennootschap Caisses Regionales Centenaire Blanzy Guillen Landrau Ea Matsekha 2 Posse Comitatus LORIMAR TELEPICTURES Petits Riens Wrongful Discharge Tupac Amaru Sary Shagan Outlaw Biker GEMINI SOGETI Centenaire Blanzy Smith-Corona Typewriters

t te of t in th to NU on t the com about N said for t to b a sha

5

WHY STATISTICS?

· Pick up on word combinations which occur with "significantly" high relative frequency when compared to the frequencies of the individual words (i.e. f (x, y) as compared to f (x) and f (y)) · BUT WHY SO MANY #$%! STATISTICAL TESTS? ­ complications in evaluation (hard to say which is the "best" test, conflicting results from different researchers) ­ different corpora have different distributional idiosyncracies ­ different tests have different statistical idiosyncracies · AND WHERE'S THE #$%! LINGUISTICS!!! ­ bear with me!
6

LINGUISTICS IN COLLOCATION EXTRACTION · Apply statistical measures to (head) bigrams in a given dependency relation (e.g. subject-verb) ­ filters out stop words, produces "collocations" of pre-defined type for direct use in parsing, etc · Look beyond contiguous bigrams, to bigrams occurring within a "collocational window" of fixed size (e.g. within 3-4 words of each other) · Utilise linguistic qualities of collocations: ­ limited internal modifiability (applicable as a post-filter)

­ limited substitutability (contrast with anti-collocations, e.g. (strong *powerful) coffee) ­ non-compositional semantics
7

SUBSTITUTABILITY
Lexicalisation Concept

...
8

SUBSTITUTABILITY

· Most immediate means of testing substitutability via synonyms · Synonyms accessible from thesauri, but word sense disambiguation is generally needed to isolate which synset(s) over which to apply substitution test · Possibilities of getting at synonyms via distributional analysis (based on dependency pairs)???

9

CONCEPTUAL IDENTIFIABILITY
Lexicalisation Concept

...
10

Maximizing Multiprocessor Performance with the SUIF Compiler
Mary W. Hally Jennifer M. Anderson Saman P. Amarasinghe Brian R. Murphy Shih-Wei Liao Edouard Bugnion Monica S. Lam
Computer Systems Laboratory yUSC Information Sciences Institute Stanford University Marina del Rey, CA 90292 Stanford, CA 94305

This paper presents an overview of the SUIF compiler, which automatically parallelizes and optimizes sequential programs for shared-memory multiprocessors. We describe new technology in this system for locating coarse-grain parallelism and for optimizing multiprocessor memory behavior essential to obtaining good multiprocessor performance. These techniques have a signi cant impact on the performance of half of the NAS and SPECfp95 benchmark suites. In particular, we achieve the highest SPECfp95 ratio to date of 63.9 on an eight-processor 440MHz Digital AlphaServer.

Abstract

1 Introduction
A ordable shared-memory multiprocessors can potentially deliver supercomputer-like performance to the general public. Today, these machines are mainly used in a multiprogramming mode, increasing system throughput by running several independent applications in parallel. The multiple processors can also be used together to accelerate the execution of single applications. Automatic parallelization is a promising technique to allow ordinary sequential programs to take advantage of multiprocessors 4, 6, 9, 11]. Multiprocessors present more di cult challenges to parallelizing compilers than vector machines which were their initial target. E ective use of a vector architecture involves parallelizing repeated arithmetic operations on large data streams (e.g., innermost loops in array-oriented programs). On a multiprocessor, however, parallelizing innermost loops typically does not provide su cient granularity of parallelism|not enough work is performed in parallel to overcome the overhead of synchronization and communication between processors. To utilize a multiprocessor e ectively, the compiler must exploit coarse-grain parallelism, locating large computations that can execute independently in parallel. Multiprocessor systems also have more complex memory hierarchies than typical vector machines. Modern multiprocessors contain multiple levels of caches in addition to the shared memory. Locating parallelism is but the rst step in producing e cient multiprocessor code it is critical to make e ective use of the memory hierarchy to achieve high performance. These additional challenges often prevented early parallelizing compilers from being e ective for multiprocessors. Consequently, parallel programming today predominantly requires that the programmer explicitly manage both the parallelism and the memory use of the application. Developing an e cient parallel program in this way requires a highly knowledgeable programmer. Moreover, explicit parallel programming is tedious and error prone, and the resulting programs are only optimized for a speci c machine.
This research was supported in part by the Air Force Material Command and DARPA contracts F30602-95-C-0098, DABT6395-C-0118 and DABT63-94-C-0054, NASA's HPCC program, an NSF Young Investigator Award, an NSF CISE postdoctoral fellowship, and fellowships from AT&T Bell Laboratories, DEC Western Research Laboratory, Intel Corporation and NSF. Jennifer Anderson is currently a researcher with Digital Equipment's Western Research Lab.

1

This paper presents an overview of the automatic parallelization techniques in the Stanford SUIF compiler. We describe two techniques essential to obtaining good multiprocessor performance for array-based numerical programs: locating coarse-grain parallelism and managing multiprocessor memory use. We present performance measurements for two complete benchmark suites, the NAS and the SPECfp95 benchmarks. Overall, the results for these scienti c programs are promising. The compiler yields speedups on more than three-fourths of the programs, and has obtained the highest SPECfp95 ratio reported to date, indicating that the compiler is also able to achieve e cient absolute performance.

2 Finding Coarse-Grain Parallelism
Multiprocessors work best when the individual processors have large units of independent computation. Finding such coarse-grain parallelism is challenging. First, it is necessary to nd available parallelism across procedure boundaries. Furthermore, the original computations may not be parallelizable as given but require some transformations to parallelize. For example, experience in hand parallelization suggests that it is often necessary to replace global arrays by private versions on di erent processors. Sometimes the computation must be restructured|for example, a sequential accumulation replaced by a parallel reduction operation. It takes a large suite of robust analysis techniques to successfully locate coarse-grain parallelism. To cope with the complexity involved in building such a system into SUIF, we rely on general and uniform frameworks. We have automated the analysis to privatize arrays and to recognize reductions to both scalar and array variables. All the analysis techniques in our compiler operate across procedure boundaries seamlessly. There are three major components in the analysis to detect coarse-grain parallelism:

Scalar analyses. An integrated pass analyzes scalar variables in the programs. It detects parallelism
among operations with scalar variables using techniques such as data dependence analysis, scalar privatization analysis, and reduction recognization. It also derives symbolic information on these scalar variables that is useful to the array analysis pass, including constant propagation, induction variable recognition and elimination, recognition of loop-invariant computations, and symbolic relation propagation 8, 10].

Array Analyses. An integrated array analysis uses a uni ed mathematical framework based on linear

algebra and integer linear programming 9]. The analysis applies the basic data dependence test to determine if accesses to an array can refer to the same location. To support array privatization, it also nds array dataow information that determines if array elements used in an iteration refer to the values produced in a previous iteration. It also recognizes commutative operations on sections of an array and transforms them into parallel reductions. The reduction analysis is powerful enough to recognize commutative updates of even indirectly accessed array locations, allowing parallelization of sparse computations. All these analyses are formulated in terms of integer programming problems on systems of linear inequalities representing the data accessed. These inequalities are derived from loop bounds and array access functions. Optimizations to speed up common cases are implemented to reduce the compilation time. yses are implemented using a uniform interprocedural framework. The framework uses a true interprocedural analysis 11], which is more e cient than the more common technique of inline substitution 4]. Inline substitution replaces each procedure call with a copy of the called procedure, then analyzes the expanded code in the usual intraprocedural manner. Inline substitution is not practical for large programs, as program size can increase to an unmanageable extent. Our technique analyzes only a single copy of each procedure, capturing its side e ects in a function. This function is then applied at each call site to produce precise results. When necessary, the algorithm selectively clones a procedure so that code can be optimized or parallelized under di erent calling contexts (such as when di erent constant values are passed to the same formal parameter), thus achieving the full advantages of inlining without expanding the code indiscriminately. 2

Interprocedural Analysis Framework. To manage the software engineering complexity, all of the anal-

ZFFT

TURB3D

Parallelized Loops

XYFFT DRCFT FFTZ1

CFFT DCFT

TRANS

DCRFT DCRFT FFTZ2

Our analyses can successfully parallelize loops spanning hundreds of lines of code and numerous procedures, as shown by the above code segment from the SPECfp95 benchmark turb3d. The boxes in the gure represent procedure bodies and the lines connecting them represent procedure calls. The main computation is a series of four loops to compute three-dimensional fast Fourier transforms (FFTs). Using interprocedural scalar and array analyses, the SUIF compiler determines that these loops are parallelizable. Each loop contains over 500 lines of code spanning eight or nine procedures with up to 42 procedure calls. Note that if this program had been fully inlined, the loops presented to the compiler for analysis would have each contained over 86,000 lines of code. Figure 1: Illustration showing scope of coarse-grain parallelism analysis.

3 Memory Optimizations
Numerical applications on high-performance microprocessors are often memory bound. One or more levels of caches are commonly used to bridge the gap between processor and memory speeds, but it is still not uncommon to nd a processor wasting half its time stalled on memory accesses because of frequent cache misses. This memory bottleneck is further exacerbated on multiprocessors, as they have increased need for memory tra c and more contention on the memory bus. To optimize for memory subsystem behavior, the compiler must address the following four issues that a ect the behavior of the caches: Communication. Processors on a multiprocessor system communicate data through accesses to the same memory location. Coherent caches typically keep the data consistent by causing accesses to data written by another processor to miss in the cache. Such misses are called true sharing misses. Limited Capacity. Numeric applications tend to have large working sets, which typically exceed the capacity of the cache. These applications often stream through large amounts of data before re-using any of the data, resulting in poor temporal locality and a large number of capacity misses. 3

Limited Associativity. Caches typically have a small set associativity, that is, each memory location can only map to one or just a few locations in the cache. Con ict misses can occur even when the application's working set is smaller than the cache if the data are mapped to the same cache locations. Large Line Size. Data in a cache are transferred in xed-size units called cache lines. Applications that do not use all the data in a cache line, e.g. when accessing data with a non-unit stride, incur more misses and are said to have poor spatial locality. On a multiprocessor, large cache lines can also lead to cache misses that occur when di erent processors use di erent parts of the same cache line. Such misses are called false sharing misses. The compiler tries rst to eliminate as many cache misses as possible, and then to minimize the impact of any that remain. We reduce the problem of eliminating cache misses due to the four factors above to two subproblems: (1) ensuring that processors re-use the same data as much as possible and (2) making the data accessed by each processor contiguous in the shared address space. The techniques to address each subproblem are discussed below. Finally, to tolerate the latency of remaining cache misses, the compiler uses compiler-inserted prefetching to move data into the cache before it is needed.

Improving Processor Re-use of Data. The compiler reorganizes the computation so that each processor

re-uses the same data as much as possible 2, 3, 12]. This reduces the working set on each processor thus minimizing capacity misses it also reduces communication between processors thus minimizing true sharing misses. To achieve this goal, the compiler uses the technique of a ne partitioning. The technique analyzes the reference patterns in the program to derive an a ne mapping (linear transformation plus an o set) of the computation and data onto the processors. The a ne mappings are chosen so as to maximize the re-use of data by the same processor while maintaining su cient parallelism to keep the processors busy. The compiler also uses loop blocking to reorder the computation executed on a single processor so that data is re-used in the cache.

Making Processor Data Contiguous. The compiler tries to arrange the data so that the accesses of

a processor are contiguous whenever possible. This improves spatial locality, reduces con ict misses and reduces false sharing. The SUIF compiler is able to manage data placement within a single array, as well as across multiple arrays. The data-to-processor mappings computed by the a ne partitioning analysis are used to determine the data being accessed by each processor. To make the data within a single array that is accessed by one processor contiguous, the compiler uses data permutation and data stripmining 1]. Data permutation interchanges the dimensions of the array|e.g. transposing a two-dimensional array. Data stripmining changes the dimensionality of an array so that all data accessed by the same processor is in the same plane of the array. To make the data across multiple arrays that is accessed by the same processor contiguous, we use a technique that involves the cooperation of the compiler and operating system called compiler-directed page coloring 5]. The compiler uses its knowledge of the access patterns to direct the operating system's page allocation policy to make each processor's data contiguous in the physical address space. The operating system uses these hints to determine the virtual-to-physical page mapping at page allocation time.

4 Experimental Results
We demonstrate the impact of SUIF's analyses and optimizations with a series of performance evaluations. The measurements were obtained on a Digital AlphaServer 8400 with eight 21164 processors, each with two levels of on-chip cache and a 4MB external cache. As it is harder to obtain speedups on machines with fast processors, the use of a state-of-the-art machine in our experiment makes our results more meaningful and applicable to future systems. 4

1

1 1 3 3

2

2

2

stripmine

1

permute
1 1 3

3

2

2

2

The diagram shows how data transformations are used to make the data accessed by each processor contiguous in the shared address space. The original arrays are two-dimensional the axes are numbered so that elements along the rst axis are contiguous. First the a ne partitioning analysis determines which data elements are accessed by the same processor (in the gure, the shaded elements are those accessed by the rst processor). Second, data stripmining turns the two-dimensional array into a three-dimensional array. Now all the shaded elements accessed by the same processor are in the same plane of the array. Finally, data permutation is applied to rotate the array so that data accessed by each processor become contiguous, as shown in the diagram. Figure 2: Illustration of Memory Optimizations We use two complete standard benchmark suites to evaluate our compiler. We present results on the 10 programs in the SPECfp95 benchmark suite, which is commonly used for benchmarking uniprocessors. The runs were performed using the full reference data sets. We also use the eight programs from the NAS parallel benchmarks designed to benchmark parallel systems. We used the o cial benchmark programs, with the exception of embar where we used a slightly modi ed version from Applied Parallel Research. In all cases we used the large sample data set size provided. Figure 3 shows the speedups of the SPECfp95 and the NAS benchmarks, measured on up to eight processors on a 300MHz AlphaServer. The speedups were calculated over the best sequential execution time. Note that mgrid and applu appear in both benchmark suites (the program source and data set sizes di er slightly in the two suites). To measure the e ects of the di erent compiler techniques, we break down the performance obtained on eight processors into three components, as shown in Figure 4. Baseline shows the speedup obtained with parallelization based on intraprocedural data dependence analysis and only scalar privatization and reduction transformations. Coarse grain includes the baseline techniques as well as techniques for locating coarse-grain parallel loops: array privatization and reduction transformations, and 5

Speedup

16

|

15

swim
| | | | |

14

13

12

11

10

tomcatv

| | | | | | | | | |
| 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8

9

8

Speedup

8

embar

| |

7

7

6

mgrid applu turb3d hydro2d

6

|

5

5

su2cor
4

appbt applu cgm appsp mgrid

| | |

4

3

3

2

2

|

1

wave5 fpppp apsi

1

buk fftpde
| 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8

|

0| 0

0| 0

full interprocedural analysis of both scalar and array variables. Memory includes the coarse-grain techniques as well as all the multiprocessor memory optimizations described in Section 3. The gure shows that of the 18 programs, three-fourths show good parallel speedup and are thus able to take advantage of additional processors. SUIF's coarse-grain techniques and memory optimizations have a signi cant impact on the performance of half of all the programs. The swim and tomcatv programs show superlinear speedups because the compiler eliminates almost all cache misses, and their 14MB working sets t into the multiprocessor's aggregate cache. For most of the programs that do not speed up, the compiler nds a signi cant portion of their computation to be parallelizable, but the granularity is too ne to yield good multiprocessor performance on machines with fast processors. Only two applications, fpppp and buk, have no statically analyzable loop-level parallelism and are thus not amenable to our techniques. To show that our compiler delivers high absolute performance, we report the times and SPEC ratios obtained on an eight-processor 440MHz Digital AlphaServer 8400 in Table 1. The SPEC ratios compare the machine performance to that of a reference machine. The total SPEC ratio is the geometric mean of the ratios obtained for individual programs. The geometric mean of the performance improves over the uniprocessor execution by 3.0 with four processors and by 4.3 with eight processors. The eight-processor ratio of 63.9 we obtain represents a 50% improvement over the highest number reported to date 7]. 6

|

|

Processors

Processors

(a)

(b)

Figure 3: Speedups on the (a) SPECfp95 and (b) NAS Parallel Benchmarks

16 14 12 Memory Optimization Coarse-Grain Parallelism Baseline

Speedup

10 8 6 4 2 0

buk

tomcatv

su2cor

embar

applu

applu

fftpde

mgrid

turb3d

wave5

appsp

hydro2d

fpppp

Figure 4: Impact of SUIF optimizations, shown as speedup on eight processors.

Benchmark tomcatv swim su2cor hydro2d mgrid applu turb3d apsi fpppp wave5 SPEC ratio

Execution Time (sec) 1P 4P 8P 219.1 30.3 18.5 297.9 33.5 17.2 155.0 44.9 31.0 249.4 61.1 40.7 185.3 42.0 27.0 296.1 85.5 39.5 267.7 73.6 43.5 137.5 141.2 143.2 331.6 331.6 331.6 151.8 141.9 147.4

15.0 44.4 63.9

SPEC ratio 1P 4P 8P 16.9 122.1 200.0 28.9 256.7 500.0 9.0 31.2 45.2 9.6 39.3 59.0 13.5 59.5 92.6 7.4 25.7 55.7 15.3 55.7 94.3 15.3 14.9 14.7 29.0 29.0 29.0 19.8 21.1 20.4

Table 1: Absolute performance for the SPECfp95 benchmarks measured on a 440MHz Digital AlphaServer. 7

appbt

mgrid

swim

cgm

apsi


COURSE ADMINISTRATION ACCESS TO STAFF In general, an open door policy operates in the Department: you are welcome to call on staff in their rooms if they are available to discuss your work. However, the easiest way to contact staff is by email: if possible, please give a minimum of 24 hours notice for a meeting. APPEALING AGAINST THE DECISIONS OF BOARDS OF EXAMINERS The Faculty of Science operates a system whereby degree examination results are approved by Boards of Examiners. The Board of Examiners acts in accordance with the degree regulations for the course currently in force when considering the marks presented for each candidate. It recommends to the Board of Study whether a candidate has met the criteria to pass an individual class, what the progress decision should be and, where appropriate, the award of a degree. See http://www.mis.strath.ac.uk/Secretariat/Publications/general/publications/index.html for the current regulations (.pdf file of Part 3 of the University Calendar). Postgraduate students may submit an appeal where the Board of Examiner's decision requires the student either to transfer to a different degree (e.g. Masters to Postgraduate Diploma) or to withdraw. Normally such appeals have to be submitted in writing to the Faculty Officer not later than the date specified by the Board of Study in the letter informing the student of the decision. Information on the procedures for submitting appeals to Faculties is available from the Faculty Officer (Dr Jim McGrath, e-mail: j.s.mcgrath@mis.strath.ac.uk) Students may appeal to the Faculty on any of the following grounds: · · · That there were procedural irregularities in the conduct of the examination or of the assessment; That there were medical, personal or other circumstances affecting the student's performance of which the examiners were not aware when their decision was taken; That there was inadequate assessment, prejudice or bias on the part of one or more of the examiners.

See Regulations 20.1.37 and 20.10.11 in the University Calendar, available at: http://www.mis.strath.ac.uk/Secretariat/Publications/general/publications/index.html Appeals against the decision of a Board of Examiners are normally dealt with by the Faculty in the first instance. A Faculty Appeals Committee will be set up by the Board of Study, taking care to avoid bias in membership with regard to the individual appeals under consideration. If a student is not satisfied with the outcome of an appeal to the Faculty, then he or she has the ultimate right of appeal to Senate. Such an appeal must be lodged in writing with the Academic Registrar no later than six weeks from the date they are notified of the outcome of the Faculty appeal. Appeals are dealt with by the Senate Appeals Committee in accord with the principles of natural justice. Where an appeal against transfer to another course/award is pending, either at Faculty or Senate level, a student will not normally be allowed to graduate.

1

Students who are contemplating appealing against the decisions of Boards of Examiners should consult their personal tutor before instigating an appeal. The counsellor can advise on the appeals process, the best way to formulate the appeal and the supporting evidence, which might help a student's case. Students may also wish to consult with the Student Advisory and Counselling Service and the Welfare Service within the Students' Association for advice before submitting an appeal. It is advisable for the letter of appeal to include the following information: · · · · · · · your name and address; student registration number; degree programme; the decision appealed against; grounds of your appeal (which should fall into one or more of the three categories listed above); the outcome you are seeking; and evidence supporting your appeal.

The Appeals Committee will consider your letter of appeal as soon as possible and the decision will be conveyed to you in writing immediately after the meeting. AWARDS AND PRIZES The John Smith and Son Award (£100 of books) is for the best dissertation on a publishing topic submitted by a student on either the MSc in Information Management or the MSc in Information and Library Studies. These awards are made on the recommendation of the Board of Examiners. Various other competitions operate throughout the academic year, usually sponsored by professional organisations. These usually require you to write a report or to submit a dissertation accompanied by a statement of support from the Department. Details of these will be announced from time to time and posted on the notice board. BOARD OF EXAMINERS There will be three Boards of Examiners to monitor progress and make recommendations regarding students to the Board of Study. The first Board is an interim one, held after the January examination diet, which will consider MSc dissertations, resits and resubmissions from the previous cohort of students. A Progress Committee will meet immediately after this Board to review the marks achieved by individual students for assignments from the first semester and the examinations; these marks will be confirmed at the next appropriate Board of Examiners. Students will obtain written feedback on their performance after the Progress Committee and will be invited to make an appointment for counselling should they so wish. The second Board of Examiners, at which marks for the whole of the taught part of the course will be considered, will be held at the end of May/beginning of June. Students will be notified in writing of the Board's decision shortly afterwards. A third Board of Examiners is held at the end of September/beginning of October and at this Board dissertations submitted for the award of Masters are considered. Marks for resit examinations and resubmissions of coursework are also considered by this Board.

2

The Board of Examiners approves all marks for the course and recommends the awards to be made. It consists of the Head of Department, the External Examiner(s), Course Director and all staff who examine elements of the course. The Board's decisions are passed to Registry and from there to the Board of Study for final ratification on behalf of Senate. Thereafter, they will appear on your Pegasus record. For the award of MSc, students must: 1. Have made a credible attempt (i.e., achieve at least 40%) at all assessed work in each class; and 2. Accumulate 180 credits, of which 60 are from the dissertation and 120 from the instructional component of the course. In order to continue or to transfer to Masters, students must: 1. Make a credible attempt (i.e., achieve at least 40%) at all assessed work in each class; and 2. Have an overall first attempt average for the instructional component of not less than 50%; and 3. Accumulate 120 credits from the instructional component of the course, of which a minimum of 100 credits must be gained at the first attempt. A student who has accumulated at least 100 credits at the first attempt (and who satisfies the first two conditions) will be allowed meanwhile to continue to the dissertation element of the Masters course, but will be required to discontinue his or her dissertation and transfer to the Certificate if he or she has failed to achieve 120 credits from the instructional component by the end of his or her second assessment attempt. For the award of Postgraduate Diploma: a student will be awarded the Postgraduate Diploma who: 1. Accumulates 120 credits but otherwise fails to meet the criteria listed above for continuation or transfer to Masters, or 2. Has met the criteria for continuation to Masters but elects not to continue, or 3. Has met the criteria for continuation or transfer but fails the dissertation component For the award of Postgraduate Certificate, students must: 1. Accumulate at least 60 credits from the instructional component of the course. For all classes (including the dissertation), the pass mark is 50%. A credible attempt at assessed work normally means achieving a mark of 40%. Students should note from the class outlines that each class has a number of credits associated with it. These credits are used to weight the marks obtained for each class when assessing each student's overall performance. You may be required to re-submit an assignment or re-sit an examination in order to complete the requirements either for the award of the Diploma or to proceed to Masters. It will be made clear to you which of these is applicable. The Board of Examiners may compensate one, and only one, class. Students may obtain a transcript of their final marks from the Faculty of Science Registry on payment of a small fee. Any student who feels that his or her performance during the session or during the examinations has been impaired by medical, personal or psychological problems should

3

provide documentary evidence to the Board of Examiners via the Course Director. It is in your interests to notify the Course Director or your personal tutor if you are having any problems, at any time, which could affect your performance during the session. This is particularly important on a course like this in which regular assignments are the principal method of assessment. We may be able to direct you to the appropriate support services of the University for help, and we may be able to take the circumstances into account when assessing your work - but we can only do so if we know about them. Any information that you provide will be treated as confidential and will not be made available to the Board of Examiners without your permission. The Board of Examiners will consider the series of marks attained by each student and will record one of six decisions: Proceed to Masters indicates that the student has achieved an appropriate standard in the assignments and examinations to be allowed, if he or she so wishes, to proceed to the MSc Dissertation. The student is under no obligation to proceed and may elect instead to accept the award of Postgraduate Diploma. Award of Diploma indicates that the student has achieved an appropriate standard in the assignments and examinations to be awarded the Postgraduate Diploma but not of a sufficient standard to be allowed to proceed to the MSc Dissertation. Award of Certificate indicates that the student has achieved an appropriate standard in the assignments and examinations in 60 credits to be awarded the Postgraduate Certificate but has insufficient credits to be awarded a Postgraduate Diploma. Resit Selected Examinations and/or Resubmit Coursework indicates that the student has achieved a series of marks in the examinations and project work, which includes some, which are not of an appropriate standard for the award of Postgraduate Diploma. However, in the light of his or her overall performance, the student is to be given one further attempt at the relevant examination(s) or coursework, and a decision on progress will then be considered by the next Board of Examiners. Students may not ask to resubmit coursework in an effort to gain a higher mark. Sit Examination as a First Attempt indicates that, in the light of documented evidence of medical and/or psychological problems immediately prior to, or during the first examination diet, the student is to be given the opportunity to sit a further examination diet, and that any mark obtained in the first diet is to be discounted. The Course Director or personal tutor must be made aware of these problems and, if appropriate, be in possession of documentation prior to the relevant examination diet. Withdraw indicates that the student has not achieved a standard in the assignments and examinations appropriate for an award or to be allowed to resit the examinations or resubmit assignments. If a student feels that he or she is unable to proceed to the dissertation over the summer, it is possible to go into voluntary suspension temporarily (see University Postgraduate Regulation 19.1.30). This has to be approved by the Department and the Board of Study and the request must be accompanied by relevant evidence. It is not automatic and has to be renewed at intervals. Further information is available from the Course Director.

4

Any student wishing to appeal against the decision of the Board of Examiners should follow the guidelines elsewhere in this handbook. Students may obtain a transcript of their final marks in June from the Faculty of Science Registry on payment of a small fee. CERTIFICATION FOR STUDENT ABSENCE Senate has agreed that the University should adopt a system of student self-certification for absences of up to and including seven days (see below for procedures). However, a Board of Examiners will not take account of special pleading for illness unless it is accompanied by the appropriate self or medical certification. Please note that retrospective medical certificates will not be accepted by the Board of Examiners. Medical certificates must be submitted to the Departmental Office within ten days of the illness. For absences of seven days or less: The self-certification convention applies where there is absence from classes or tutorials for seven or fewer consecutive University teaching days. The self-certification form (available from the Departmental Office and as downloadable form) should be returned to that office for noting in the student's file (see Appendix 1 for a sample form). For absences of more than seven days: Where sickness results in absence of more than 7 normal University days, the student is required to submit a medical certificate to the Departmental Office. For absences from an examination or failure to complete assessed course work: The self-certification convention does not apply and a student absent from a formal examination, class examination or who fails to submit an assessment/assignment on time because of illness must submit a medical certificate. CLASS CO-ORDINATORS Each class has its own co-ordinator (see class descriptors) to whom any problems regarding a particular class should be referred in the first instance. COMMUNICATIONS The Department uses a variety of communication channels (i.e. e-mail, web-site, noticeboard and conventional mail) to keep students up to date with timetable changes, key dates, special events, etc. It is our responsibility to distribute information to you but it also your responsibility to keep yourself informed via these channels on a regular basis. It is therefore essential that you notify any change of address to both the Departmental Office and Registry. You will be provided with a Departmental e-mail account, which will be used by the Department for all official communications. We do not recommend that you forward e-mail from this account to an external service (e.g. Hotmail) as we cannot guarantee either delivery or integrity of the message beyond the University systems. The notice boards are in the corridor outside the Departmental Office on the 10th Floor of the Livingstone Tower. Timetables and other notices of interest will be displayed here. The display shelves and other notice boards contain relevant professional information and information on conferences and meetings. Course information can be found on the Graduate School of Informatics web site: see http://www.gsi.strath.ac.uk/

5

An online conferencing system http://forums.gsi.strath.ac.uk/forums/

is

available

to

both

students

and

staff

at:

This conferencing system is intended to carry notices affecting teaching and to allow students and staff to discuss course content. It is not intended for social activities or gossip (for which there are other systems). Be sure to read the guidelines for its proper use. The Graduate School of Informatics Office can be contacted on ext 3700. To bypass the switchboard when calling from outside the University prefix this, or any other extension, with (0141)-548-. Each course has its own group e-mail, which you can use to contact all your colleagues in your year of study. Please note that we cannot provide e-mail addresses, telephone numbers or residential addresses for individual students. MSc Information and Library Studies MSc Information Management MSc Computer and Internet Technologies mailto:ils2007@cis.strath.ac.uk mailto:im2007@cis.strath.ac.uk mailto:cit2007@cis.strath.ac.uk

COURSE DIRECTORATES Each course has a Course Directorate, which is responsible for the management and development of the course. The current Course Directorates are: Information and Library Studies Paul F. Burton David McMenemy Information Management Steven Buchanan Computer and Internet Technologies George Weir ETHICS COMMITTEE Coursework and dissertations, which involve investigations on human subjects may have to be approved by the Departmental Ethics Committee. Your Supervisor will advise you on this. EXAMINATIONS There are two main examination diets each year and the schedule and location for these will be provided in the timetables section of this site once room bookings have been confirmed. EXTENSIONS FOR ASSIGNMENTS If you have a genuine reason for late submission of an assignment, you must use a Request for Extension form, which is obtainable from the Departmental Office or as a downloadable form (see Appendix 2 for a sample) . You must state the reason for late submission, provide copies of any relevant documentation, and return the completed form to the Office. If your request is approved a new submission date will be set. Request for Extension forms should normally be completed before the date on which the assignment is due. Please note that a request for an extension does not mean that you will not be penalised at a rate of 5% per week or part of a week.

6

GRADUATE SCHOOL OF INFORMATICS The Graduate School of Informatics staff are located in room 10.01 on the 10th floor of the Livingstone Tower and will be an important point of contact for handing in assignments and collecting handouts. The staff contacts are: Linda Hunter ­ Secretary, IM course (e-mail: mailto:linda.hunter@cis.strath.ac.uk) Zakia Majid ­ Secretary, ILS course (e-mail: mailto:zakia.majid@cis.strath.ac.uk) Julie Pringle ­ Secretary, CIT course (e-mail: mailto:julie.pringle@cis.strath.ac.uk) The official address is: Graduate School of Informatics Department of Computer and Information Sciences University of Strathclyde LT10.01 Livingstone Tower 26 Richmond Street Glasgow G1 1XH UK E-mail: (mailto:enquiries@gsi.strath.ac.uk) Tel: 0141-548-3700 Fax: 0141-548 4523 JOB OPPORTUNITIES The Department receives notification of vacancies directly from employers and through the professional press. Current vacancies are normally posted on the notice boards or in the pamphlet racks near the Office. Recruitment agencies, such as TFPL and Sue Hill Associates, also visit the Department during the academic year. You should also maintain regular contact with the Careers Service on the 5th Floor of the Livingstone Tower. KEY DATES Examinations Main diet: week beginning 7 January 2008 Second semester diet: week beginning 12 May 2008 Re-sit diet: 6 ­ 19 August 2008 The date of all diets is governed by University Regulations (Chapter 4) and cannot be altered. Students should be available to attend both diets of examinations. Progress Committee Late January, 2008 Examination Boards Interim Board (for dissertations, re-sits and re-submissions from previous cohort): late January 2008. Main Board: end of May or beginning of June 2008. Third Board (for dissertations, re-sits and re-submissions): end of September or beginning of October 2008.

7

MSc DISSERTATION Students who proceed to the MSc dissertation will be allocated a supervisor once their research topic has been approved. It is essential that you maintain regular contact with your supervisor during the period June-September: you will be expected to attend regular meetings with supervisors during this period and essentially to remain at the University (unless work on your dissertation requires absence elsewhere). Dissertations should be between 15,000 and 20,000 words in length and the final bound copy must be submitted in early September. You must also submit an electronic copy of your dissertation in one of the following formats: Microsoft Word (97 or later), PDF, or RTF. You will be asked to confirm whether you wish this to be included in the online archive of dissertations. It is not in your interest to delay submission of your dissertation. Extensions to the period of study required to complete your dissertation may be granted if your work is affected by personal, psychological or medical problems and you have submitted documentary evidence, but only if there is evidence of satisfactory progress up to that point. You have a maximum of 3 years from first registration in which to submit your dissertation. Dissertation writing will be discussed during the Research Methodologies class, and dissertation guidelines are included below, under Study and Learning. Dissertations will be marked and you will receive a feedback form with the mark and comments. Marks will be allocated to each part of the dissertation (introduction, literature review, etc.) and a mark of less than 50% for any part will require correction of the part(s) and re-submission of the dissertation. Full details of marking criteria will be distributed during the MSc seminar in the second semester. MSc with Distinction or with Merit The award is normally that of MSc. The Board of Examiners awards an MSc with Distinction or with Merit in accordance with University regulation 19.1.38. PERSONAL TUTORS You will be assigned a personal tutor at the start of the course, who may meet with you at times throughout the session. Your tutor is there to help you with any problems you may be experiencing, whether they are with course work, accommodation, personal difficulties, etc., and you should not hesitate to contact her or him when necessary. You are perfectly free to raise a problem with any member of staff if you prefer to do so. Please remember your personal tutor is not a trained counsellor and may not have the experience or necessary skills to deal with more serious problems. He or she will, however, be able to direct you to appropriately qualified staff within the University. The University has a comprehensive welfare service for students on the 4th floor of the Graham Hills Building, which will deal with any difficulties you may have on a confidential basis. There is also a Student Health Service in Livingstone Tower (ext 3916 for clinic appointments). PROFESSIONAL ASSOCIATIONS CILIP is the Chartered Institute of Library and Information Professionals, the professional body. The Institute has a student membership category, the subscription for which includes a monthly magazine, a jobs bulletin, and a discount on CILIP books and certain conferences. Attending their meetings will introduce you to other members and potential

8

employers, as well as adding to your course. Student membership is also the first step on the road to full membership of this association. See http://www.cilip.org.uk/ Aslib, the Association for Information Management, also has a student membership category (although otherwise it does not offer personal membership). See http://www.aslib.co.uk/. The British Computer Society also has a student membership category. BCS membership will give you access to a broad range of services for young professionals as well as demonstrating to potential employers that you are committed to a career in Information Systems. Services include: · · · · · · · A free copy of Computing every week. The bi-monthly membership magazine The Computer Bulletin. A CPD programme to enable you to plan and record your professional development. Free access to the BCS Library Online job searches and recruitment shows Access to local Branch and Special Interest Group network A variety of financial services such as insurance and loans

See http://www.bcs.org.uk/. Application forms for these associations will be available from the Departmental Office. PUBLICATIONS BY STUDENTS, AND CONFERENCE ATTENDANCE You are encouraged to consider publication of suitable work in professional journals, etc. and every assistance will be given to you to prepare such work. Staff of the Department are involved in various ways with many professional journals, publishers and will be happy to advise you. You are also encouraged to attend relevant conferences, details of which are displayed on the notice boards. Many of these conferences have a special student rate. REFERENCES FOR STUDENTS Staff are happy to provide references for students. It may be helpful to discuss any job or course application with your referee if there are any particular aspects of the course that you would like emphasised. REGISTRY Registry is an important point of contact for students both during their studies and when they graduate. They have produced a booklet in response to a need for information about the services, which Registry provides for students, and the procedures, which Registry carries out for departments and other sections of the administration within the University. (Available at: http://www.strath.ac.uk/registry/). The Science Faculty Registry is located on the ground floor of the McCance Building and is headed by Lindsay Munro (e-mail:mailto:l.munro@mis.strath.ac.uk; ext 2901).

9

REGULATIONS The Department's courses are governed by the regulations contained in the University Calendar. (Available as PDF files at: www.mis.strath.ac.uk/Secretariat/Publications/general/publications/index.html). RESEARCH OPPORTUNITIES The Department has a growing Higher Degree programme and welcomes applications from current students to read for a PhD or MPhil. If you are interested in pursuing a research degree we will be happy to advise on funding opportunities and the research interests of staff. Deadlines for funding occur throughout the year so it is advisable to speak to a member of staff at as early a stage as possible. The Department is involved in numerous projects and from time to time may also be looking to recruit research fellows to join project teams. See: http://www.cis.strath.ac.uk/research/res_groups.html for research groupings. STAFF INVOLVED IN MSc/PG INSTRUCTIONAL COURSES
Contact details for the staff involved in the Postgraduate courses can be found on the

Department's web site at http://www.cis.strath.ac.uk/cis/staff/index.php?group=academic. The External Examiners for the courses are: Information and Library Studies: Dr Anne Goulding, University of Loughborough Information Management: Dr. Maria Burke, University of Salford Computer and Internet Technologies: Graham Kirby, University of St. Andrews STUDENT REPRESENTATION The Department has a Staff-Student Committee drawn from each course, each of which has one course representative. The Staff-Student Committee is regarded seriously by the University, which provides a short training course for the elected representative. Each course is asked to elect its own representative within two weeks of the course commencing. STUDENTS WITH SPECIAL NEEDS (See Disability) Students with a physical or psychological condition that may affect their academic performance should make an appointment with the Student Adviser (Disability Services) to discuss their circumstances. They should do so at least two months prior to their first diet of examinations so that there is ample time for students to be assessed and for the department to be able to make appropriate arrangements. They should also discuss their circumstances with a member of the Course Directorate and/or personal tutor in order to explore their needs regarding tuition materials and computer equipment. Further information is available at: http://www.strath.ac.uk/Departments/specneeds/ SUBMITTING ASSIGNMENTS Assignments must be handed in by the stipulated time. Work, which is handed in late must be supported by a legitimate reason and appropriate documentation (e.g. medical certificate). In the absence of supporting documentation late work will be penalised at a rate of 5% per week or part of a week. Assignments, which are submitted more than three weeks late without a documented reason will attract a mark of zero percent; the Board of Examiners will consider whether a resubmission is required.

10

Assignments must be handed in to the Departmental Office with a completed Assignment Cover Sheet and will be date stamped. An electronic copy must also be uploaded to the Department server. Details will be provided during classes. You will receive a receipt for your assignments (see Appendix 3 for sample). Assignments should not be handed in to or e-mailed to lecturers. Assignments will have an appropriate word length and you should keep to this length ± 20% and include a word count at the end of the assignment. The word count should exclude preliminaries, such as title page, table of contents, and any references and/or bibliography at the end of the assignment. Assignments, which do not keep to the limit set will be penalised. Assignments, which are over length will have their marks scaled down by the ratio of the word limit/actual word length. Marked assignments will be retained by the Department, but you will be given an individual feedback form. A feedback form with your mark and other comments for particular aspects of the work will normally be given to you not more than four working weeks (excluding holidays) after the submission date for the assignment (see Appendix 4 for sample): you will be notified of any delay in providing feedback (the large size of some classes may mean that marking will take longer). If you wish, you may arrange to see the lecturer setting an assignment for a fuller discussion of your marks. Quality assurance of marking is achieved through second marking and the auditing procedures undertaken by the External Examiner. The Department utilises a scheme of generic descriptors for grades of work (see below), which you should use in combination with the feedback form. Scale 1 Mark band 0-39% Description Significantly below pass standard. Very poor analytical and interpretive skills. General lack of understanding of relevant concepts, applications and implications. Weak exercise of judgement and poor problem solving. Significant problems with effective communication. Presentation needs considerable attention in terms of style and editing. Credible attempt Analytical and interpretive skills lack incisiveness and clarity. Patchy understanding of key concepts, applications and implications. Judgement and problem-solving unconvincing and demonstrating vagueness. Presentation needs more attention in terms of style and editing. Sound standard Competent degree of analytical and interpretive skills, but requiring fuller development. Competent but not incisive understanding of key concepts, applications and implications. Judgement and problem solving uneven. Good presentation. Merit standard High degree of analytical and interpretive skills. Good understanding of key concepts, applications and

2

40-49%

3

50-59%

4

60-69%

11

5

70+%

implications. Good judgement and problem solving. Very good presentation. Distinction standard. Exceptional degree of analytical and interpretive skills with a high degree of originality. Comprehensive understanding of key concepts, applications and implications. Professional and mature judgement and problem solving. Excellent presentation.

You may be required to resubmit an assignment which achieves a mark of less than 40%. Note that voluntary resubmission of assignments in an effort to improve the mark awarded is not permitted. Assignments may be presented by the Department to the External Examiner for comment. Your attention is drawn to the guidelines on Writing Assignments and Dissertations and in particular the serious view that is taken of plagiarism.

12

STUDENT SUPPORT OUTWITH THE DEPARTMENT The University has a wide range of services to help you during your course of study. These are listed below together with the URL of their respective web sites. Please do not hesitate to contact any of them if you need to.

ASK 4 (Formerly Student Welfare): http://www.strathstudents.com/display/strathclydeadvice/Ask4 Careers Service: http://www.careers.strath.ac.uk/ Centre for Academic Practice and Learning Enhancement: http://www.strath.ac.uk/caple/ Centre for Sport and Recreation: http://www.strath.ac.uk/sport/ Chaplaincy: http://www.strath.ac.uk/chaplaincy/ Childcare: Support for childcare costs may be available through the Childcare Fund (Student Finance Officer, 0141 548 2753 or email s.finance@strath.ac.uk). Childcare Scotland runs a nursery on the John Anderson campus on a paying basis for pre-school children of all ages. (Nursery Manager 0141-553 4125). Disability Service: http://www.mis.strath.ac.uk/SSS/ English Language Teaching Division: http://www.strath.ac.uk/eltd/ Equal Opportunities: Email mailto:equalopps@theunion.strath.ac.uk Graduate Centre: http://www.strath.ac.uk/postgrad/ International and Graduate office: http://www.io.strath.ac.uk/ Learning Services: http://www.learningservices.strath.ac.uk/ National Union of Students: http://www.nusonline.co.uk/ Other Students Association services: http://www.strathstudents.com/display/strathclyde/Home Student Advisory and Counselling Service: http://www.strath.ac.uk/sacs/ Student Finance Office: http://www.mis.strath.ac.uk/SSS/finance/index.html Student and Occupational Health Service: http://www.mis.strath.ac.uk/SSS/occupational_health/index.htm

13

STUDY AND LEARNING COURSE MATERIALS You will be supplied with lecture notes, which will form the foundation for your studies. You are however, expected to read outside of these notes and lecturers will provide indicative reading lists. While you are not obliged to buy books on the reading lists, you are advised to acquire a representative selection of the literature as library books have an annoying habit of being out on loan when they are most needed. John Smith and Son Ltd have a bookshop on campus, in the Curran Building. DEPARTMENTAL COMPUTING FACILITIES The Department operates a number of laboratories for its own students. At present, there are three large teaching laboratories, one on each of the tenth, eleventh and twelfth floors of the Livingstone Tower, and two smaller laboratories (for postgraduate and final year students) on the thirteenth floor. There are at least two printers in each main laboratory: a mix of colour, laser and draft dot-matrix printers. All departmental machines in the Livingstone Tower are linked by a high speed local area network and operate under an integrated file system, managed by a combination of Sun and Linux multi-processor servers with a combined file store of over 2 Terabytes (2 million, million bytes). At present the configuration of the laboratories is as follows: Name Arrol Kelvin Muir Telford Telford Baird Room Use L10.09 General L11.01 General L12.01 General L12.22 General L12.22 General L13.14A PG & Final Year Machines Pentium 4 2.8GHz Pentium 4 3.0GHz Pentium 3.4GHz Sun Workstations Pentium 2 3.4GHz Pentium 3.4GHz No. 50 60 30 25 25 15 OS Windows XP Windows XP Linux Solaris 8 Linux Windows XP

Note that the laboratory in L13.14A and the accompanying study is available for you. It is shared with final year undergraduates. It is likely that these facilities will again be updated before the start of the next academic year. The Department operates a printer quota system, whereby additional printing capacity can be purchased from time to time by individual students. Remote use is also made of machines operated by Information Technology Services, which is adjacent to the University Library in the Curran Building (St. James' Road). In particular, some classes make use of the campus-wide network of over a hundred Unix workstations provided for general teaching purposes, and for research. The Department welcomes the physically disabled, but University regulations prohibit the non-ambulant from the third and higher floors of the Livingstone Tower. Anyone who is affected should contact a member of the Course Directorate as soon as possible. Access to Laboratories You may gain access to laboratory and other departmental areas freely during the normal working day - except that you may share use of a laboratory with a scheduled class only with the explicit permission of the member of staff in charge.

14

On individual application, access to departmental areas is also possible in the evenings and at weekends. Ask at the Departmental Office (L10.01) for an S6 Application Form. Evening access (from 18.00 hours to 22.00) will be granted upon request, but more extended access is not encouraged or supported. Access to departmental laboratories is through a coded electronic lock. During normal working hours, use the code issued to you; access outwith those hours requires a special magnetic card, which will only be issued to those already holding the valid [paper] permit required by the University's security system and referred to in the previous paragraph. Please remember that your security (and that of your colleagues and of departmental equipment) requires that each of us makes proper use of the new system. See http://www.cis.strath.ac.uk/people/ssgroup.html for details on systems support. DICTIONARIES Students whose first language is not English are permitted to use dictionaries in examinations. You should present your dictionary in advance of the start of the examination diet to the Departmental Office for inspection where it will be housed for the duration of the diet. The invigilators for each examination will bring the dictionary with them to the examination for your use. GROUP WORK Group work is seen as an important part of our courses, as it provides experience in group management, negotiation and co-ordination, which reflects the requirements of the operational world. Group work also allows us to explore and test understanding of more complex problems than would be possible with individual assignments. Students should note that for group assignments there may be an element of peer assessment, and the Department reserves the right to moderate an individual mark in the light of this peer assessment where it is supported by other evidence. The method of peer assessment will be explained for each assignment. Group extensions will only be given in exceptional circumstances. If a group extension is required it must be made with the backing of the entire group, and must be supported by evidence that the group as a whole is unable to fulfil its commitments. Individuals cannot make requests for extensions for a particular part of a group assignment for which they have responsibility. GUIDELINES FOR DISSERTATIONS Detailed guidelines for the MSc dissertation will be issued during the MSc seminar in the second semester. A copy is available at http://student.gsi.strath.ac.uk/student/msc/ Guidelines for assignments are given below, under Writing Assignments LIBRARY The Main Library is located at 101 James Street in the Curran building. Membership is automatic when you register at the University: your Strathclyde student card has the library bar code user number on it. The Science Faculty Librarian is Elaine Blair. See http://www.lib.strath.ac.uk/for full details of library services. You are entitled to request inter-library loans for material relevant to your course. You should complete an ILL form, have it countersigned by a lecturer and then stamped by the Department.

15

The Andersonian Library subscribes to an increasing number of electronic databases and journals. A full list of these services is available on the Andersonian's web site, at http://www.lib.strath.ac.uk/els.htm. The majority of individual journal and database files are also listed on the library's catalogue. The Library also holds and networks a number of CDROMs. You will be receiving a basic introduction to the library and its services in the early weeks of the first semester. Several of the Library's electronic service providers require authentication using an Athens username/password. These are only available to registered students and members of staff of the University. Please note, not all service providers allow remote access to their databases. Distance learning students with no access to a University machine and no University VPN access should contact the Library. All other users should create their own personal account. See http://www.lib.strath.ac.uk/athens.htm LIBRARY RIGHTS AT OTHER UNIVERSITIES Those on the instructional part of the postgraduate course have consultation rights at the University of Glasgow on production of their student card. Those who have proceeded to the Masters dissertation can obtain borrowing rights. Students who wish borrowing rights must obtain a letter of introduction from the Departmental Office. You may also be entitled to use the Library facilities of other Universities (for instance, if you are a graduate of that University). PLAGIARISM AND OTHER FORMS OF ACADEMIC DISHONESTY The University regards academic dishonesty as a serious offence. Allegations of academic dishonesty will be fairly assessed and appropriate action will then be taken. An allegation that has been dismissed as a disciplinary offence may still incur an academic penalty for poor scholarship. A record will be kept of any formal allegations and the outcome of their assessment. University Regulation 4: Examination Regulations for All Instructional Courses, and Regulation 5: Regulations for Student Discipline, give full details of the procedures to be followed and penalties which may arise in cases of academic dishonesty. Plagiarism is unacceptable, and the University deems it a very serious offence. Assignments and dissertations are not intended to be an exercise in copying material from books and articles or from fellow students, but should always be your own work. Omitting acknowledgements and the clear identification of quotations and other material from original sources constitutes plagiarism and is not consistent with the aim of demonstrating understanding. When you take material from a book, an article or web site, you should consider it and fashion it in order to support your argument, or to criticise it. You may use quotations, facts, ideas, etc. but they must be related to your work and must be attributed. If significant portions of material are copied with only minor alterations, this also counts as plagiarism. Plagiarism must also be avoided in practical work such as individual computer-based projects. It is not acceptable to copy the work of other students in such projects, with only minor amendments (e.g. simply changing function or variable names), and then to submit it as your own work. If such plagiarism is identified, the Department may take the appropriate action against all the students involved, regardless of who copied from whom. It may also be necessary to take further action, and students who plagiarise another's work may be subject to disciplinary proceedings.

16

Where plagiarism occurs, a formal warning will be given and the Department, in assessing the merit of an assignment or dissertation, may decide that the extent of plagiarism is such that the assignment or dissertation contains nothing of the student's own effort and therefore attracts a mark of zero and must be resubmitted. In less extreme cases, the plagiarised sections will be set aside and the assignment or dissertation marked only on those parts, which do follow normal conventions. When you submit an assignment, you will be required to sign a declaration that it embodies your own work, that it has been composed by yourself, and that you have made due acknowledgement to the works of others. The Department requires an electronic copy of each assignment: a random sample of these will be analysed for plagiarism. A seminar will be held early in semester 1 which will cover correct forms of citation and how to avoid plagiarism. STUDY SKILLS You can improve your study skills with the help of the Centre for Academic Practice (CAP), and, for those who do not have English as their first language, the English Language Teaching Division (ELTD). You can register with CAP (ext 2637) to be notified about the courses they run. ELTD run courses in both the first and second semester, which are aimed at improving written and oral English language skills. Leaflets are available from ELTD or from the Course Office. Students in previous years have found the sessions run by CAP and ELTD valuable and you may wish to discuss the options with your personal tutor, who will be able to advise you. You may also wish to consult Techniques of Study available at: http://www.cis.strath.ac.uk/teaching/ug/courses/study.html UNIVERSITY COMPUTING FACILITIES The University has a large number of computer laboratories located across the campus. Full details of these and the software available in each lab are available at: http://www.its.strath.ac.uk/ and notice boards in laboratories. Your attention is drawn to the fact that in using these facilities you must comply with the University Policy on the use of computing facilities and resources. See http://www.its.strath.ac.uk/doc/ - top. Selected centrally managed laboratories may be used up to 22.00. If you intend to stay in a building after 18.00 you must have a blue security card (available from the Departmental Office), which is valid for that building. If you wish to use the facilities after 22.00 or at the weekend, you must obtain a red security card (available from the Departmental Office). These cards must, be countersigned by an authorised member of the Computer Centre staff. New cards must be obtained each semester and if you are proceeding to MSc. WRITING ASSIGNMENTS The exact nature of assignments will vary from class to class and may involve individual work, group exercises or practical work with, for instance, software packages. Assignments are an important part of your course, and to do them properly, you should be aware of the need to follow certain conventions. There are a number of standard questions you should

17

ask yourself in order to give yourself the greatest opportunity to produce an effective assignment: · · · · · · · · What am I being asked to do? What criteria are being used to assess me? What weighting is placed on the various elements of the assignment? How will I structure the assignment? What research will I have to do? Does this look and read like a professional piece of work? What source material did I use for the assignment? What deadlines have been set and what deadlines should I set myself?

Understanding the assignment The first three questions will be answered by the assignment outline (see Appendix 5 for an example). It is important that you understand the assignment brief and that you focus on what the lecturer has asked you to do (sounds obvious but you would be surprised how often this simple piece of advice is overlooked!). If you have any doubts about the assignment brief or have difficulty interpreting the requirements then raise them with the lecturer who has set the assignment. Our aim is to set assignments that allow you to demonstrate your understanding of the topics covered in the course and we want you to have the best opportunity to record results which truly reflect your capabilities. However, you will not get credit for material, which is not related to the topic so ensure that your assignment is focused on what has been requested. Your assignment will be marked according to a number of criteria, each of which will carry a percentage of the total marks attributed to the assignment. These are designed to help you decide on the balance of material, which should be contained in your assignment. Again it is important that you understand the criteria that are being used and the weight that is placed on them: clearly there is little point concentrating your assignment on one criterion which only carries 15% of the marks and giving only superficial treatment to one that carries 50% of the marks. Group assignments may also have an element of peer evaluation, in which you will be asked to evaluate the contribution made to the work by each member of the group. Details of this will be provided where appropriate. Structuring your assignments It is always a good idea to work out a structure for your assignments in advance, and to decide what parts of your explanations and arguments are going into each section, before filling in the detail. For longer assignments, and for reports, it is helpful both to you and to the reader if you provide headings for each of the main sections. For any assignment the lecturer would expect to see an introductory section, in which you describe the scope of the assignment, and a final section in which you summarise your conclusions. Between these two points, your ideas, and any information, should be presented in a logical order. Bibliographies and/or lists of references should be given at the end of the assignment (see below for instructions on assignments). You should also incorporate page numbers. For a report, you would normally number the sections and subsections and provide a table of contents with associated page numbers.

18

Researching your assignments You will normally use a representative selection of readings to provide some theoretical background, supporting evidence and possibly counter-examples. You should not rely on the lecture notes and will get credit for independent research (i.e. the identification of relevant source materials which have not been provided in class or in reading lists by the lecturer). Typically you will use the library and search engines to identify these materials but do not forget the power of asking other people! Writing your assignments You should follow English grammar and usage, and it is always worthwhile double-checking your spelling (use the spellchecker on your word processor if you have one). Note, however, that a spellchecker will not highlight where you have used the wrong word (from vs. form; their vs. there) and you should also proofread your assignments before handing them to capture any legitimate words which have been used in the wrong context. Do not use a style, which is too informal and chatty. These are postgraduate courses and you are expected to write in a professional style. Always use the expanded form of an acronym before employing the shorthand version using the following convention "...will find that Asymmetric Digital Subscriber Lines (ADSL) provide a higher throughput...". Further guidelines on style will be given during the Research Methodologies module. Assignments should use 11- or 12-point font (this handbook uses 11 point), 1.5 line spacing and have either indented paragraphs or paragraphs separated by a single line. Leave a good margin all round (this handbook has top and bottom margins of 2.54 cm and side margins of 3.17 cm). You may use any font you wish, but avoid those, which resemble handwriting, as they can often be difficult to read. As an academic work, an assignment or dissertation should give the reader the opportunity to make up his or her own mind that what is being said is true. Do not, therefore, simply make assertions and generalisations of fact, unless that fact is something about which there can be no doubt and which the reader can be expected to know. For example, it is unlikely that anyone will argue if you assert that information technology is having a major impact on organisations and society. If, however, you state that the introduction of IT has led to the loss of 25,000 jobs in the Canadian insurance industry, you must cite the evidence, which supports that claim. You may not always know what can be taken as common knowledge, especially if the subject is new to you. In that case, it will be a good idea to err on the side of caution - if in doubt, cite your source! Citing references As a general guideline: · if you draw on someone else's opinion, facts, or generalisations, you must make some reference to that writer; · if you use his or her words directly, use quotation marks; · give references for: assertions of fact that cannot be presumed to be common knowledge; direct quotations or paraphrases of other writers; opinions and generalisations derived directly from other writers; tables and diagrams (for which you should give the source underneath the table or diagram).

19

Lecturers will look for good standards of accuracy in citing references. A key guideline is: could the reader identify and locate the reference uniquely and quickly? It is therefore a good discipline to record citation details as you use them. In general this means that you should provide the following key elements (which you might imagine as fields in a database record): · · · · · The author or organisation responsible for the writing the work. The title of the work. Where the work was published and who published it (if a book or report); or the journal where it appeared (if an article); or the web address (i.e. URL) where it appeared (if located on the web). The date when it was published (if a book, report or journal article); or the last time it was accessed (if a web page). The pages(s) cited (of a book or report); or the start and end pages (if an article).

Fuller details are given below of how to cite particular types of work. References in the text should be made using the Harvard system: Give the author's surname, date of publication and specific page number in brackets, e.g.: As Flint has pointed out, the call for the free flow of information has come predominantly from ... (Flint, 1998, p.46). A single list of references, plus other works consulted, in alphabetical order by surname should be provided at the end of the assignment. (If you list more than one work by the same author with the same publication date, use lower case a, b, etc. to distinguish them, e.g. Flint, 1998b). Follow the citation style detailed here, including the use of punctuation. Note the use of italics for the titles of books, journals and web sites. This is not a comprehensive list: these examples should be regarded as models for any other type of citation you might make. Further information will be provided in relevant classes such as Research Methodologies. If you are citing a reference (e.g. to a journal article) found on an online database, cite it as you would any other journal article, etc. You do not need to cite the database in which you found the reference. Citing a monograph (i.e. book): Author(s) or editor(s). Date of publication within parenthesis Title: subtitle. Edition (if not the first). Place of publication: Publisher. Page number(s). Example: Lowe, C. (1999). Systems and people: an anthropological approach. 2nd ed. London: Paradigm. p39. Citing a journal article:

20

Author(s). Date of publication in parenthesis. Title of article. Title of journal. Volume number (part number), Page number(s). Example: Herberts, I., Dryden, H. and Clark, J. (2000). Managing the introduction of new technology. Journal of Informatics. 13 (4), p253-255. Citing a conference paper: Author(s). Date of publication in parenthesis. Title of paper. In: Editor(s). Title of conference proceedings. Place of publication: Publisher. Page number(s). Example: Urtin, D.J. (1998). The information professions in the new century. In: Hapling, A. (ed.) The new information professionals: proceedings of the European Conference of Librarians and Information Scientists, Brussels 4-6 September, 1998. Aldershot: Gower. p65. Citing a chapter in a book: Author(s). Date of publication in parenthesis. Title of chapter. In: Editor(s). Title of book. Place of publication: Publisher. Page number(s). Example: Rumpole, E. (1997). Managerial expert systems and organizational change. In: Withers, R.J. and Patroch, R.A. (eds). Change management: a reader. Chichester: Wiley. p140. Citing an unpublished thesis or dissertation: Author. Date of publication in parenthesis. Title of dissertation. Type of dissertation, Awarding institution, Page number(s). Example: Brown, S. (1994). The impact of information technology on management functions and structures. Unpublished MSc dissertation, University of Strathclyde. p26. Citing a letter or other private correspondence: Author. Type of correspondence. Date of correspondence. Example:

21

Gibb, F. Private correspondence, 23 November, 2006. Electronic resources pose the greatest problems as the information you require may not be immediately obvious. Citing an item read on an electronic mail discussion list: Author. Subject line. Name of discussion list. Availability online: URL of archive, or address of list. Date last accessed. Example: Walon, B. Re: Spam question. Internet sales discussion list. Available online: http://www.mmgco.com/isales.html. Last accessed 12 November 2001. Citing an item of personal mail: Author. Subject line [e-mail to recipient's name]. Available e-mail: recipient's name. Date last accessed. Example: Wakeford, R. Standards of service in the library. Available email: l.short@cis.strath.ac.uk. Last accessed 12 July 2002. Citing a complete work found in an electronic source (e.g. a report on the Internet, or a full-text market report found on Dialog): Author. Date of publication (if given) in parenthesis Title. Edition (if not first). Place: Publisher, Availability online. Date last accessed. Example: Webber, S. (1998).Business sources on the internet. Glasgow: University of Strathclyde. Available: URL http://www.dis.strath.ac.uk/business/. Last accessed 8 August 1999. Citing an electronic journal article: Author. Date of publication in parenthesis. Title of article title. Title of journal title. Volume (issue - if given), Pages (if given). Availability online. Date last accessed. Example:

22

Nimitz, E.L. (2001). The surveillance corporation. Privacy Monitor.3(4), p4-12. Available: http://www.infocast.com/PrivacyMonitor/34Nimitz.htm Last accessed 16 August 2003 Citing an electronic database: Database name [medium]. Place: Producer. Inclusive dates. Available: Distributor. Example: MEDLINE [Online]. Bethesda: National Library of Medicine. 1987-2002. Available: Dialog file 45. Time Management The schedule of assignments given out should allow you to balance your time and plan for the hand-in of assignments. You can avoid putting unnecessary stress on yourself by following simple pieces of advice: · · · · Don't try to print your assignment an hour before the hand-in date. Equipment fails and disks get corrupted (so always make a back up). Give yourself sufficient time to check your work before handing it in. Get ideas down on paper as soon as you can so that you can evaluate and refine them. If you have two assignments due within a week of each other avoid the temptation to spend four weeks on one and then only leave a week to complete the next one.

23

UNIVERSITY RESOURCES AND POLICIES In many cases, the URL of the relevant policy document is provided. Please ensure that you read these documents as soon as possible: they contain valuable information for your time here at Strathclyde.

BUILDING PREFIXES The following prefixes will be used on the course timetables: F/G AT Col Cur DUN HD P K M L McC R S C WOL MTC SIBS Architecture Alexander Turnbull Colville Building Curran Building Sir William Duncan Building Henry Dyer Building Graham Hills John Anderson James Weir Livingstone Tower McCance Building Royal College Building Stenhouse Building Thomas Graham Building Wolfson Centre Marine Technology Building Strathclyde Institute of Biomedical Sciences

BUILDINGS Lectures are held in a number of different rooms throughout the campus and the main University buildings are indicated on the Campus map which can be found at: http://www.strath.ac.uk/maps/johnandersoncampus/ The University has established a number of policies on matters relating to your period of study here and you should familiarise yourself with the requirements of the policies listed below: Computing regulations University Policy on the Use of Computing Facilities and Resources: http://www.strath.ac.uk/IT/PolicyDocs/regs.html - top and University Regulation 6.11 http://www.its.strath.ac.uk/doc/policy/regulation/ Data Protection Act The Act limits the way in which students can be informed of marks, etc. Marks and feedback will only be distributed by sealed letter in person. Marks and decisions on progress cannot be given over the telephone. See http://www.mis.strath.ac.uk/Secretariat/DataProtection.htm and http://www.cis.strath.ac.uk/teaching/ug/regulations/6_9.html Freedom of Information Act: http://www.strath.ac.uk/foi/faq/

24

Equal opportunities These policies apply equally to students and staff http://www.strath.ac.uk/about/policies/equalopportunities/ Equal Opportunities Officer Fiona George Jordanhill Campus Ext 773195 Equal Opportunities Officer Students' Association, John Street Ext 2060, then select option for Welfare

at

the

University.

See

There is a network of trained harassment advisers across the University who can give confidential help, support and advice to anyone who feels they are being subject to harassment. A list of advisers can be obtained from the people listed above. Use of non-sexist language: http://www.strath.ac.uk/Other/POW/nscomm.htm FIRE Students should familiarise themselves with fire exits in any of the buildings, lecture theatres and laboratories that they use. The fire alarm is a loud continuous siren. The drills to be followed in the event of a fire are mandatory: · · · · · Evacuate the building immediately through the nearest exit; Do not stop to collect belongings; Do not use lifts. Use the stairs; Keep well away from the building and allow a clear route for the emergency services; and Do not re-enter the building until instructed by the Security staff.

If you discover a fire telephone security on internal extension number 2222, report its whereabouts and then evacuate as above. HEALTH AND SAFETY If you are involved in an accident or incident on University property or if you observe an unsafe situation of practice, please inform the Departmental Safety Convenor, John Ferguson (ext 3617) as soon as possible. First aid can only be administered by trained members of staff and can be obtained from Security Wardens. The University's emergency internal telephone extension is 2222. University of Strathclyde Health and Safety Policy Statement It is the policy of the University of Strathclyde to ensure, so far as it is reasonably practicable the health, safety and welfare at work of all its employees in accordance with relevant statutory requirements. It is the policy of the University to ensure, so far as is reasonably practicable, the health, safety and welfare of its students while they are engaged in activities, which are under the supervision of the University.

25

The University will also afford, so far as is reasonably practicable, the same safety and health assurances to those members of the general public who have access to the University property. The policy stated above will be enacted through the following: · · · · A Health and Safety Policy document including the University's Safety Code which contains the arrangements and organisation for health and safety (a summary of the policy is distributed to all staff); Local safety rules as are approved by the University Court and issued to departments for appropriate distribution; Departmental Safety Regulations; and University Safety Services' Guidance Notes

It is the duty of all staff and students to abide by the said code, rules and regulations. Within the general policy stated above, it is the University's policy in particular: · · · · · To provide and maintain accommodation, equipment, services and systems of work which are, so far as is reasonably practicable, safe and without risks to health; To make arrangements for ensuring, so far as is reasonably practicable, safety and absence of risks to health in connection with the use, handling, storage and transport of articles and substances; To provide such information, instruction, training and/or supervision as is necessary to ensure, so far as is reasonably practicable, the health and safety of the persons detailed above; To provide and maintain such protective equipment and clothing as is necessary to ensure, so far as is reasonably practicable, the health and safety at work of its staff and students; To encourage staff to set a high standard of safety by personal example in order that students leaving the University should take with them an attitude of mind which accepts good safety practice as normal.

In pursuance of this policy, the University has established the Statutory Advisory Committee on Safety to advise the University Court on all matters relating to safety in the University and to oversee the implementation of the University's Safety Policy. The University has appointed a University Safety Advisor (Head of University Safety Services), a Radiation Protection Advisor and a Biological Protection Advisor. The latter two are responsible, through the Head of the University's Safety's Services to the secretary of the University (and Court) for the implementation of the University Safety Policy. The University expects all staff and students to contribute to the maintenance of this policy by adhering to such regulations as are in force, by reporting hazards, accidents and inadequacies in the working environment to the person responsible. Each member of staff has a personal responsibility (under section 7 of the Health and Safety at Work Act 1974) for his/her own health and safety and for the health and safety of those who may be affected by their activities.

26

MENINGITIS IMMUNISATION Note for Incoming New Students See http://www.strath.ac.uk/healthsafetyalerts/health-meningitis/ The health authorities have recommended immunisation for new full-time students against Group C meningococcal infection, an important cause of Meningitis. Please Note: the above immunisation does not protect you against all forms of Meningitis! You should still be aware of the symptoms of Meningitis, as given to you with Registration packs. If you have any further queries about Meningitis immunisation, please contact: Student and Occupational Health Service Level One Livingstone Tower Ext 3678 MOBILE PHONES Please make sure that mobile phones are switched off during any examinations, lectures, practicals, tutorials, or in the library, computer laboratories and study areas. You are not permitted to have a mobile phone at your desk during any examination. NOISE Please note unnecessary noise or any other disturbance during lectures, practical sessions etc. will not be tolerated and will be dealt with accordingly. REFECTORIES The University offers a wide range of eating places throughout the Campus, e.g. Curran Building, Livingstone Tower, SGBS, Student Union and the Todd Centre, SECURITY Regrettably security is a problem at times within the University and you are advised to look after your personal possessions with care and not to leave them unattended. If you plan to stay in the University buildings after 18.00 in the evening you must be in possession of the appropriate security card to giving you permission to do so. These cards are available from the Departmental Office. This is for your own protection. Buildings are locked at 22.00 at night and working after this time is only permitted if you have a duly authorised card. Any suspicious circumstances/persons should be reported to Security Control on extension 3333. You should carry your student registration card with you at all times as a means of identification. SMOKING The University, in compliance with the Smoking, Health and Social Care (Scotland) Act 2005 which prohibits smoking in enclosed public spaces, has agreed the following policy: Smoking is prohibited: · Within all University buildings · Within all vehicles owned and operated by the University

27

· ·

Within leased vehicles used during University business Within 15 feet (4.6m) of any University building entrance, doorway or stairs or covered area where this distance is within University property.

Staff, students and visitors are asked to take a responsible attitude to ensure areas are kept litter free and they do not stand in close proximity to open windows. Further information on the University's smoking policy can be found at: http://www.strath.ac.uk/about/policies/nosmokingpolicy/ SPORT AND PHYSICAL EDUCATION The Centre for Sport and Recreation offers all members of the University the opportunity to participate in physical activity as a means of achieving a healthier lifestyle, to develop new physical skills and to maintain or improve their sporting talents. The Centre is located in the Sports Centre on the John Anderson Campus at the top of John Street, very close to the Students' Union. See http://www.strath.ac.uk/sport/ for details of the Centre's facilities Telephone: 0141-548-2446 e-mail ags98104@strath.ac.uk STUDENT CHARTER A copy of the guide to the Further and Higher Education Charter for Scotland is distributed to all students. If you have a problem with any part of your course, you are encouraged to discuss this initially with your Personal Tutor, Class Co-ordinator or the Course Director, as appropriate. Key elements from the charter are given below: Strathclyde Students and the Higher Education Charter The Scottish Office Education Department launched the Further and Higher Education Charter in 1993 after open consultation with all the parties concerned. The University contributed positively to the debate on the Charter and supports many of its principles, which reflect existing good practice and standards of customer care in the University. The University endorses for the most part the aims of the Charter. Additionally, this document identifies those issues which receive particular attention in the University or where University policy may be at variance with the Charter. The Charter is devoted largely to the obligations of the institutions, but students also have responsibilities, in particular the expectation that they will observe the Charter, Statues, Ordinances, Regulations and any other rules of the University. This document is distributed, and should be read in conjunction, with the Further and Higher Education Charter for Scotland. [Charter page 2] Standards of Service The University endeavours to provide all students with an environment that is educationally supportive, fair and intellectually challenging and where services are provided in an efficient and friendly manner. However, should problems occur, or should you not be satisfied with the standard of service you receive, we would ask you to let us know as soon as possible using the complaints procedure published in course and departmental handbooks. [Charter pages 4, 5]

28

Keeping Students Informed Choice of Institution and Course The University is a founder member of the Higher Education Liaison Officers Association of the United Kingdom, and fully supports its Code of Practice regarding quality of information and service. The University supports recognised publications (such as the University and College Entrance Guide and the Entrance Guide to Higher Education in Scotland), databases (such as ECCTIS and Gateway) and sources of advice, which give general information on the opportunities available. These help potential students to understand the nature and standard of education provided and so make an informed choice of institution. More importantly, potential students should seek information and guidance from professional advisory staff such as schools and college guidance staff, members of the local careers services, or the Schools and Colleges Liaison Service of the University, which has a team of trained staff to advise. [Charter pages 6, 7] The Undergraduate and Postgraduate Prospectuses provide candidates with information and advice to help them choose the most suitable institution and course for their needs. [Charter page 7] The Higher Education Quality Control (then known as the Academic Audit Unit) last reported on the quality assurance systems in the University in 1992. Its report is available from the Academic Registrar. The Scottish Higher Education Council publishes an assessment of the quality of research carried out by each institution. Its latest report on the University of Strathclyde is available for consultation in the Secretariat Office. [Charter page 8] The University's courses involve progression through subjects along coherent pathways by credit accumulation. All students have considerable freedom of choice and some take up opportunities to transfer to other compatible courses in this or other institutions. The University has an original signature to the Scottish Credit Accumulation and Transfer Scheme (SCOTCATS). [Charter page 9] Students with Disabilities or Learning Disabilities Candidates with special needs should contact Anne Simpson, Student Adviser (Disability Service), to discuss their requirements before applying for admission. [Charter page 17] Student Services The full range of student services is available on the John Anderson campus. Most are also offered on the Jordanhill campus and a process of harmonisation across the two campuses is under way. Each service provides a written guide to the information and advice it offers which is available on request direct from the appropriate service. [Charter page 11] After Acceptance New students receive copies of the undergraduate or postgraduate handbook appropriate to their course, detailing the aims and structure of the course along with other more general

29

information. Course handbooks will normally be provided by the Course Organisers. In cases of difficulty they are available from the appropriate Faculty Officer. Course Assessment Course handbooks and class statements include information on the criteria for assessment of work during the course. [Charter page 16] Equal Opportunities The University is implementing a policy of equal opportunities irrespective of religion, race, politics, sex, age, marital status, disability, culture or sexual orientation. This applies across the whole range of students and staff, and details are available on request from Fiona George, Equal Opportunities Office. [Charter page 17] Students' Association The University does not subscribe to the Government's views on student organisations. It considers that the proposed reforms would impose on activities, which would result in the demise of many student services. The University depends upon the Students' Association to provide sporting, social and educational support services, which enhance the quality of the student experience and assist the University in providing an effective teaching and learning environment. [Charter page 17] STUDENT COMPLAINTS The University of Strathclyde endeavours to provide all students with an environment that is educationally supportive, fair and intellectually challenging and where services are provided in an efficient and friendly manner. However, we acknowledge that problems can occur from time to time. When they do or when you are not satisfied that we have acted in accord with our policies and standards we would ask you to let us know as soon as possible using the procedures are described below. Policies, Definitions and Standards Academic Matters In partnership with each student, the University undertakes to identify and supervise an approved programme of study and to make a fair assessment of each student's performance at each key stage of their programme. Details of specific study and assessment programmes and criteria for assessment are contained in Course Handbooks available from the appropriate Faculty Officer. Academic Departments frequently invite feedback from students through questionnaires and staff/student committees. Administrative or Academic Support Services Most departments that provide Administrative or Academic Support Services for students issue a written account of the services they provide. Services are resource limited but each Department aims to provide an efficient and friendly service. Some have published specific performance standards as part of the Administration's Customer Care Programme. All encourage feedback from students as an input to assigning priorities for development.

30

Discrimination, Harassment or Intimidation The University is committed to equal opportunities for all students (and staff) no matter their age, gender, disability, race, culture, religious beliefs or sexual orientation. It wishes to maintain a strong working and learning environment, which welcomes diversity and is free from discrimination, harassment and intimidation. It will act on complaints received and encourage education programmes both to develop awareness or the issues allied to an equal opportunities policy and also to identify any systematic barriers to achieving equal opportunities within the University community. An Equal Opportunities Officer has been appointed to work with staff and students to identify training needs, to develop support mechanisms and to monitor implementation of the University's equal opportunities policy. Further information may be obtained from Fiona George, Equal Opportunities Officer. How can you Make a Complaint or Appeal against an Academic Decision? If you are dissatisfied with an academic decision, concerning for example, assessment grades, progress, awards or classification of awards, please ask for an explanation from those providing the Course, or from the appropriate Faculty Officer. If you remain unhappy with the outcome, you may appeal to the Faculty or Senate Appeals Committees by writing to the Faculty Officer or Academic Registrar as set down in Course Regulations published in Course Handbooks and the University Calendar. If you are dissatisfied with other academic matters or administrative support services in the University please ask for an explanation from those providing the Course or the Service. The SUSA Vice President (Welfare) may be able to asst you in making initial approaches. If you remain unhappy with the reply given, a formal written complaint may be made to the Head of the Academic or Administrative Department or Service. If you believe that you are the subject of discrimination or harassment please seek help from a Designated Harassment Adviser or the Student Advisory and Counselling Service or the Students' Association or your Academic Counsellor, or Adviser of Studies, or the University Chaplains. International students can also seek help from the International Students Adviser. If you so decide, a formal written complaint may be made to the head of the appropriate Academic or Administrative Department. Should you remain dissatisfied with the response you receive from a Head of Department or Service or if you feel unable to put your case to them you can pursue the matter further: in the case of complaints about academic matters, by writing to the Dean of the Faculty concerned in the case of complaints about services or about discrimination or harassment, by writing to the Secretary to the University. How will Complaints be Dealt with? You have a right to complaint without fear of recrimination and to expect that your formal written complaint will be considered in confidence and fairly by an unbiased reviewer(s). This may be the Head of Department, the Dean or the University Secretary themselves or their nominees. The reviewer may consult with other unbiased advisers as appropriate. Procedures for academic appeals to Faculty and Senate Appeal Committees are set out in University Regulations set down in the Calendar and Faculty guidelines. Procedures for complaints about sexual or racial harassment are set out in the University's policy statement available from Fiona George, Equal Opportunities Officer. For other formal written complaints you will as a minimum be accorded an opportunity to submit written

31

evidence. Depending on the seriousness of the complaint you may also be accorded an opportunity to have a personal interview with the reviewer, and/or to invoke witnesses and/or to have a full hearing in accordance with the principles of natural justice. The reviewer will investigate your complaint fully; will make an initial response to you within 7 days; will inform you regularly of the progress of investigations and will advise you of the outcome as soon as practicable. STUDENTS UNION AND SHOP The Students' Union and shop are located on John Street. The Union has bars, banks and recreation facilities and the shop provides a wide range of stationery and other items.

32

APPENDIX 1

CONFIDENTIAL

SICKNESS SELF-CERTIFICATION FORM This form covers you for a maximum period of 7 days including weekends. Any further days must be covered by a doctor's certificate Student's Name:

Course: Period of sickness (enter day and date and include Saturday and Sunday where applicable): DAY First day of sickness Last day of sickness First day of absence Last day of absence DATE

Details of sickness (e.g. viral infection, sprained leg):

DECLARATION I declare that I have been unable to attend the University during the period of sickness stated above and that the information given above is factually correct. Student's signature: Date:

33

APPENDIX 2

REQUEST FOR AN EXTENSION FOR SUBMISSION OF AN ASSIGNMENT

Student's Name: Course: Module: Assignment No: Tutor:

Reason for deferral documentation):

(student

to

complete;

please

attach

any

supporting

Student's Signature:

DECISION Extension Approved? New Deadline: Name of Lecturer: Lecturer's Signature: Date:

Yes | No (Please circle as applicable)

34

APPENDIX 3a

ASSIGNMENT COVER SHEET

Course: Module: Assignment Number: Student's Name: Registration Number:

I have uploaded an electronic copy of the assignment: I declare that this assignment is my own work

Student's Signature: Date:

FOR OFFICE USE ONLY Date Received: Time Received: Disk Received: Received By:

35

APPENDIX 3b

GROUP ASSIGNMENT COVER SHEET

Course: Module: Assignment Number: Date:

I declare that this assignment is entirely the work of this group Student's Name: Signature: Uploaded:

FOR OFFICE USE ONLY Date Received: Time Received: Disk Received: Received By:

36

APPENDIX 4 SAMPLE ASSIGNMENT FEEDBACK FORM ASSIGNMENT NUMBER: 1 STUDENT NAME: REGISTRATION NUMBER: FIRST MARKER: CRITERIA 1. Summary of the key characteristics and functionality of a selected information technology (30%) 2. Examples of how competitors have used that technology to improve their business performance (30%) 3. Identification of where the technology would bring or could extend business benefits to RBSG (30%) 4. Writing an effective report (10%) 1 2 3 4 5 Comments

General Comments:

Mark: Signature:

Deductions:

Final mark: Date:

Deductions of 5 marks per week, or part thereof, may be made for late submissions that have not been approved. Note that this mark is subject to ratification by the Examination Board. Scale 1 2 3 4 5 Mark band 0-39% 40-49% 50-59% 60-69% 70+% Description Automatic resubmission. Credible attempt/Diploma standard Sound standard. Merit standard. Distinction standard.

37

APPENDIX 5 SAMPLE ASSIGNMENT Aim of the assignment: The aim of this assignment is to promote an understanding of the competitive opportunities afforded by a selected information technology applications. Learning outcomes: On completion of this assignment you will have gained experience of: Concisely summarising the key characteristics and functionality of a selected information technology; Researching how that technology has been used by competitors; Identifying and evaluating the potential benefits of that technology to your organisation; Writing an effective report. Brief: You have been given the task of preparing a briefing report on the potential benefits that one of the information technologies listed below has for your organisation. You are required to summarise, in terms suitable for non-technical senior managers, the key characteristics and functionality offered by this technology and to evaluate how your competitors have made use of it. You are not expected to provide a detailed technical description of the technology, only the features that make it attractive to business operations. You are then asked to assess the benefits that the technology might bring to your organisation and, if it is already being used, how its use could be extended. Topics: Grid computing; Content management solutions; Data warehousing; Software re-use environments. Marking criteria: The following criteria will be used when marking your assignment: Summary of the key characteristics and functionality of a selected information technology (30%); Examples of how competitors have used that technology to improve their business performance (30%); Identification of where the technology would bring or could extend business benefits to your organisation (30%) Writing an effective report (10%). Format: The assignment is individual based and should be no longer than 2,500 words. Contribution to overall marks: The marks for this assignment will not form part of the formal assessment. Due date: Noon, 12 November 2007.

38

An Axiomatic Basis for Computer Programming
C. A. R. HOARE

of axioms it is possible to deduce such simple theorems as:

x=x+yXO y<r ~r +y X q = (ry) + y X (1 + q )

The proof of the second of these is:

The Queen's University of Belfast,* Northern Ireland

A5

(r--y) + y X (l+q) = (r--y)+ (yXl+yXq)
X q)

In this paper an attempt is made to explore the logical foundations of computer programming by use of techniques which were first applied in the study of geometry and have later been extended to other branches of mathematics. This involves the elucidation of sets of axioms and rules of inference which can be used in proofs of the properties of computer programs. Examples are given of such axioms and rules, and a formal proof o f a simple theorem is displayed. Finally, it is argued that important advantages, both theoretical and practical, may follow from a pursuance of these topics. KEY WORDS AND PHRASES: axiomatic method, theory of programming' proofs of programs, formal language definition, programming language design, machine-independentprogramming, program documentation CR CATEGORY: 4.0, 4.21,4.22, 5.20, 5.21,5.23, 5.24

A9 A3 A6

= ( r - - y) + (y + y = ((r--y)+y)+yXq =r+ yXq

providedy < r

1.

Introduction

Computer programming is an exact science in that all the properties of a program and all the consequences of executing it in any given environment can, in principle, be found out from the text of the program itself by means of purely deductive reasoning. Deductive reasoning involves the application of valid rules of inference to sets of valid axioms. I t is therefore desirable and interesting to elucidate the axioms and rules of inference which underlie our reasoning about computer programs. The exact choice of axioms will to some extent depend on the choice of programming language. For illustrative purposes, this paper is confined to a very simple language, which is effectively a subset of all eurrent procedure-oriented languages.

The axioms A1 to A9 are, of course, true of the traditional infinite set of integers in mathematics. However, they are also true of the finite sets of "integers" which are manipulated by computers provided that they are confined to nonnegative numbers. Their truth is independent of the size of the set; furthermore, it is largely independent of the choice of technique applied in the event of "overflow"; for example: (1) Strict interpretation: the result of an overflowing operation does not exist; when overflow occurs, the offending program never completes its operation. Note that in this case, the equalities of A1 to A9 are strict, in the sense that both sides exist or fail to exist together. (2) Firm boundary: the result of an overflowing operation is taken as the maximum value represented. (3) Modulo arithmetic: the result of an overflowing operation is computed modulo the size of the set of integers represented. These three techniques are illustrated in Table II by addition and multiplication tables for a trivially small model in which 0, 1, 2, and 3 are the only integers represented. I t is interesting to note that the different systems satisfying axioms A1 to A9 may be rigorously distinguished from each other by choosing a particular one of a set of mutually exclusive supplementary axioms. For example, infinite arithmetic satisfies the axiom: A10z

~3xVy

(y < x),

where all finite arithmetics satisfy: A10~ Vx (x < max)

2.

Computer Arithmetic

The first requirement in valid reasoning about a program is to know the properties of the elementary operations which it invokes, for example, addition and multiplication of integers. Unfortunately, in several respects computer arithmetic is not the same as the arithmetic familiar to mathematicians, and it is necessary to exercise some care in selecting an appropriate set of axioms. For example, the axioms displayed in Table I are rather a small selection of axioms relevant to integers. From this incomplete set * Depurtment of Computer Science 576 Communications of the ACM

where "max" denotes the largest integer represented. Similarly, the three treatments of overflow may be distinguished by a choice of one of the following aMoms relating to the value of max + 1: Alls All, AllM ~ 3x (x = max + 1) (strict interpretation) (firm boundary) (modulo arithmetic)

max + 1 = max max + 1 = 0

Having selected one of these axioms, it is possible to use it in deducing the properties of programs; however, Volume 12 / Number 10 / October, 1969

TABLE

I

A1 x + y = y + x A2 x X y = y X x A3 (x + y) + z = x + (y + z) A4 (xX y) X z = x X (yX z) A5 x X
(y+z) = xX y+xX =x z

A6 y < x D

(x-- y)+y

addition is commutative multiplication is commutative addition is associative multiplication is associative multiplication distributes through addition addition cancels subtraction

A7 x + 0 = x A8 x X 0 = 0 A9 x X l = x

of mathematical logic to express these assertions, and the familiar rules of operator precedence have been used wherever possible to improve legibility. I n many cases, the validity of the results of a program (or part of a program) will depend on the values taken by the variables before that program is initiated. These initial preconditions of successful use can be specified by the same type of general assertion as is used to describe the results obtained on termination. To state the required connection between a precondition (P), a program (Q) and a description of the result of its execution (R), we introduce a new notation:
P{Q}R.

TABLE II
1. StrictInterpretation 23 x 012

+

01

This may be interpreted " I f the assertion P is true before initiation of a program Q, then the assertion R will be true on its completion." If there are no preconditions imposed, we write t r u e { Q } R ) The treatment given below is essentially due to Floyd [8] but is applied to texts rather than flowcharts. 3.1. Axiom OF ASSIGNMENT Assignment is undoubtedly the most characteristic feature of programming a digital computer, and one that most clearly distinguishes it from other branches of mathematics. I t is surprising therefore that the axiom governing our reasoning about assignment is quite as simple as any to be found in elementary logic. Consider the assignment statement:
x:=f

0 0123 1 123 * 2 23** 3 3*** · nonexistent +

0
1 2 3

000 012
02* 03*

2. FirmBoundary 123 × 0123 123 233 333 333 0 1 2 3 0000 0123 0233 0333

+ 0
1

3. Modulo Arithmetic 3 X 012 012

2 3

0123 123 0 230 1 3012

0 1 2 3

000 012 020 032

these properties will not necessarily obtMn, unless the program is executed on an implementation which satisfies the chosen axiom. 3. Program Execution

where x is an identifier for a simple variable; f is an expression of a programming language without side effects, but possibly containing x. Now any assertion P (x) which is to be true of (the value of) x after the assignment is made must also have been true of (the value of) the expression f, taken before the assignment is made, i.e. with the old value of x. Thus if P (x) is to be true after the assignment, then P (f) must be true before the assignment. This fact m a y be expressed more formally: DO Axiom of Assignment

-P0 {x := f} P
where x is a variable identifier; f is an expression; P0 is obtained from P by substituting f for all occurrences of x. I t m a y be noticed that DO is not really an axiom at all, but rather an axiom schema, describing an infinite set of axioms which share a common pattern. This pattern is described in purely syntactic terms, and it is easy to cheek whether any finite text conforms to the pattern, thereby qualifying as an axiom, which may validly appear in any line of a proof. 1 If this can be proved in our formal system, we use the familiar logical symbol for theoremhood: [-P {Q} R Communications of the ACM 577

As mentioned above, the purpose of this study is to provide a logical basis for proofs of the properties of a program. One of the most important properties of a program is whether or not it carries out its intended function. The intended function of a program, or part of a program, can be specified by making general assertions about the values which the relevant variables will take after execution of the program. These assertions will usually not ascribe particular values to each variable, but will rather specify certain general properties of the values and the relationships holding between them. We use the normal notations Volume 12 / Number 10 / October, 1969

3.2. RULES OF CONSEQUENCE In addition to axioms, a deductive science requires at least one rule of inference, which permits the deduction of new theorems from one or more axioms or theorems already proved. A rule of inference takes the form " I f ~-X and ~-Y then ~-Z", i.e. if assertions of the form X and Y have been proved as theorems, then Z also is thereby proved as a theorem. The simplest example of an inference rule states t h a t if the execution of a program Q ensures the t r u t h of the assertion R, then it also ensures the t r u t h of every assertion logically implied by R. Also, if P is known to be a precondition for a program Q to produce result R, then so is any other assertion which logically implies P. These rules may be expressed more formally: D1 Rules of Consequence If ~-P{Q}Rand ~-R D S then If ~-P{Q}Rand ~-S ~ P then

no iterations). Furthermore, it is known t h a t the controlling condition B is false when the iteration finally terminates. A slightly more powerful formulation is possible in light of the fact that B may be assumed to be true on initiation of S: D3 Rule of Iteration If ~P A B{S}P then ~-P{while B do S} ~ B A P

~-P{Q}S ~-S{Q}R

3.5. EXAMPLE The axioms quoted above are sufficient to construct the proof of properties of simple programs, for example, a routine intended to find the quotient q and remainder r obtained on dividing x by y. All variables are assumed to range over a set of nonnegative integers conforming to the axioms listed in Table I. For simplicity we use the trivial but inefficient method of successive subtraction. The proposed program is: ((r := x; q := 0);
while

3.3. RULE OF COMPOSITION A program generally consists of a sequence of statements which are executed one after another. The statements may be separated by a semicolon or equivalent symbol denoting procedural composition: (Q1 ; Q2 ; "'" ; Q~). I n order to avoid the awkwardness of dots, it is possible to deal initially with only two statements (Q1 ; Q2), since longer sequences can be reconstructed by nesting, thus (Q~ ; (Q2 ; ( " " (Q,-1 ; Q.) - ' " ))). The removal of the brackets of this nest may be regarded as convention based on the associativity of the ";-operator", in the same way as brackets are removed from an arithmetic expression (6 + (t2 + ( . . - (t,_~ + t,) - - . ) ) ) . The inference rule associated with composition states that if the proven result of the first part of a program is identical with the precondition under which the second part of the program produces its intended result, then the whole program will produce the intended result, provided that the precondition of the first part is satisfied. In more formal terms: D2 Rule of Composition If ~-P{QdR1and ~-R~{Q2}Rthen ~-P{ (Q~ ;

y<rdo

(r:=r--y;

q:=

l+q))

An important property of this program is t h a t when it terminates, we can recover the numerator x by adding to the remainder r the product of the divisor y and the quotient q (i.e. x = r + y X q). Furthermore, the remainder is less than the divisor. These properties may be expressed formally:
true{Q} ~y ~< r A x = r+ yX q

Q2)}R

3.4. RvL~ OF ITERATION The essential feature of a stored program computer is the ability to execute some portion of program (S) repeatedly until a condition (B) goes false. A simple way of expressing such an iteration is to adapt the ALGOL 60 w h i l e notation:
while B do S

where Q stands for the program displayed above. This expresses a necessary (but not sufficient) condition for the "correctness" of the program. A formal proof of this theorem is given in Table III. Like all formal proofs, it is excessively tedious, and it would be fairly easy to introduce notational conventions which would significantly shorten it. An even more powerful method of reducing the tedium of formal proofs is to derive general rules for proof construction out of the simple rules accepted as postulates. These general rules would be shown to be valid by demonstrating how every theorem proved with their assistance could equally well (if more tediously) have been proved without. Once a powerful set of supplementary rules has been developed, a "formal proof" reduces to little more than an informal indication of how a formal proof could be constructed.
4. General Reservations

In executing this statement, a computer first tests the condition B. If this is false, S is omitted, and execution of the loop is complete. Otherwise, S is executed and B is tested again. This action is repeated until B is found to be false. The reasoning which leads to a formulation of an inference rule for iteration is as follows. Suppose P to be an assertion which is always true on completion of S, provided t h a t it is also true on initiation. Then obviously P will still be true after any number of iterations of the statement S (even 578
C o m m u n i c a t i o n s of t h e ACM

The axioms and rules of inference quoted in this paper have implicitly assumed the absence of side effects of the evaluation of expressions and conditions. In proving properties of programs expressed in a language permitting side effects, it would be necessary to prove their absence in each ease before applying the appropriate proof technique. If the main purpose of a high level programming language is to assist in the construction and verification of correct programs, it is doubtful whether the use of functional notation to call procedures with side effects is a genuine advantage. Another deficiency in the axioms and rules quoted above Volume 12 / Number 10 / October, 1969

is that they give no basis for a proof that a program successfully terminates. Failure to terminate may be due to an infinite loop; or it may be due to violation of an implementation-defined limit, for example, the range of numeric operands, the size of storage, or an operating system time limit. Thus the notation "PIQ}R" should be interpreted "provided t h a t the program successfully terminates, the properties of its results are described by R." I t is fairly easy to adapt the axioms so that they cannot be used to predict the "results" of nonterminating programs; but the actual use of the axioms would now depend on knowledge of many implementation-dependent features, for example, the size and speed of the computer, the range of numbers, and the choice of overflow technique. Apart from proofs of the avoidance of infinite loops, it is probably better to prove the "conditional" correctness of a program and rely on an implementation to give a warning if it has had to

abandon execution of the program as a result of violation of an implementation limit. Finally it is necessary to list some of the areas which have not been covered: for example, real arithmetic, bit and character manipulation, complex arithmetic, fractional arithmetic, arrays, records, overlay definition, files, i n p u t / output, declarations, subroutines, parameters, recursion, and parallel execution. Even the characterization of integer arithmetic is far from complete. There does not appear to be any great difficulty in dealing with these points, provided that the programming language is kept simple. Areas which do present real difficulty are labels and jumps, pointers, and name parameters. Proofs of programs which made use of these features are likely to be elaborate, and it is not surprising that this should be reflected in the complexity of the underlying axioms.
5. Proofs of Program Correctness



NOTES i. The left hand column is used to number the lines, and the right hand column to justify each line, by appealing to an axiom, a l e m m a or a rule of inference applied to one or two previous

lines, indicated in brackets. Neither of these columns is part of the formal proof. For example, line 2 is an instance of the axiom of assignment (DO); line 12 is obtained from lines 5 and 11 by application of the rule of composition (D2). 2. Lemma 1 may be proved from axioms A7 and AS. 3. Lemma 2 follows directly from the theorem proved in See. 2.
Volume

The most important property of a program is whether it accomplishes the intentions of its user. If these intentions can be described rigorously by making assertions about the values of variables at the end (or at intermediate points) of the execution of the program, then the techniques described in this paper may be used to prove the correctness of the program, provided that the implementation of the programming language conforms to the axioms and rules which have been used in the proof. This fact itself might also be established by deductive reasoning, using an axiom set which describes the logical properties of the hardware circuits. When the correctness of a program, its compiler, and the hardware of the computer have all been established with mathematical certainty, it will be possible to place great reliance on the results of the program, and predict their properties with a confidence limited only by the reliability of the electronics. The practice of supplying proofs for nontrivial programs will not become widespread until considerably more powerful proof techniques become available, and even then will not be easy. But the practical advantages of program proving will eventually outweigh the difficulties, in view of the increasing costs of programming error. At present, the method which a programmer uses to convince himself of the correctness of his program is to try it out in particular cases and to modify it if the results produced do not correspond to his intentions. After he has found a reasonably wide variety of example cases on which the program seems to work, he believes that it will always work. The time spent in this program testing is often more than half the time spent on the entire programming project; and with a realistic costing of machine time, two thirds (or more) of the cost of the project is involved in removing errors during this phase. The cost of removing errors discovered after a program has gone into use is often greater, particularly in the case of items of computer manufacturer's software for which a large part of the expense is borne by the user. And finally, the cost of error in certain types of program may be almost
Communications
of the ACM

12 / N u m b e r

10 / O c t o b e r , 1969

579

inealculable--a lost spacecraft, a collapsed building, a crashed aeroplane, or a world war. Thus the practice of program proving is not only a theoretical pursuit, followed in the interests of academic respectability, but a serious recommendation for the reduction of the costs associated with programming error. The practice of proving programs is likely to alleviate some of the other problems which afflict the computing world. For example, there is the problem of program documentation, which is essential, firstly, to inform a potential user of a subroutine how to use it and what it accomplishes, and secondly, to assist in further development when it becomes necessary to update a program to meet changing circumstances or to improve it in the light of increased knowledge. The most rigorous method of formulating the purpose of a subroutine, as well as the conditions of its proper use, is to make assertions about the values of variables before and after its execution. The proof of the correctness of these assertions can then be used as a lemmain the proof of any program which calls the subroutine. Thus, in a large program, the structure of the whole can be clearly mirrored in the structure of its proof. Furthermore, when it becomes necessary to modify a program, it will always be valid to replace any subroutine by another which satisfies the same criterion of correctness. Finally, when examining the detail of the algorithm, it seems probable that the proof will be helpful in explaining not only what is happening but why. Another problem which can be solved, insofar as it is soluble, by the practice of program proofs is that of transferring programs from one design of computer to another. Even when written in a so-called machine-independent programming language, many large programs inadvertently take advantage of some machine-dependent property of a particular implementation, and unpleasant and expensive surprises can result when attempting to transfer it to another machine. However, presence of a machinedependent feature will always be revealed in advance by the fMlure of an attempt to prove the program from machine-independent axioms. The programmer will then have the choice of formulating his algorithm in a machineindependent fashion, possibly with the help of environment enquiries; or if this involves too much effort or inefficiency, he can deliberately construct a machine-dependent program, and rely for his proof on some machine-dependent axiom, for example, one of the versions of A11 (Section 2). I n the latter case, the axiom must be explicitly quoted as one of the preconditions of successful use of the program. The program can still, with complete confidence, be transferred to any other machine which happens to satisfy the same machine-dependent axiom; but if it becomes necessary to transfer it to an implementation which does not, then all the places where changes are required[will be clearly annotated by the fact that the proof at that point appeals to the t r u t h of the offending machine-dependent axiom. Thus the practice of proving programs would seem to 580 Communications of the ACM

lead to solution of three of the most pressing problems in software and programming, namely, reliability, documentation, and compatibility. However, program proving, certainly at present, will be difficult even for programmers of high caliber; and may be applicable only to quite simple program designs. As in other areas, reliability can be purchased only at the price of simplicity.

6.

Formal Language Definition

A high level programming language, such as ALc~oL, FORTRAN, or COBOL, is usually intended to be implemented on a variety of computers of differing size, configuration, and design. I t has been found a serious problem to define these languages with sufficient rigour to ensure compatibility among all implementors. Since the purpose of compatibility is to facilitate interchange of programs expressed in the language, one way to achieve this would be to insist that all implementations of the language shall "satisfy" the axioms and rules of inference which underlie proofs of the properties of programs expressed in the language, so t h a t all predictions based on these proofs will be fulfilled, except in the event of hardware failure. In effect, this is equivalent to accepting the axioms and rules of inference as the ultimately definitive specification of the meaning of the language. Apart from giving an immediate and possibly even provable criterion for the correctness of an implementation, the axiomatic technique for the definition of programming language semantics appears to be like the formal syntax of the ALaOL 60 report, in that it is sufficiently simple to be understood both by the implementor and by the reasonably sophisticated user of the language. I t is only by bridging this widening communication gap in a single document (perhaps even provably consistent) that the maximum advantage can be obtained from a formal language definition. Another of the great advantages of using an axiomatic approach is that axioms offer a simple and flexible technique for leaving certain aspects of a language undefined, for example, range of integers, accuracy of floating point, and choice of overflow technique. This is absolutely essential for standardization purposes, since otherwise the language will be impossible to implement efficiently on differing hardware designs. Thus a programming language standard should consist of a set of axioms of universal applicability, together with a choice from a set of supplementary axioms describing the range of choices facing an implementor. An example of the use of axioms for this purpose was given in Section 2. Another of the objectives of formal language definition is to assist in the design of better programming languages. The regularity, clarity, and ease of implementation of the ALGOL 60 syntax may at least in part be due to the use of an elegant formal technique for its definition. The use of axioms may lead to similar advantages in the area of "semantics," since it seems likely that a language which can
(Continued on p. 583)

Volume 12 / Number 10 / October, 1969

by Lowe. In addition, we define F(j) = ~ = ~ f(i) and write Ix] for the greatest integer not exceeding x. In a packed list file, the bucket which contains the first element of list j will have its first

since ~ f = l p(j) = 1. Equation (2) corresponds to (11) in [1]. The assumptions on f(j) and p(j) in [1] may be substituted into (2). The first 
positions occupied by lists j - 1, j - 2, . . . . For any practical file, when j is not a small integer, (1) behaves as a random variable uniformly distributed between 0 and C. In other words, the start of a list is independent of bucket boundaries. It is easy to see that the expected number of accesses required to retrieve list j is f ( j ) / C ~ 1. Hence we have
T, = t~ (f(j)/C + 1)p(j) ,

and the third assumption, for large N, yields approximately

T~/t~ = 1 + (lnN + ~)-2~-V6.

(4)

These equations should be compared with the right-hand inequalities of (13) and (24) in [1].
RECEIVED MARCH REFERENCES

1969; REVISED

JUNE 1969

(2)
.'.

T,/t, -- 1 + ~

f(j)p(j)/C,

1. LOWE, THOMAS C. The influence of data-base characteristics and usage on direct-access file organization. J . A C M 15, 4 (Oct. 1968), 535-548.

A

C. A. R. HOARE--cont'd from page 5 8 0
be described by a few "self-evident" axioms from which proofs will be relatively easy to construct will be preferable to a language with many obscure axioms which are difficult to apply in proofs. Furthermore, axioms enable the language designer to express his general intentions quite simply and directly, without the mass of detail which usually accompanies algorithmic descriptions. Finally, axioms can be formulated in a manner largely independent of each other, so that the designer can work freely on one axiom or group of axioms without fear of unexpected interaction effects with other parts of the language.

language undefined; (2) a comprehensive evaluation of the possible benefits to be gained by adopting this approach both for program proving and for formal language definition. However, the formal material presented here has only an expository status and represents only a minute proportion of what remains to be done. It is hoped that many of the fascinating problems involved will be taken up by others.
RECEIVED NOVEMBER,

1968; REVISED
REFERENCES

MAY,

1969

Acknowledgments. Many axiomatic treatments of computer programming [1, 2, 3] tackle the problem of proving the equivalence, rather than the correctness, of algorithms. Other approaches [4, 5] take recursive functions rather than programs as a starting point for the theory. The suggestion to use axioms for defining the primitive operations of a computer appears in [6, 7]. The importance of program proofs is clearly emphasized in [9], and an informal technique for providing them is described. The suggestion that the specification of proof techniques provides an adequate formal definition of a programming language first appears in [8]. The formal treatment of program execution presented in this paper is clearly derived from Floyd. The main contributions of the author appear to be: (1) a suggestion that axioms may provide a simple solution to the problem of leaving certain aspects of a
V o l u m e 12 / N u m b e r 10 / October, 1969

i. YANOV, Yu I. Logical operator schemes. Kybernetika I, (1958). 2. IGARASHI, S. An axiomatic approach to equivalence problems of algorithms with applications. Ph.D. Thesis 1964. Rep. Compt. Centre, U. Tokyo, 1968, pp. i-I01. 3. DE BAKICER, J. W. Axiomatics of simple assignment statements. M.R. 94, Mathematisch Centrum, Amsterdam, June 1968. 4. McCARTHY, J. Towards a mathematical theory of computation. Proc. IFIP Cong. 1962, North Holland Pub. Co., Amsterdam, 1963. 5. BURSTALL,R. Proving properties of programs by structural induction. Experimental Programming Reports: No. 17 DMIP, Edinburgh, Feb. 1968. 6. VAN WIJNGAARDEN, A. Numerical analysis as an independent science. B I T 6 (1966), 66-81. 7. LASKI, J. Sets and other types. ALGOL Bull. 27, 1968. 8. FLOYD, R. W. Assigning meanings to programs. Proc. Amer. Math. Soc. Symposia in Applied Mathematics, Vol. 19, pp. 19-31. 9. N~_uR, P. Proof of algorithms by general snapshots. B I T 6 (1966), 310-316.
C o m m u n i c a t i o n s of t h e ACM

583

Survey of the State of the Art in Human Language Technology
Editorial Board: Ronald A. Cole, Editor in Chief Joseph Mariani Hans Uszkoreit Annie Zaenen Victor Zue Managing Editors: Giovanni Varile Antonio Zampolli

Sponsors: National Science Foundation Directorate XIII-E of the Commission of the European Communities Center for Spoken Language Understanding, Oregon Graduate Institute
Forewords

Foreword by the Editor in Chief
The field of human language technology covers a broad range of activities with the eventual goal of enabling people to communicate with machines using natural communication skills. Research and development activities include the coding, recognition, interpretation, translation, and generation of language. The study of human language technology is a multidisciplinary enterprise, requiring expertise in areas of linguistics, psychology, engineering and computer science. Creating machines that will interact with people in a graceful and natural way using language requires a deep understanding of the acoustic and symbolic structure of language (the domain of linguistics), and the mechanisms and strategies that people use to communicate with each other (the domain of psychology). Given the remarkable ability of people to converse under adverse conditions, such as noisy social gatherings or band-limited communication channels, advances in signal processing are essential to produce robust systems (the domain of electrical engineering). Advances in computer science are needed to create the architectures and platforms needed to represent and utilize all of this knowledge. Collaboration among researchers in each of these areas is needed to create multimodal and multimedia systems that combine speech, facial cues and gestures both to improve language understanding and to produce more natural and intelligible speech by animated characters. Human language technologies play a key role in the age of information. Today, the benefits of information and services on computer networks are unavailable to those without access to computers or the skills to use them. As the importance of interactive networks increases in commerce and daily life, those who do not have access to computers or the skills to use them are further handicapped from becoming productive members of society. Advances in human language technology offer the promise of nearly universal access to on-line information and services. Since almost everyone speaks and understands a language, the development of spoken language systems will allow the average xi

xii person to interact with computers without special skills or training, using common devices such as the telephone. These systems will combine spoken language understanding and generation to allow people to interact with computers using speech to obtain information on virtually any topic, to conduct business and to communicate with each other more effectively. Advances in the processing of speech, text and images are needed to make sense of the massive amounts of information now available via computer networks. A student's query: "Tell me about global warming," should set in motion a set of procedures that locate, organize and summarize all available information about global warming from books, periodicals, newscasts, satellite images and other sources. Translation of speech or text from one language to another is needed to access and interpret all available material and present it to the student in her native language. This book surveys the state of the art of human language technology. The goal of the survey is to provide an interested reader with an overview of the field--the main areas of work, the capabilities and limitations of current technology, and the technical challenges that must be overcome to realize the vision of graceful human computer interaction using natural communication skills. The book consists of thirteen chapters written by 97 different authors. In order to create a coherent and readable volume, a great deal of effort was expended to provide consistent structure and level of presentation within and across chapters. The editorial board met six times over a two-year period. During the first two meetings, the structure of the survey was defined, including topics, authors, and guidelines to authors. During each of the final four meetings (in four different countries), each author's contribution was carefully reviewed and revisions were requested, with the aim of making the survey as inclusive, up-to-date and internally consistent as possible. This book is due to the efforts of many people. The survey was the brainchild of Oscar Garcia (then program director at the National Science Foundation in the United States), and Antonio Zampolli, professor at the University of Pisa, Italy. Oscar Garcia and Mark Liberman helped organize the survey and participated in the selection of topics and authors; their insights and contributions to the survey are gratefully acknowledged. I thank all of my colleagues on the editorial board, who dedicated remarkable amounts of time and effort to the survey. I am particularly grateful to Joseph Mariani for his diligence and support during the past two years, and to Victor Zue for his help and guidance throughout this project. I thank Hans Uszkoreit and Antonio Zampolli for their help in finding publishers. The survey owes much to the efforts of Vince Weatherill, the production editor, who worked with the editorial board and the authors to put the survey together, and to Don Colton, who indexed the book several times and copyedited much of it. Finally, on behalf of the editorial board, we thank the authors of this survey, whose talents and patience were responsible for the quality of this product. The survey was supported by a grant from the National Science Foundation to Ron Cole, Victor Zue and Mark Liberman, and by the European Commission. Additional support was provided by the Center for Spoken Language Understanding at the Oregon Graduate Institute and the University of Pisa, Italy. Ron Cole Poipu Beach

xiii Kauii, Hawaii, USA January 31, 1996

xiv

Foreword by the Former Program Manager of the National Science Foundation
This book is the work of many different individuals whose common bond is the love for the understanding and use of spoken language between humans and with machines. I was fortunate enough to have been included in this community through the work of one of my students, Alan Goldschen, who brought to my attention almost a decade ago the intriguing problem of lipreading. Our unfinished quest for a machine which could recognize speech more robustly via acoustic and optical channels was my original motivation for entering the wide world of spoken language research so richly exemplified in this book. I have been credited with producing the small spark which began this truly joint international work via a small National Science Foundation (NSF) award, and a parallel one abroad, while I was a rotating program officer in the Computer and Information Science and Engineering Directorate. We should remember that the International Division of NSF also contributed to the work of U.S. researchers, as did the European Commission for others in Europe. The spark occurred at a dinner meeting convened by George Doddington, then of ARPA, during the 1993 Human Language Technology Workshop at the Merril Lynch Conference Center in New Jersey. I made the casual remark to Antonio Zampolli that I thought it would be interesting and important to summarize, in a unifying piece of work, the most significant research taking place worldwide in this field. Mark Liberman, present at the dinner, was also very receptive to the concept. Zampolli heartily endorsed the idea and took it to Nino Varile of the European Commission's DG XIII. I did the same and presented it to my boss at the NSF, the very supportive Y. T. Chien, and we proceeded to recruit some likely suspects for the enormous job ahead. Both Nino and Y. T. were infected with the enthusiasm to see this work done. The rest is history, mostly punctuated by fascinating "editorial board" meetings and the gentle but unforgiving prodding of Ron Cole. Victor Zue was, on my side, a pillar of technical strength and a superb taskmaster. Among the European contributors who distinguished themselves most in the work, and there were several including Annie Zaenen and Hans Uszkoreit, from my perspective, it was Joseph Mariani with his group at the Human-Machine Communication at LIMSI/CNRS, who brought to my attention the tip of the enormous iceberg of research in Europe on speech and language, making it obvious to me that the state-of-the-art survey must be done. ¿From a broad perspective point of view it is not surprising that this daunting task has taken so much effort: witness the wide range of topics related to language research ranging from generation and perception to higher level cognitive functions. The thirteen chapters that have been produced are a testimony of the depth and width of research that is necessary to advance the field. I feel gratified by the contributions of people with such a variety of backgrounds and I feel particularly happy that Computer Scientists and Engineers are becoming more aware of this, making significant contributions. But in spite of the excellent work done in reporting, the real task ahead remains: the deployment of reliable and robust systems which are usable in a broad range of applications, or as I like to call it "the cosumerization of speech technology." I personally consider the spoken language challenge one of the most difficult problems among the

xv scientific and engineering inquiries of our time, but one that has an enormous reward to be received. Gordon Bell, of computer architecture fame, once confided that he had looked at the problem, thought it inordinately difficult, and moved on to work in other areas. Perhaps this survey will motivate new Gordon Bells to dig deeper into research in human language technology. Finally, I would like to encourage any young researcher reading this survey to plunge into the areas of most significance to them, but in an unconventional and brash manner, as I feel we did in our work in lipreading. Deep knowledge of the subject is, of course, necessary but the boundaries of the classical work should not be limiting. I feel strongly that there is need and room for new and unorthodox approaches to humancomputer dialogue that will reap enormous rewards. With the advent of world-wide networked graphical interfaces there is no reason for not including the speech interactive modality in it, at great benefit and relatively low cost. These network interfaces may further erode the international barriers which travel and other means of communications have obviously started to tear down. Interfacing with computers sheds much light on how humans interact with each other, something that spoken language research has taught us. The small NSF grant to Ron Cole, I feel, has paid magnified results. The resources of the original sponsors have been generously extended by those of the Center for Spoken Language Understanding at the Oregon Graduate Institute, and their personnel, as well as by the University of Pisa. From an ex-program officer's point of view in the IRIS Division at NSF this grant has paid great dividends to the scientific community. We owe an accolade to the principal investigator's Herculean efforts and to his cohorts at home and abroad. Oscar N. Garcia Wright State University Dayton, Ohio

xvi

Foreword by the Managing Editors1
Language Technology and the Information Society
The information age is characterized by a fast growing amount of information being made available either in the public domain or commercially. This information is acquiring an increasingly important function for various aspects of peoples' professional, social and private life, posing a number of challenges for the development of the Information Society. In particular, the classical notion of universal access needs to be extended beyond the guarantee for physical access to the information channels, and adapted to cover the rights for all citizens to benefit from the opportunity to easily access and effectively process information. Furthermore, with the globalization of the economy, business competitiveness rests on the ability to effectively communicate and manage information in an international context. Obviously, languages, communication and information are closely related. Indeed, language is the prime vehicle in which information is encoded, by which it is accessed and through which it is disseminated. Language technology offers people the opportunity to better communicate, provides them with the possibility of accessing information in a more natural way, supports more effective ways of exchanging information and control its growing mass. There is also an increasing need to provide easy access to multilingual information systems and to offer the possibility to handle the information they carry in a meaningful way. Languages for which no adequate computer processing is being developed, risk gradually losing their place in the global Information Society, or even disappearing, together with the cultures they embody, to the detriment of one of humanity's great assets: its cultural diversity.

What Can Language Technology Offer?
Looking back, we see that some simple functions provided by language technology have been available for some time--for instance spelling and grammar checking. Good progress has been achieved and a growing number of applications are maturing every day, bringing real benefits to citizens and business. Language technology is coming of age and its deployment allows us to cope with increasingly difficult tasks. Every day new applications with more advanced functionality are being deployed-- for instance voice access to information systems. As is the case for other information technologies, the evolution towards more complex language processing systems is rapidly accelerating, and the transfer of this technology to the market is taking place at an increasing pace. More sophisticated applications will emerge over the next years and decades and find their way into our daily lives. The range of possibilities is almost unlimited. Which
1 The ideas expressed herein are the authors' and do not reflect the policies of the European Commission and the Italian National Research Council.

xvii ones will be more successful will be determined by a number of factors, such as technological advances, market forces, and political will. On the other hand, since sheer mass of information and high bandwidth networks are not sufficient to make information and communication systems meaningful and useful, the main issue is that of an effective use of new applications by people, which interact with information systems and communicate with each other. Among the many issues to be addressed are difficult engineering problems and the challenge of accounting for the functioning of human languages--probably one of the most ambitious and difficult tasks. Benefits that can be expected from deploying language technology are a more effective usability of systems (enabling the user) and enhanced capabilities for people (empowering the user). The economic and social impact will be in terms of efficiency and competitiveness for business, better educated citizens, and a more cohesive and sustainable society. A necessary precondition for all this, is that the enabling technology be available in a form ready to be integrated into applications. The subject of the thirteen chapters of this Survey are the key language technologies required for the present applications and research issues that need to be addressed for future applications.

Aim and Structure of the Book
Given the achievements so far, the complexity of the problem, and the need to use and to integrate methods, knowledge and techniques provided by different disciplines, we felt that the time was ripe for a reasonably detailed map of the major results and open research issues in language technology. The Survey offers, as far as we know, the first comprehensive overview of the state of the art in spoken and written language technology in a single volume. Our goal has been to present a clear overview of the key issues and their potential impact, to describe the current level of accomplishments in scientific and technical areas of language technology, and to assess the key research challenges and salient research opportunities within a five- to ten-year time frame, identifying the infrastructure needed to support this research. We have not tried to be encyclopedic; rather, we have striven to offer an assessment of the state of the art for the most important areas in language processing. The organization of the Survey was inspired by three main principles: an accurate identification of the key work areas and sub-areas of each of the fields;
     

a well-structured multi-layered organization of the work, to simplify the coordination between the many contributors and to provide a framework in which to carry out this international cooperation; a granularity and style that, given the variety of potential readers of the Survey, would make it accessible to non-specialist and at the same time to serve for specialists, as a reference for areas not directly of their own expertise.

xviii Each of the thirteen chapters of the Survey consists of: an introductory overview providing the general framework for the area concerned, with the aim of facilitating the understanding and assessment of the technical contributions;
   

a number of sections, each dealing with the state of the art, for a given subarea, i.e., the major achievements, the methods and the techniques available, the unsolved problems, and the research challenges for the future.

For ease of reference, the reader may find it useful to refer to the analytical index given at the end of the book. We hope the Survey will be a useful reference to both non-specialists and practitioners alike, and that the comments received from our readers will encourage us to edit updated and improved versions of this work.

Relevance of International Collaboration
This Survey is the result of international collaboration, which is especially important for the progress of language technology and the success of its applications, in particular those aiming at providing multilingual information or communication services. Multilingual applications require close coordination between the partners of different languages to ensure the interoperability of components and the availability of the necessary linguistic data--spoken and written corpora, lexica, terminologies, and grammars. The major national and international funding agencies play a key role in organizing the international cooperation. They are currently sponsoring major research activities in language processing through programs that define the objectives and support the largest projects in the field. They have undertaken the definition of a concrete policy for international cooperation2 that takes into account the specific needs and the strategic value of language technology. Various initiatives have, in the past ten years, contributed to forming the cooperative framework in which this Survey has been organized. One such initiative was the workshop on `Automating the Lexicon' held in Grosseto, Italy, in 1986, which involved North American and European specialists, and resulted in recommendations for an overall coordination in building reusable large scale resources. Another one took place in Turin, Italy, in 1991, in the framework of international cooperation agreement between the NSF and the ESPRIT programme of the European Commission. The experts convened at that meeting called for cooperation in building reusable language resources, integration between spoken and written language technology--in particular the development of methods for combining rule-based and stochastic techniques--and an assessment of the state of the art. A special event convening representatives of American, European and Japanese sponsoring agencies was organized at COLING 92 and has since become a permanent
2 Several international cooperation agreements in science and technology are currently in force; more are being negotiated.

xix feature of this bi-annual conference. For this event, an overview 3 of some of the major American, European and Japanese projects in the field was compiled. The present Survey is the most recent in a series of cooperative initiatives in language technology.

Acknowledgements
We wish to express our gratitude to all those who, in their different capacities, have made this Survey possible, but first of all the authors who, on a voluntary basis, have accepted our invitation, and have agreed to share their expert knowledge to provide an overview for their area of expertise. Our warmest gratitude goes to Oscar Garcia, who co-inspired the initiative and was an invaluable colleague and friend during this project. Without his scientific competence, management capability, and dedicated efforts, this Survey would not have been realized. His successor, Gary Strong, competently and enthusiastically continued his task. Thanks also to the commitment and dedication of the editorial board consisting of Joseph Mariani, Hans Uszkoreit, Annie Zaenen and Victor Zue. Our deep-felt thanks to Ron Cole, who coordinated the board's activities and came to serve as the volume's editor-in-chief. Mark Liberman, of the University of Pennsylvania and initially member of the editorial board, was instrumental in having the idea of this Survey approved, and his contribution to the design of the overall content and structure was essential. Unfortunately, other important tasks called him in the course of this project. Invaluable support to this initiative has been provided by Y.T. Chien, the director of the Computer and Information Science and Engineering Directorate of the National Science Foundation, Vincente Parajon-Collada, the deputy-director general of Directorate General XIII of the European Commission, and Roberto Cencioni head of Language Engineering sector of the Telematics Application Programme. Vince Weatherill, of Oregon Graduate Institute, dedicated an extraordinary amount of time, care and energy to the preparation and editing of the Survey. Colin Brace carried out the final copyediting work within an extremely short time schedule. The University of Pisa, Italy, the Oregon Graduate Institute, and the Institute of Computational Linguistics of the Italian National Research Council generously contributed financial and human resources. Antonio Zampolli Giovanni Battista Varile

3 Synopses of American, European and Japanese Projects Presented at the International Projects Day at COLING 1992. In: Linguistica Computazionale, volume VIII, Giovanni Battista Varile and Antonio Zampolli, editors, Giardini, Pisa. ISSN 0392-6907 (out of print). This volume was the direct antecedent of and the inspiration for the present survey.

Chapter 1

Spoken Language Input
1.1 Overview
Victor Zue & Ron Cole
MIT Laboratory for Computer Science, Cambridge, Massachusetts, USA Oregon Graduate Institute of Science & Technology, Portland, Oregon, USA
£   ¢ ¡

Spoken language interfaces to computers is a topic that has lured and fascinated engineers and speech scientists alike for over five decades. For many, the ability to converse freely with a machine represents the ultimate challenge to our understanding of the production and perception processes involved in human speech communication. In addition to being a provocative topic, spoken language interfaces are fast becoming a necessity. In the near future, interactive networks will provide easy access to a wealth of information and services that will fundamentally affect how people work, play and conduct their daily affairs. Today, such networks are limited to people who can read and have access to computers--a relatively small part of the population, even in the most developed countries. Advances in human language technology are needed to enable the average citizen to communicate with networks using natural communication skills and everyday devices, such as telephones and televisions. Without fundamental advances in user-centered interfaces, a large portion of society will be prevented from participating in the age of information, resulting in further stratification of society and tragic loss of human potential. The first chapter in this survey deals with spoken language input technologies. A speech interface, in a user's own language, is ideal because it is the most natural, flexible, efficient, and economical form of human communication. The following sections summarize spoken input technologies that will facilitate such an interface. Spoken input to computers embodies many different technologies and applications, as illustrated in Figure 1.1. In some cases, as shown at the bottom of the figure, one is interested not in the underlying linguistic content but in the identity of the speaker or the language being spoken. Speaker recognition can involve identifying a specific speaker out of a known population, which has forensic implications, or verifying the claimed 1

2

Chapter 1: Spoken Language Input

identity of a user, thus enabling controlled access to locales (e.g., a computer room) and services (e.g., voice banking). Speaker recognition technologies are addressed in section 1.7. Language identification also has important applications, and techniques applied to this area are summarized in section 8.7. When one thinks about speaking to computers, the first image is usually speech recognition, the conversion of an acoustic signal to a stream of words. After many years of research, speech recognition technology is beginning to pass the threshold of practicality. The last decade has witnessed dramatic improvement in speech recognition technology, to the extent that high performance algorithms and systems are becoming available. In some cases, the transition from laboratory demonstration to commercial deployment has already begun. Speech input capabilities are emerging that can provide functions like voice dialing (e.g., Call home), call routing (e.g., I would like to make a collect call), simple data entry (e.g., entering a credit card number), and preparation of structured documents (e.g., a radiology report). The basic issues of speech recognition, together with a summary of the state of the art, is described in section 1.2. As these authors point out, speech recognition involves several component technologies. First, the digitized signal must be transformed into a set of measurements. This signal representation issue is elaborated in section 1.3. Section 1.4 discusses techniques that enable the system to achieve robustness in the presence of transducer and environmental variations, and techniques for adapting to these variations. Next, the various speech sounds must be modeled appropriately. The most widespread technique for acoustic modeling is called hidden Markov modeling (HMM), and is the subject of section 1.5. The search for the final answer involves the use of language constraints, which is covered in section 1.6. Speech recognition is a very challenging problem in its own right, with a well defined set of applications. However, many tasks that lend themselves to spoken input-- making travel arrangements or selecting a movie--are in fact exercises in interactive problem solving. The solution is often built up incrementally, with both the user and the computer playing active roles in the "conversation." Therefore, several languagebased input and output technologies must be developed and integrated to reach this goal. Figure 1.1 shows the major components of a typical conversational system. The spoken input is first processed through the speech recognition component. The natural language component, working in concert with the recognizer, produces a meaning representation. The final section of this chapter on spoken language understanding technology, section 1.8, discusses the integration of speech recognition and natural language processing techniques. For information retrieval applications illustrated in this figure, the meaning representation can be used to retrieve the appropriate information in the form of text, tables and graphics. If the information in the utterance is insufficient or ambiguous, the system may choose to query the user for clarification. Natural language generation and speech synthesis, covered in chapters 4 and 5 respectively, can be used to produce spoken responses that may serve to clarify the tabular information. Throughout the process, discourse information is maintained and fed back to the speech recognition and language understanding components, so that sentences can be properly understood in context.

1.2 Speech Recognition
Sentence

3

Speech

SPEECH SYNTHESIS Graphs & Tables

LANGUAGE GENERATION

SYSTEM MANAGER

DATABASE

DISCOURSE CONTEXT

Meaning Representation

Speech

SPEECH RECOGNITION Words SPEAKER RECOGNITION

LANGUAGE UNDERSTANDING

LANGUAGE RECOGNITION

Figure 1.1: Technologies for spoken language interfaces.

1.2 Speech Recognition
MIT Laboratory for Computer Science, Cambridge, Massachusetts, USA Oregon Graduate Institute of Science & Technology, Portland, Oregon, USA Carnegie Mellon University, Pittsburgh, Pennsylvania, USA
£  

Victor Zue, Ron Cole, & Wayne Ward
  ¡ ¢

1.2.1 Defining the Problem
Speech recognition is the process of converting an acoustic signal, captured by a microphone or a telephone, to a set of words. The recognized words can be the final results, for such applications as commands & control, data entry, and document preparation. They can also serve as the input to further linguistic processing in order to achieve speech understanding, a subject covered in section 1.8. Speech recognition systems can be characterized by many parameters, some of the more important of which are shown in Figure 1.1. An isolated-word speech recognition

¡

4

Chapter 1: Spoken Language Input

system requires that the speaker pause briefly between words, whereas a continuous speech recognition system does not. Spontaneous, or extemporaneously generated, speech contains disfluencies and is much more difficult to recognize than speech read from script. Some systems require speaker enrollment--a user must provide samples of his or her speech before using them--whereas other systems are said to be speakerindependent, in that no enrollment is necessary. Some of the other parameters depend on the specific task. Recognition is generally more difficult when vocabularies are large or have many similar-sounding words. When speech is produced in a sequence of words, language models or artificial grammars are used to restrict the combination of words. The simplest language model can be specified as a finite-state network, where the permissible words following each word are explicitly given. More general language models approximating natural language are specified in terms of a context-sensitive grammar. One popular measure of the difficulty of the task, combining the vocabulary size and the language model, is perplexity, loosely defined as the geometric mean of the number of words that can follow a word after the language model has been applied (see section 1.6 for a discussion of language modeling in general and perplexity in particular). In addition, there are some external parameters that can affect speech recognition system performance, including the characteristics of the environmental noise and the type and the placement of the microphone. Parameters Speaking Mode Speaking Style Enrollment Vocabulary Language Model Perplexity SNR Transducer Range Isolated words to continuous speech Read speech to spontaneous speech Speaker-dependent to Speaker-independent Small ( 20 words) to large (¡ 20,000 words) Finite-state to context-sensitive Small ( 10) to large (¡ 100) High (¡ 30 dB) to low ( 10 dB) Voice-cancelling microphone to telephone
     

Table 1.1: Typical parameters used to characterize the capability of speech recognition systems Speech recognition is a difficult problem, largely because of the many sources of variability associated with the signal. First, the acoustic realizations of phonemes, the smallest sound units of which words are composed, are highly dependent on the context in which they appear. These phonetic variabilities are exemplified by the acoustic differences of the phoneme1 /t/ in two, true, and butter in American English. At word boundaries, contextual variations can be quite dramatic--making gas shortage sound like gash shortage in American English, and devo andare sound like devandare in Italian.
1 Linguistic symbols presented between slashes, e.g., /p/, /t/, /k/, refer to phonemes [the minimal sound unit by changing it one changes the meaning of a word]. The acoustic realizations of phonemes in speech are referred to as allophones, phones, or phonetic segments, and are presented in brackets, e.g., [p], [t], [k].

1.2 Speech Recognition

5

Second, acoustic variabilities can result from changes in the environment as well as in the position and characteristics of the transducer. Third, within-speaker variabilities can result from changes in the speaker's physical and emotional state, speaking rate, or voice quality. Finally, differences in sociolinguistic background, dialect, and vocal tract size and shape can contribute to across-speaker variabilities. Figure 1.2 shows the major components of a typical speech recognition system. The digitized speech signal is first transformed into a set of useful measurements or features at a fixed rate, typically once every 10­20 msec (see sections 1.3 and 11.3 for signal representation and digital signal processing, respectively). These measurements are then used to search for the most likely word candidate, making use of constraints imposed by the acoustic, lexical, and language models. Throughout this process, training data are used to determine the values of the model parameters.

Training Data

Acoustic Models Speech Signal Representation

Lexical Models

Language Models Recognized Words Search

Modeling/ Classification

Figure 1.2: Components of a typical speech recognition system. Speech recognition systems attempt to model the sources of variability described above in several ways. At the level of signal representation, researchers have developed representations that emphasize perceptually important speaker-independent features of the signal, and de-emphasize speaker-dependent characteristics (Hermansky, 1990). At the acoustic phonetic level, speaker variability is typically modeled using statistical techniques applied to large amounts of data. Speaker adaptation algorithms have also been developed that adapt speaker-independent acoustic models to those of the current speaker during system use (see section 1.4). Effects of linguistic context at the acoustic phonetic level are typically handled by training separate models for phonemes in different contexts; this is called context dependent acoustic modeling. Word level variability can be handled by allowing alternate pronunciations of words in representations known as pronunciation networks. Common alternate pronunciations of words, as well as effects of dialect and accent are handled by allowing search algorithms to find alternate paths of phonemes through these networks. Statistical language models, based on estimates of the frequency of occurrence of word sequences, are often used to guide the search through the most probable sequence of words. The dominant recognition paradigm in the past fifteen years is known as hidden Markov models (HMM). An HMM is a doubly stochastic model, in which the gener-

6

Chapter 1: Spoken Language Input

ation of the underlying phoneme string and the frame-by-frame, surface acoustic realizations, are both represented probabilistically as Markov processes, as discussed in sections 1.5, 1.6 and 11.2. Neural networks have also been used to estimate the frame based scores; these scores are then integrated into HMM-based system architectures, in what has become known as hybrid systems, as described in section 11.5. An interesting feature of frame-based HMM systems is that speech segments are identified during the search process, rather than explicitly. An alternate approach is to first identify speech segments, then classify the segments and use the segment scores to recognize words. This approach has produced competitive recognition performance in several tasks (Zue, Glass, et al., 1990; Fanty, Barnard, et al., 1995).

1.2.2 State of the Art
Comments about the state-of-the-art need to be made in the context of specific applications which reflect the constraints on the task. Moreover, different technologies are sometimes appropriate for different tasks. For example, when the vocabulary is small, the entire word can be modeled as a single unit. Such an approach is not practical for large vocabularies, where word models must be built up from subword units. Performance of speech recognition systems is typically described in terms of word error rate, , defined as:

where is the total number of words in the test set, and , , and are, respectively, the total number of substitutions, insertions, and deletions. The past decade has witnessed significant progress in speech recognition technology. Word error rates continue to drop by a factor of 2 every two years. Substantial progress has been made in the basic technology, leading to the lowering of barriers to speaker independence, continuous speech, and large vocabularies. There are several factors that have contributed to this rapid progress. First, there is the coming of age of the HMM. HMM is powerful in that, with the availability of training data, the parameters of the model can be trained automatically to give optimal performance. Second, much effort has gone into the development of large speech corpora for system development, training, and testing. Some of these corpora are designed for acoustic phonetic research, while others are highly task specific. Nowadays, it is not uncommon to have tens of thousands of sentences available for system training and testing. These corpora permit researchers to quantify the acoustic cues important for phonetic contrasts and to determine parameters of the recognizers in a statistically meaningful way. While many of these corpora (e.g., TIMIT, RM, ATIS, and WSJ; see section 12.3) were originally collected under the sponsorship of the U.S. Defense Department's Advanced Research Projects Agency (ARPA), to spur human language technology development among its contractors, they have nevertheless gained world-wide acceptance (e.g., in Canada, France, Germany, Japan, and the U.K.) as standards on which to evaluate speech recognition. Third, progress has been brought about by the establishment of standards for performance evaluation. Only a decade ago, researchers trained and tested their systems using locally collected data, and had not been very careful in delineating training and




1.2 Speech Recognition

7

testing sets. As a result, it was very difficult to compare performance across systems, and a system's performance typically degraded when it was presented with previously unseen data. The recent availability of a large body of data in the public domain, coupled with the specification of evaluation standards, has resulted in uniform documentation of test results, thus contributing to greater reliability in monitoring progress (corpus development activities and evaluation methodologies are summarized in chapters 12 and 13 respectively). Finally, advances in computer technology have also indirectly influenced our progress. The availability of fast computers with inexpensive mass storage capabilities has enabled researchers to run many large scale experiments in a short amount of time. This means that the elapsed time between an idea and its implementation and evaluation is greatly reduced. In fact, speech recognition systems with reasonable performance can now run in real time using high-end workstations without additional hardware--a feat unimaginable only a few years ago. One of the most popular and potentially most useful tasks with low perplexity (  ) is the recognition of digits. For American English, speaker-independent recognition of digit strings, spoken continuously and restricted to telephone bandwidth, can achieve an error rate of 0.3% when the string length is known. One of the best known moderate-perplexity tasks is the 1,000-word so-called Resource Management (RM) task, in which inquiries can be made concerning various naval vessels in the Pacific Ocean. The best speaker-independent performance on the RM task is less than 4%, using a word-pair language model that constrains the possible words following a given word (  ). More recently, researchers have begun to address the issue of recognizing spontaneously generated speech. For example, in the Air Travel Information Service (ATIS) domain, word error rates of less than 3% has been reported for a vocabulary of nearly 2,000 words and a bigram language model with a perplexity of around 15. High perplexity tasks with a vocabulary of thousands of words are intended primarily for the dictation application. After working on isolated-word, speaker-dependent systems for many years, since 1992 the community has moved towards very-largevocabulary (20,000 words and more), high-perplexity (  ), speaker-independent, continuous speech recognition. The best system in 1994 achieved an error rate of 7.2% on read sentences drawn from North American business news (Pallett, Fiscus, et al., 1994). With the steady improvements in speech recognition performance, systems are now being deployed within telephone and cellular networks in many countries. Within the next few years, speech recognition will be pervasive in telephone networks around the world. There are tremendous forces driving the development of the technology; in many countries, touch tone penetration is low, and voice is the only option for controlling automated services. In voice dialing, for example, users can dial 10­20 telephone numbers by voice (e.g., Call Home) after having enrolled their voices by saying the words associated with telephone numbers. AT&T, on the other hand, has installed a call routing system using speaker-independent word-spotting technology that can detect a few key phrases (e.g., person to person, calling card) in sentences such as: I want to charge it to my calling card. At present, several very large vocabulary dictation systems are available for document generation. These systems generally require speakers to pause between words.



Chapter 1: Spoken Language Input

Their performance can be further enhanced if one can apply constraints of the specific domain such as dictating medical reports. Even though much progress is being made, machines are a long way from recognizing conversational speech. Word recognition rates on telephone conversations in the Switchboard corpus are around 50% (Cohen, Gish, et al., 1994). It will be many years before unlimited vocabulary, speaker-independent, continuous dictation capability is realized.

1.2.3 Future Directions
In 1992, the U.S. National Science Foundation sponsored a workshop to identify the key research challenges in the area of human language technology and the infrastructure needed to support the work. The key research challenges are summarized in Cole, Hirschman, et al. (1992). Research in the following areas of speech recognition were identified: Robustness: In a robust system, performance degrades gracefully (rather than catastrophically) as conditions become more different from those under which it was trained. Differences in channel characteristics and acoustic environment should receive particular attention. Portability: Portability refers to the goal of rapidly designing, developing and deploying systems for new applications. At present, systems tend to suffer significant degradation when moved to a new task. In order to return to peak performance, they must be trained on examples specific to the new task, which is time consuming and expensive. Adaptation: How can systems continuously adapt to changing conditions (new speakers, microphone, task, etc.) and improve through use? Such adaptation can occur at many levels in systems, subword models, word pronunciations, language models, etc. Language Modeling: Current systems use statistical language models to help reduce the search space and resolve acoustic ambiguity. As vocabulary size grows and other constraints are relaxed to create more habitable systems, it will be increasingly important to get as much constraint as possible from language models; perhaps incorporating syntactic and semantic constraints that cannot be captured by purely statistical models. Confidence Measures: Most speech recognition systems assign scores to hypotheses for the purpose of rank ordering them. These scores do not provide a good indication of whether a hypothesis is correct or not, just that it is better than the other hypotheses. As we move to tasks that require actions, we need better methods to evaluate the absolute correctness of hypotheses.

1.3 Signal Representation

9

Out-of-Vocabulary Words: Systems are designed for use with a particular set of words but system users may not know exactly which words are in the system vocabulary. This leads to a certain percentage of out-of-vocabulary words in natural conditions. Systems must have some method of detecting such out-of-vocabulary words, or they will end up mapping a word from the vocabulary onto the unknown word, causing an error. Spontaneous Speech: Systems that are deployed for real use must deal with a variety of spontaneous speech phenomena, such as filled pauses, false starts, hesitations, ungrammatical constructions and other common behaviors not found in read speech. Development on the ATIS task has resulted in progress in this area, but much work remains to be done. Prosody: Prosody refers to acoustic structure that extends over several segments or words. Stress, intonation, and rhythm convey important information for word recognition and the user's intentions (e.g., sarcasm, anger). Current systems do not capture prosodic structure. How to integrate prosodic information into the recognition architecture is a critical question that has yet to be answered. Modeling Dynamics: Systems assume a sequence of input frames which are treated as if they were independent. But it is known that perceptual cues for words and phonemes require the integration of features that reflect the movements of the articulators, which are dynamic in nature. How to model dynamics and incorporate this information into recognition systems is an unsolved problem.

1.3 Signal Representation
Melvyn J. Hunt
Dragon Systems UK Ltd., Cheltenham, UK

In statistically based automatic speech recognition, the speech waveform is sampled at a rate between 6.6 kHz and 20 kHz and processed to produce a new representation as a sequence of vectors containing values that are generally called parameters. The vectors (  in the notation used in section 1.5) typically comprise between 10 and 20 parameters, and are usually computed every 10 or 20 msec. These parameter values are then used in succeeding stages in the estimation of the probability that the portion of waveform just analyzed corresponds to a particular phonetic event in the phonesized or whole-word reference unit being hypothesized. In practice, the representation and the probability estimation interact strongly: what one person sees as part of the representation, another may see as part of the probability estimation process. For most systems, though, we can apply the criterion that if a process is applied to all speech, it is part of the representation, while if its application is contingent on the phonetic hypothesis being tested, it is part of the later matching stage. Representations aim to preserve the information needed to determine the phonetic identity of a portion of speech while being as impervious as possible to factors such as

10

Chapter 1: Spoken Language Input

speaker differences, effects introduced by communications channels, and paralinguistic factors such as the emotional state of the speaker. They also aim to be as compact as possible. Representations used in current speech recognizers (see Figure 1.3), concentrate primarily on properties of the speech signal attributable to the shape of the vocal tract rather than to the excitation, whether generated by a vocal-tract constriction or by the larynx. Representations are sensitive to whether the vocal folds are vibrating or not (the voiced/unvoiced distinction), but try to ignore effects due to variations in their frequency of vibration (  ). Representations are almost always derived from the short-term power spectrum; that is, the short-term phase structure is ignored. This is primarily because our ears are largely insensitive to phase effects. Consequently, speech communication and recording equipment often does not preserve the phase structure of the original waveform, and such equipment, as well as factors such as room acoustics, can alter the phase spectrum in ways that would disturb a phase-sensitive speech recognizer, even though a human listener would not notice them. The power spectrum is, moreover, almost always represented on a log scale. When the gain applied to a signal varies, the shape of the log power spectrum is preserved; the spectrum is simply shifted up or down. More complicated linear filtering caused, for example, by room acoustics or by variations between telephone lines, which appear as convolutional effects on the waveform and as multiplicative effects on the linear power spectrum, become simply additive constants on the log power spectrum. Indeed, a voiced speech waveform amounts to the convolution of a quasi-periodic excitation signal and a time-varying filter determined largely by the configuration of the vocal tract. These two components are easier to separate in the log-power domain, where they are additive. Finally, the statistical distributions of log power spectra for speech have properties convenient for statistically based speech recognition that are not, for example, shared by linear power spectra. Because the log of zero is infinite, there is a problem in representing very low energy parts of the spectrum. The log function therefore needs a lower bound, both to limit the numerical range and to prevent excessive sensitivity to the low-energy, noise-dominated parts of the spectrum. Before computing short-term power spectra, the waveform is usually processed by a simple pre-emphasis filter, giving a 6 dB/octave increase in gain over most of its range to make the average speech spectrum roughly flat. The short-term spectra are often derived by taking successive overlapping portions of the pre-emphasized waveform, typically 25 msec long, tapering at both ends with a bell-shaped window function, and applying a Fourier transform. The resulting power spectrum has undesirable harmonic fine structure at multiples of . This can be reduced by grouping neighboring sets of components together to form about 20 frequency bands before converting to log power. These bands are often made successively broader with increasing frequency above 1 kHz, usually according to the technical mel frequency scale (Davis & Mermelstein, 1980), reflecting the frequency resolution of the human ear. A less common alternative to the process just described is to compute the energy in the bands, directly using a bank of digital filters. The results are similar. Since the shape of the spectrum imposed by the vocal tract is smooth, energy levels in adjacent bands tend to be correlated. Removing the correlation allows the number

1.3 Signal Representation

11

Figure 1.3: Examples of representations used in current speech recognizers: (a) Time varying waveform of the word speech, showing changes in amplitude (y axis) over time (x axis); (b) Speech spectrogram of (a), in terms of frequency (y axis), time (x axis) and amplitude (darkness of the pattern); (c) Expanded waveform of the vowel ee (underlined in b); (d) Spectrum of the vowel ee, in terms of amplitude (y axis) and frequency (x axis); (e) Mel-scale spectrogram.

12

Chapter 1: Spoken Language Input

of parameters to be reduced while preserving the useful information. It also makes it easier to compute reasonably accurate probability estimates in a subsequent statistical matching process. The cosine transform (a version of the Fourier transform using only cosine basis functions) converts the set of log energies to a set of cepstral coefficients, which turn out to be largely uncorrelated. Compared with the number of bands, typically only about half as many of these cepstral coefficients need be kept. The first cepstral coefficient (  ) described the shape of the log spectrum independent of its overall level: measures the balance between the upper and lower halves of the spectrum, and the higher order coefficients are concerned with increasingly finer features in the spectrum. To the extent that the vocal tract can be regarded as a lossless, unbranched acoustic tube with plane-wave sound propagation along it, its effect on the excitation signal is that of a series of resonances; that is, the vocal tract can be modeled as an all-pole filter. For many speech sounds in favorable acoustic conditions, this is a good approximation. A technique known as linear predictive coding (LPC) (Markel & Gray, 1976) or autoregressive modeling in effect fits the parameters of an all-pole filter to the speech spectrum, though the spectrum itself need never be computed explicitly. This provides a popular alternative method of deriving cepstral coefficients. LPC has problems with certain signal degradations and is not so convenient for producing mel-scale cepstral coefficients. Perceptual Linear Prediction (PLP) combines the LPC and filter-bank approaches by fitting an all-pole model to the set of energies (or, strictly, loudness levels) produced by a perceptually motivated filter bank, and then computing the cepstrum from the model parameters (Hermansky, 1990). Many systems augment information on the short-term power spectrum with information on its rate of change over time. The simplest way to obtain this dynamic information would be to take the difference between consecutive frames. However, this turns out to be too sensitive to random interframe variations. Consequently, linear trends are estimated over sequences of typically five or seven frames (Furui, 1986b). Some systems go further and estimate acceleration features as well as linear rates of change. These second-order dynamic features need even longer sequences of frames for reliable estimation (Applebaum & Hanson, 1989). Steady factors affecting the shape or overall level of the spectrum (such as the characteristics of a particular telephone link) appear as constant offsets in the log spectrum and cepstrum. In a technique called blind deconvolution (Stockham, Connon, et al., 1975), cepstrum is computed, and this average is subtracted from the individual frames. This method is largely confined to non-real-time experimental systems. Since they are based on differences, however, dynamic features are intrinsically immune to such constant effects. Consequently, while is usually cast aside, its dynamic equivalent, , depending only on relative rather than absolute energy levels, is widely used. If first-order dynamic parameters are passed through a leaky integrator, something close to the original static parameters are recovered with the exception that constant and very slowly varying features are reduced to zero, thus giving independence from constant or slowly varying channel characteristics. This technique, sometimes referred to as RASTA, amounts to band-pass filtering of sequences of log power spectra, is better suited than blind deconvolution to real-time systems (Hermansky, Morgan, et al., 1993). A similar technique, applied to sequences of power spectra before logs are taken, is ca-
1.3 Signal Representation

13

pable of reducing the effect of steady or slowly varying additive noise (Hirsch, Meyer, et al., 1991). Because cepstral coefficients are largely uncorrelated, a computationally efficient method of obtaining reasonably good probability estimates in the subsequent matching process consists of calculating Euclidean distances from reference model vectors after suitably weighting the coefficients. Various weighting schemes have been used. One empirical scheme that works well derives the weights for the first 16 coefficients from the positive half cycle of a sine wave (Juang, Rabiner, et al., 1986). For PLP cepstral coefficients, weighting each coefficient by its index (root power sum (RPS) weighting) giving a weight of zero, etc., has proved effective. Statistically based methods weight coefficients by the inverse of their standard deviations computed about their overall means, or preferably computed about the means for the corresponding speech sound and then averaged over all speech sounds (so-called grand-variance weighting) (Lippmann, Martin, et al., 1987). While cepstral coefficients are substantially uncorrelated, a technique called principal components analysis (PCA) can provide a transformation that can completely remove linear dependencies between sets of variables. This method can be used to de-correlate not just sets of energy levels across a spectrum but also combinations of parameter sets such as dynamic and static features, PLP and non-PLP parameters. A double application of PCA with a weighting operation, known as linear discriminant analysis (LDA), can take into account the discriminative information needed to distinguish between speech sounds to generate a set of parameters, sometimes called IMELDA coefficients, suitably weighted for Euclidean-distance calculations. Good performance has been reported with a much reduced set of IMELDA coefficients, and there is evidence that incorporating degraded signals in the analysis can improve robustness to the degradations while not harming performance on undegraded data (Hunt & Lef` bvre, 1989). e

Future Directions
The vast majority of major commercial and experimental systems use representations akin to those described here. However, in striving to develop better representations, wavelet transforms (Daubechies, 1990) are being explored, and neural network methods are being used to provide non-linear operations on log spectral representations. Work continues on representations more closely reflecting auditory properties (Greenberg, 1988) and on representations reconstructing articulatory gestures from the speech signal (Schroeter & Sondhi, 1994). This latter work is challenging because there is a one-to-many mapping between the speech spectrum and the articulatory settings that could produce it. It is attractive because it holds out the promise of a small set of smoothly varying parameters that could deal in a simple and principled way with the interactions that occur between neighboring phonemes and with the effects of differences in speaking rate and of carefulness of enunciation. As we noted earlier, current representations concentrate on the spectrum envelope and ignore fundamental frequency; yet we know that even in isolated-word recognition fundamental frequency contours are an important cue to lexical identity not only in tonal languages such as Chinese but also in languages such as English where they correlate with lexical stress. In continuous speech recognition fundamental frequency

¡ 

14

Chapter 1: Spoken Language Input
